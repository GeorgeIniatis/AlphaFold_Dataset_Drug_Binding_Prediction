{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# General Imports\n",
    "from models_utils import *\n",
    "\n",
    "# Classification Models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "feature_selection_columns = load_from_pickle(\"Training_Test_Sets/Classification/X_train_feature_selection\").loc[:,\n",
    "                            \"MolecularWeight\":].columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = load_from_pickle(\"Training_Test_Sets/Classification/X_train_feature_selection\")\n",
    "X_train.drop(columns=[\"Drug_CID\", \"Protein_Accession\"], inplace=True)\n",
    "X_train = X_train.to_numpy()\n",
    "\n",
    "y_train = load_from_pickle(\"Training_Test_Sets/Classification/y_train\")\n",
    "y_train = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_test = load_from_pickle(\"Training_Test_Sets/Classification/X_test_feature_selection\")\n",
    "X_test.drop(columns=[\"Drug_CID\", \"Protein_Accession\"], inplace=True)\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "y_test = load_from_pickle(\"Training_Test_Sets/Classification/y_test\")\n",
    "y_test = y_test.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (99705, 388)\n",
      "y_train shape: 99705 (Binding Count: 73498, Non-Binding Count: 26207)\n",
      "X_test shape: (816, 388)\n",
      "y_test shape: 816 (Binding Count: 563, Non-Binding Count: 253)\n"
     ]
    }
   ],
   "source": [
    "# Useful Information & Sanity Checks\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape[0]} \", end=\"\")\n",
    "print(f\"(Binding Count: {y_train[y_train == 1].shape[0]}, \", end=\"\")\n",
    "print(f\"Non-Binding Count: {y_train[y_train == 0].shape[0]})\")\n",
    "\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape[0]} \", end=\"\")\n",
    "print(f\"(Binding Count: {y_test[y_test == 1].shape[0]}, \", end=\"\")\n",
    "print(f\"Non-Binding Count: {y_test[y_test == 0].shape[0]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training & Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def on_step(optim_result):\n",
    "    global index\n",
    "    print(f\"Iteration Completed: {index}\")\n",
    "    index += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dummy Classifier (DC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model', DummyClassifier(random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': DummyClassifier(random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__constant': None,\n 'model__random_state': 42,\n 'model__strategy': 'prior'}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_classifier = Pipeline(\n",
    "    [\n",
    "        ('scale', StandardScaler()),\n",
    "        ('model', DummyClassifier(random_state=42))\n",
    "    ]\n",
    ")\n",
    "dummy_classifier.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dummy_classifier.fit(X_train, y_train)\n",
    "#\n",
    "# y_train_pred = dummy_classifier.predict(X_train)\n",
    "# calculate_metrics_classification(y_train, y_train_pred)\n",
    "#\n",
    "# # Save Model\n",
    "# dump(dummy_classifier, 'Dataset_Files/Baseline_Models/Classification/dc.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Load Model\n",
    "dummy_classifier = load('Dataset_Files/Baseline_Models/Classification/dc.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 1000\n",
      "--------------------------------------------------------\n",
      "Median Recall: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median Precision: 0.74 with a 95% confidence interval of [0.71,0.77]\n",
      "Median F1: 0.85 with a 95% confidence interval of [0.83,0.87]\n",
      "Median Accuracy: 0.74 with a 95% confidence interval of [0.71,0.77]\n",
      "Median MCC: 0.00 with a 95% confidence interval of [0.00,0.00]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(dummy_classifier, X_train, y_train, 1000, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 500\n",
      "--------------------------------------------------------\n",
      "Median Recall: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median Precision: 0.69 with a 95% confidence interval of [0.65,0.73]\n",
      "Median F1: 0.82 with a 95% confidence interval of [0.79,0.84]\n",
      "Median Accuracy: 0.69 with a 95% confidence interval of [0.65,0.73]\n",
      "Median MCC: 0.00 with a 95% confidence interval of [0.00,0.00]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(dummy_classifier, X_test, y_test, 500, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Logistic Regression (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model', LogisticRegression(random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': LogisticRegression(random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__C': 1.0,\n 'model__class_weight': None,\n 'model__dual': False,\n 'model__fit_intercept': True,\n 'model__intercept_scaling': 1,\n 'model__l1_ratio': None,\n 'model__max_iter': 100,\n 'model__multi_class': 'auto',\n 'model__n_jobs': None,\n 'model__penalty': 'l2',\n 'model__random_state': 42,\n 'model__solver': 'lbfgs',\n 'model__tol': 0.0001,\n 'model__verbose': 0,\n 'model__warm_start': False}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scale', StandardScaler()),\n",
    "        ('model', LogisticRegression(random_state=42))\n",
    "    ]\n",
    ")\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = BayesSearchCV(estimator=pipe,\n",
    "                      search_spaces=[\n",
    "                          {'model__C': Real(1e-6, 1e+2, prior='log-uniform'),\n",
    "                           'model__solver': Categorical(['newton-cg', 'lbfgs', 'sag']),\n",
    "                           'model__penalty': Categorical(['none', 'l2']),\n",
    "                           'model__max_iter': Integer(50, 5000),\n",
    "                           'model__class_weight': Categorical([None, \"balanced\"])},\n",
    "                          {'model__C': Real(1e-6, 1e+2, prior='log-uniform'),\n",
    "                           'model__solver': Categorical(['liblinear']),\n",
    "                           'model__penalty': Categorical(['l2', 'l1']),\n",
    "                           'model__max_iter': Integer(50, 5000),\n",
    "                           'model__class_weight': Categorical([None, \"balanced\"])},\n",
    "                          {'model__C': Real(1e-6, 1e+2, prior='log-uniform'),\n",
    "                           'model__l1_ratio': Real(0, 1),\n",
    "                           'model__solver': Categorical(['saga']),\n",
    "                           'model__penalty': Categorical(['none', 'l2', 'l1', 'elasticnet']),\n",
    "                           'model__max_iter': Integer(50, 5000),\n",
    "                           'model__class_weight': Categorical([None, \"balanced\"])},\n",
    "                      ],\n",
    "                      scoring='f1',\n",
    "                      cv=5,\n",
    "                      error_score=np.nan,\n",
    "                      n_jobs=-1,\n",
    "                      pre_dispatch='2*n_jobs',\n",
    "                      random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# index = 1\n",
    "# model.fit(X_train, y_train, callback=on_step)\n",
    "#\n",
    "# optimised_lr = model.best_estimator_\n",
    "#\n",
    "# y_train_pred = optimised_lr.predict(X_train)\n",
    "# calculate_metrics_classification(y_train, y_train_pred)\n",
    "#\n",
    "# # Save Model & CV Results\n",
    "# dump(optimised_lr, 'Dataset_Files/Baseline_Models/Classification/optimised_lr.joblib')\n",
    "# np.save(\"Dataset_Files/Baseline_Models/Classification/optimised_lr_cv_results\", model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Load Model\n",
    "optimised_lr = load('Dataset_Files/Baseline_Models/Classification/optimised_lr.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 1000\n",
      "--------------------------------------------------------\n",
      "Median Recall: 0.93 with a 95% confidence interval of [0.91,0.95]\n",
      "Median Precision: 0.84 with a 95% confidence interval of [0.81,0.86]\n",
      "Median F1: 0.88 with a 95% confidence interval of [0.87,0.90]\n",
      "Median Accuracy: 0.82 with a 95% confidence interval of [0.79,0.84]\n",
      "Median MCC: 0.49 with a 95% confidence interval of [0.43,0.55]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_lr, X_train, y_train, 1000, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model',\n   LogisticRegression(C=0.0005922659193283465, max_iter=86, penalty='none',\n                      random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': LogisticRegression(C=0.0005922659193283465, max_iter=86, penalty='none',\n                    random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__C': 0.0005922659193283465,\n 'model__class_weight': None,\n 'model__dual': False,\n 'model__fit_intercept': True,\n 'model__intercept_scaling': 1,\n 'model__l1_ratio': None,\n 'model__max_iter': 86,\n 'model__multi_class': 'auto',\n 'model__n_jobs': None,\n 'model__penalty': 'none',\n 'model__random_state': 42,\n 'model__solver': 'lbfgs',\n 'model__tol': 0.0001,\n 'model__verbose': 0,\n 'model__warm_start': False}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimised_lr.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n18        9.967149      0.222064         0.176222        0.045951   \n66       64.880265      2.561403         0.351809        0.056933   \n92      288.682903     23.192366         0.149290        0.068380   \n110      96.145776     43.485431         0.154168        0.101802   \n90      186.786358     38.790002         0.095461        0.023325   \n..             ...           ...              ...             ...   \n7         8.026151      1.485571         0.094766        0.025165   \n149       8.736954      0.187918         0.068754        0.015932   \n50        4.333323      0.046542         0.079652        0.010487   \n67        2.993152      0.281752         0.170432        0.094420   \n101       3.128486      0.310630         0.168329        0.100517   \n\n    param_model__C param_model__class_weight param_model__max_iter  \\\n18        0.000592                      None                    86   \n66        0.086874                      None                  4439   \n92         0.27837                      None                    50   \n110       0.458579                      None                  3710   \n90        0.171825                      None                    50   \n..             ...                       ...                   ...   \n7         0.000001                  balanced                  3719   \n149       0.000001                  balanced                  3568   \n50        0.000002                      None                  1273   \n67        0.000001                  balanced                  1764   \n101       0.000016                  balanced                  4596   \n\n    param_model__penalty param_model__solver param_model__l1_ratio  \\\n18                  none               lbfgs                   NaN   \n66                    l2           liblinear                   NaN   \n92                    l1           liblinear                   NaN   \n110                   l1                saga              0.709831   \n90                    l1           liblinear                   NaN   \n..                   ...                 ...                   ...   \n7                     l2           newton-cg                   NaN   \n149                   l2                saga              0.141119   \n50                    l2           liblinear                   NaN   \n67                    l2           liblinear                   NaN   \n101                   l1                saga              0.473675   \n\n                                                params  split0_test_score  \\\n18   {'model__C': 0.0005922659193283465, 'model__cl...           0.880807   \n66   {'model__C': 0.08687434218275818, 'model__clas...           0.881027   \n92   {'model__C': 0.27837010361065284, 'model__clas...           0.880999   \n110  {'model__C': 0.4585792720221234, 'model__class...           0.880919   \n90   {'model__C': 0.17182546055480577, 'model__clas...           0.880960   \n..                                                 ...                ...   \n7    {'model__C': 1.0691593986059968e-06, 'model__c...           0.743515   \n149  {'model__C': 1e-06, 'model__class_weight': 'ba...           0.743009   \n50   {'model__C': 2.195551082864074e-06, 'model__cl...           0.738634   \n67   {'model__C': 1e-06, 'model__class_weight': 'ba...           0.693792   \n101  {'model__C': 1.6285217534593228e-05, 'model__c...           0.000000   \n\n     split1_test_score  split2_test_score  split3_test_score  \\\n18            0.879686           0.882692           0.881077   \n66            0.879426           0.882736           0.881303   \n92            0.879634           0.882495           0.881154   \n110           0.879570           0.882601           0.881239   \n90            0.879882           0.882162           0.881228   \n..                 ...                ...                ...   \n7             0.744951           0.754247           0.746565   \n149           0.744762           0.754049           0.746680   \n50            0.740038           0.748189           0.743261   \n67            0.693219           0.703228           0.698660   \n101           0.848705           0.848705           0.848672   \n\n     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n18            0.881144         0.881081        0.000962                1  \n66            0.880858         0.881070        0.001056                2  \n92            0.880868         0.881030        0.000910                3  \n110           0.880801         0.881026        0.000970                4  \n90            0.880896         0.881025        0.000730                5  \n..                 ...              ...             ...              ...  \n7             0.743345         0.746525        0.004032              146  \n149           0.742964         0.746293        0.004111              147  \n50            0.738875         0.741799        0.003595              148  \n67            0.692990         0.696378        0.004007              149  \n101           0.000000         0.509217        0.415774              150  \n\n[150 rows x 19 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_model__C</th>\n      <th>param_model__class_weight</th>\n      <th>param_model__max_iter</th>\n      <th>param_model__penalty</th>\n      <th>param_model__solver</th>\n      <th>param_model__l1_ratio</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18</th>\n      <td>9.967149</td>\n      <td>0.222064</td>\n      <td>0.176222</td>\n      <td>0.045951</td>\n      <td>0.000592</td>\n      <td>None</td>\n      <td>86</td>\n      <td>none</td>\n      <td>lbfgs</td>\n      <td>NaN</td>\n      <td>{'model__C': 0.0005922659193283465, 'model__cl...</td>\n      <td>0.880807</td>\n      <td>0.879686</td>\n      <td>0.882692</td>\n      <td>0.881077</td>\n      <td>0.881144</td>\n      <td>0.881081</td>\n      <td>0.000962</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>64.880265</td>\n      <td>2.561403</td>\n      <td>0.351809</td>\n      <td>0.056933</td>\n      <td>0.086874</td>\n      <td>None</td>\n      <td>4439</td>\n      <td>l2</td>\n      <td>liblinear</td>\n      <td>NaN</td>\n      <td>{'model__C': 0.08687434218275818, 'model__clas...</td>\n      <td>0.881027</td>\n      <td>0.879426</td>\n      <td>0.882736</td>\n      <td>0.881303</td>\n      <td>0.880858</td>\n      <td>0.881070</td>\n      <td>0.001056</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>288.682903</td>\n      <td>23.192366</td>\n      <td>0.149290</td>\n      <td>0.068380</td>\n      <td>0.27837</td>\n      <td>None</td>\n      <td>50</td>\n      <td>l1</td>\n      <td>liblinear</td>\n      <td>NaN</td>\n      <td>{'model__C': 0.27837010361065284, 'model__clas...</td>\n      <td>0.880999</td>\n      <td>0.879634</td>\n      <td>0.882495</td>\n      <td>0.881154</td>\n      <td>0.880868</td>\n      <td>0.881030</td>\n      <td>0.000910</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>110</th>\n      <td>96.145776</td>\n      <td>43.485431</td>\n      <td>0.154168</td>\n      <td>0.101802</td>\n      <td>0.458579</td>\n      <td>None</td>\n      <td>3710</td>\n      <td>l1</td>\n      <td>saga</td>\n      <td>0.709831</td>\n      <td>{'model__C': 0.4585792720221234, 'model__class...</td>\n      <td>0.880919</td>\n      <td>0.879570</td>\n      <td>0.882601</td>\n      <td>0.881239</td>\n      <td>0.880801</td>\n      <td>0.881026</td>\n      <td>0.000970</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>186.786358</td>\n      <td>38.790002</td>\n      <td>0.095461</td>\n      <td>0.023325</td>\n      <td>0.171825</td>\n      <td>None</td>\n      <td>50</td>\n      <td>l1</td>\n      <td>liblinear</td>\n      <td>NaN</td>\n      <td>{'model__C': 0.17182546055480577, 'model__clas...</td>\n      <td>0.880960</td>\n      <td>0.879882</td>\n      <td>0.882162</td>\n      <td>0.881228</td>\n      <td>0.880896</td>\n      <td>0.881025</td>\n      <td>0.000730</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8.026151</td>\n      <td>1.485571</td>\n      <td>0.094766</td>\n      <td>0.025165</td>\n      <td>0.000001</td>\n      <td>balanced</td>\n      <td>3719</td>\n      <td>l2</td>\n      <td>newton-cg</td>\n      <td>NaN</td>\n      <td>{'model__C': 1.0691593986059968e-06, 'model__c...</td>\n      <td>0.743515</td>\n      <td>0.744951</td>\n      <td>0.754247</td>\n      <td>0.746565</td>\n      <td>0.743345</td>\n      <td>0.746525</td>\n      <td>0.004032</td>\n      <td>146</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>8.736954</td>\n      <td>0.187918</td>\n      <td>0.068754</td>\n      <td>0.015932</td>\n      <td>0.000001</td>\n      <td>balanced</td>\n      <td>3568</td>\n      <td>l2</td>\n      <td>saga</td>\n      <td>0.141119</td>\n      <td>{'model__C': 1e-06, 'model__class_weight': 'ba...</td>\n      <td>0.743009</td>\n      <td>0.744762</td>\n      <td>0.754049</td>\n      <td>0.746680</td>\n      <td>0.742964</td>\n      <td>0.746293</td>\n      <td>0.004111</td>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>4.333323</td>\n      <td>0.046542</td>\n      <td>0.079652</td>\n      <td>0.010487</td>\n      <td>0.000002</td>\n      <td>None</td>\n      <td>1273</td>\n      <td>l2</td>\n      <td>liblinear</td>\n      <td>NaN</td>\n      <td>{'model__C': 2.195551082864074e-06, 'model__cl...</td>\n      <td>0.738634</td>\n      <td>0.740038</td>\n      <td>0.748189</td>\n      <td>0.743261</td>\n      <td>0.738875</td>\n      <td>0.741799</td>\n      <td>0.003595</td>\n      <td>148</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>2.993152</td>\n      <td>0.281752</td>\n      <td>0.170432</td>\n      <td>0.094420</td>\n      <td>0.000001</td>\n      <td>balanced</td>\n      <td>1764</td>\n      <td>l2</td>\n      <td>liblinear</td>\n      <td>NaN</td>\n      <td>{'model__C': 1e-06, 'model__class_weight': 'ba...</td>\n      <td>0.693792</td>\n      <td>0.693219</td>\n      <td>0.703228</td>\n      <td>0.698660</td>\n      <td>0.692990</td>\n      <td>0.696378</td>\n      <td>0.004007</td>\n      <td>149</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>3.128486</td>\n      <td>0.310630</td>\n      <td>0.168329</td>\n      <td>0.100517</td>\n      <td>0.000016</td>\n      <td>balanced</td>\n      <td>4596</td>\n      <td>l1</td>\n      <td>saga</td>\n      <td>0.473675</td>\n      <td>{'model__C': 1.6285217534593228e-05, 'model__c...</td>\n      <td>0.000000</td>\n      <td>0.848705</td>\n      <td>0.848705</td>\n      <td>0.848672</td>\n      <td>0.000000</td>\n      <td>0.509217</td>\n      <td>0.415774</td>\n      <td>150</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows Ã— 19 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_grid_search_dataframe = pd.DataFrame(\n",
    "    np.load(\"Dataset_Files/Baseline_Models/Classification/optimised_lr_cv_results.npy\", allow_pickle=True).tolist())\n",
    "logistic_regression_grid_search_dataframe.sort_values(by=[\"rank_test_score\"], inplace=True)\n",
    "logistic_regression_grid_search_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 500\n",
      "--------------------------------------------------------\n",
      "Median Recall: 0.86 with a 95% confidence interval of [0.82,0.90]\n",
      "Median Precision: 0.77 with a 95% confidence interval of [0.73,0.81]\n",
      "Median F1: 0.81 with a 95% confidence interval of [0.78,0.85]\n",
      "Median Accuracy: 0.73 with a 95% confidence interval of [0.69,0.77]\n",
      "Median MCC: 0.33 with a 95% confidence interval of [0.24,0.42]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_lr, X_test, y_test, 500, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear Support Vector Classification (LSVC)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()), ('model', LinearSVC(random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': LinearSVC(random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__C': 1.0,\n 'model__class_weight': None,\n 'model__dual': True,\n 'model__fit_intercept': True,\n 'model__intercept_scaling': 1,\n 'model__loss': 'squared_hinge',\n 'model__max_iter': 1000,\n 'model__multi_class': 'ovr',\n 'model__penalty': 'l2',\n 'model__random_state': 42,\n 'model__tol': 0.0001,\n 'model__verbose': 0}"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scale', StandardScaler()),\n",
    "        ('model', LinearSVC(random_state=42, penalty='l2'))\n",
    "    ]\n",
    ")\n",
    "pipe.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "model = BayesSearchCV(estimator=pipe,\n",
    "                      search_spaces={'model__loss': Categorical(['hinge', 'squared_hinge']),\n",
    "                                     'model__C': Real(1e-6, 1e+2, prior='log-uniform'),\n",
    "                                     'model__class_weight': Categorical([None, \"balanced\"]),\n",
    "                                     'model__max_iter': Integer(500, 5000)},\n",
    "                      scoring='f1',\n",
    "                      cv=5,\n",
    "                      error_score=np.nan,\n",
    "                      n_jobs=-1,\n",
    "                      pre_dispatch='2*n_jobs',\n",
    "                      random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# index = 1\n",
    "# model.fit(X_train, y_train, callback=on_step)\n",
    "#\n",
    "# optimised_lsvc = model.best_estimator_\n",
    "#\n",
    "# y_train_pred = optimised_lsvc.predict(X_train)\n",
    "# calculate_metrics_classification(y_train, y_train_pred)\n",
    "#\n",
    "# # Save Model & CV Results\n",
    "# dump(optimised_lsvc, 'Dataset_Files/Baseline_Models/Classification/optimised_lsvc.joblib')\n",
    "# np.save(\"Dataset_Files/Baseline_Models/Classification/optimised_lsvc_cv_results.npy\", model.cv_results_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Load Model\n",
    "optimised_lsvc = load('Dataset_Files/Baseline_Models/Classification/optimised_lsvc.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 1000\n",
      "--------------------------------------------------------\n",
      "Median Recall: 0.94 with a 95% confidence interval of [0.92,0.95]\n",
      "Median Precision: 0.84 with a 95% confidence interval of [0.81,0.86]\n",
      "Median F1: 0.88 with a 95% confidence interval of [0.87,0.90]\n",
      "Median Accuracy: 0.82 with a 95% confidence interval of [0.80,0.84]\n",
      "Median MCC: 0.49 with a 95% confidence interval of [0.43,0.55]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_lsvc, X_train, y_train, 1000, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model',\n   LinearSVC(C=0.1382147549119633, loss='hinge', max_iter=3708, random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': LinearSVC(C=0.1382147549119633, loss='hinge', max_iter=3708, random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__C': 0.1382147549119633,\n 'model__class_weight': None,\n 'model__dual': True,\n 'model__fit_intercept': True,\n 'model__intercept_scaling': 1,\n 'model__loss': 'hinge',\n 'model__max_iter': 3708,\n 'model__multi_class': 'ovr',\n 'model__penalty': 'l2',\n 'model__random_state': 42,\n 'model__tol': 0.0001,\n 'model__verbose': 0}"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimised_lsvc.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n36      56.176328      0.590413         0.090110        0.012284   \n27      33.806663      0.289807         0.105785        0.015044   \n49      51.403866      0.477602         0.092906        0.014288   \n45      25.310576      0.198310         0.096962        0.011774   \n35      67.970470      0.654737         0.100172        0.007908   \n47     139.493681      1.239127         0.093835        0.017263   \n37      19.985416      0.191292         0.106314        0.030365   \n11     203.923365      1.299732         0.087499        0.012495   \n48      16.388446      0.204221         0.110348        0.022170   \n14      21.256865      0.154275         0.139289        0.033784   \n28      11.951910      0.101657         0.147947        0.025192   \n15       8.975395      0.090677         0.135965        0.011124   \n13       9.660700      0.088542         0.131497        0.021201   \n39       7.012258      0.081592         0.141951        0.021330   \n25      69.926335      0.210122         0.112261        0.015613   \n20     671.042691      1.531498         0.099674        0.028682   \n21     337.186943      0.696989         0.087318        0.007514   \n26     426.694321      0.960507         0.081484        0.006134   \n33      54.527078      9.390650         0.082766        0.009138   \n42      50.422560      2.893474         0.112381        0.011798   \n23     704.579067      1.481194         0.092688        0.019104   \n44      73.453864      0.186641         0.081353        0.018345   \n46      26.026245      1.622022         0.104204        0.016086   \n31      10.181759      0.554889         0.125934        0.022807   \n29       6.709389      0.225541         0.092176        0.004685   \n24       6.199446      0.376596         0.099676        0.025890   \n32       4.105729      0.160150         0.106231        0.015323   \n4      553.292869      0.780325         0.095806        0.015487   \n30       3.616593      0.032485         0.198605        0.011852   \n10      76.717862      0.155473         0.105587        0.013570   \n22       5.925119      1.127531         0.118421        0.034701   \n40       3.510504      0.108804         0.130510        0.030450   \n16       3.109341      0.035431         0.178220        0.010656   \n3      613.262495      0.784190         0.102618        0.024211   \n18       3.537884      0.143888         0.127483        0.025831   \n34       2.982127      0.428373         0.098149        0.017387   \n38     754.463311      0.632445         0.106528        0.024238   \n6       51.229421      0.262132         0.103901        0.019237   \n7       19.466794      0.180296         0.093759        0.009882   \n5      159.681896      0.847766         0.096924        0.017299   \n2        7.931138      0.112161         0.106308        0.015392   \n1      640.397510      0.448489         0.094972        0.010590   \n41     616.517097      1.007811         0.094654        0.021616   \n0       22.415431      1.355501         0.095111        0.017102   \n19      79.585758      0.157060         0.121877        0.018225   \n43       3.730349      0.118625         0.125002        0.009875   \n17     621.730066      0.386899         0.079338        0.010154   \n8      361.046766      0.392778         0.103269        0.025414   \n9        4.134569      0.022969         0.181245        0.012526   \n12       2.300901      0.087070         0.150464        0.012353   \n\n   param_model__C param_model__class_weight param_model__loss  \\\n36       0.138215                      None             hinge   \n27        0.07562                      None             hinge   \n49       0.118062                      None             hinge   \n45       0.046281                      None             hinge   \n35       0.172145                      None             hinge   \n47       0.435116                      None             hinge   \n37       0.052798                      None             hinge   \n11       0.743033                      None             hinge   \n48       0.029429                      None             hinge   \n14       0.032193                      None             hinge   \n28       0.014742                      None             hinge   \n15       0.013968                      None             hinge   \n13       0.005555                      None             hinge   \n39       0.004813                      None             hinge   \n25       0.038871                      None     squared_hinge   \n20        0.26397                      None     squared_hinge   \n21       0.081173                      None     squared_hinge   \n26       0.459543                      None     squared_hinge   \n33        0.00674                      None     squared_hinge   \n42       0.006045                      None     squared_hinge   \n23       1.130454                      None     squared_hinge   \n44       0.121737                      None     squared_hinge   \n46       0.003238                      None     squared_hinge   \n31       0.001043                      None     squared_hinge   \n29       0.000586                      None     squared_hinge   \n24       0.001405                      None             hinge   \n32       0.000214                      None     squared_hinge   \n4        2.491309                      None     squared_hinge   \n30       0.000096                      None     squared_hinge   \n10       0.350239                      None     squared_hinge   \n22       0.000618                      None             hinge   \n40       0.000062                      None     squared_hinge   \n16       0.000485                      None             hinge   \n3        3.156225                      None     squared_hinge   \n18       0.000076                      None             hinge   \n34       0.000032                      None             hinge   \n38      19.190776                      None     squared_hinge   \n6        0.086424                  balanced             hinge   \n7        0.022245                  balanced             hinge   \n5        0.745116                  balanced             hinge   \n2         0.00362                  balanced             hinge   \n1        5.001576                  balanced             hinge   \n41       0.150903                  balanced     squared_hinge   \n0        0.001909                  balanced     squared_hinge   \n19       2.576424                      None             hinge   \n43       0.000067                  balanced     squared_hinge   \n17      99.334634                      None             hinge   \n8       44.037625                  balanced     squared_hinge   \n9        0.000001                  balanced     squared_hinge   \n12       0.000001                      None             hinge   \n\n   param_model__max_iter                                             params  \\\n36                  3708  {'model__C': 0.1382147549119633, 'model__class...   \n27                  2098  {'model__C': 0.0756195398834118, 'model__class...   \n49                  5000  {'model__C': 0.11806153951092785, 'model__clas...   \n45                  3624  {'model__C': 0.0462806124078546, 'model__class...   \n35                  4946  {'model__C': 0.1721453720296977, 'model__class...   \n47                  5000  {'model__C': 0.43511575726811647, 'model__clas...   \n37                   500  {'model__C': 0.052797956980008054, 'model__cla...   \n11                  4770  {'model__C': 0.7430332957496445, 'model__class...   \n48                  1428  {'model__C': 0.02942902337296776, 'model__clas...   \n14                  5000  {'model__C': 0.03219332465407559, 'model__clas...   \n28                  2872  {'model__C': 0.014742304593320238, 'model__cla...   \n15                   513  {'model__C': 0.013967868241974836, 'model__cla...   \n13                  4936  {'model__C': 0.00555534437947526, 'model__clas...   \n39                  1605  {'model__C': 0.004813113256345993, 'model__cla...   \n25                   500  {'model__C': 0.03887079325988662, 'model__clas...   \n20                  5000  {'model__C': 0.26396976812513734, 'model__clas...   \n21                  2521  {'model__C': 0.08117259691282183, 'model__clas...   \n26                  3060  {'model__C': 0.45954321027181433, 'model__clas...   \n33                  5000  {'model__C': 0.006740278232626255, 'model__cla...   \n42                   500  {'model__C': 0.006044645492859773, 'model__cla...   \n23                  5000  {'model__C': 1.1304537728759494, 'model__class...   \n44                   500  {'model__C': 0.12173717071547675, 'model__clas...   \n46                  2901  {'model__C': 0.003238143906970181, 'model__cla...   \n31                   500  {'model__C': 0.0010433193504394752, 'model__cl...   \n29                  5000  {'model__C': 0.0005863758015860119, 'model__cl...   \n24                  2697  {'model__C': 0.0014053795758951387, 'model__cl...   \n32                  2730  {'model__C': 0.00021356215061759992, 'model__c...   \n4                   3721  {'model__C': 2.491308632420524, 'model__class_...   \n30                   500  {'model__C': 9.601709443113477e-05, 'model__cl...   \n10                   500  {'model__C': 0.3502393891452447, 'model__class...   \n22                  5000  {'model__C': 0.0006183813748776595, 'model__cl...   \n40                  5000  {'model__C': 6.239539190529237e-05, 'model__cl...   \n16                   500  {'model__C': 0.00048547084465555573, 'model__c...   \n3                   4112  {'model__C': 3.1562246465541888, 'model__class...   \n18                  4856  {'model__C': 7.605225223648453e-05, 'model__cl...   \n34                   500  {'model__C': 3.165606599337715e-05, 'model__cl...   \n38                  4991  {'model__C': 19.190776178531312, 'model__class...   \n6                   4434  {'model__C': 0.08642410048155082, 'model__clas...   \n7                   4269  {'model__C': 0.022244596968016832, 'model__cla...   \n5                   1348  {'model__C': 0.7451164370027008, 'model__class...   \n2                   2450  {'model__C': 0.003619595990038508, 'model__cla...   \n1                   4781  {'model__C': 5.001575677983704, 'model__class_...   \n41                  4246  {'model__C': 0.15090267940935065, 'model__clas...   \n0                   1921  {'model__C': 0.0019091131576909443, 'model__cl...   \n19                   513  {'model__C': 2.576423799733396, 'model__class_...   \n43                  5000  {'model__C': 6.671270500639629e-05, 'model__cl...   \n17                  4103  {'model__C': 99.33463392847965, 'model__class_...   \n8                   2371  {'model__C': 44.037625157309144, 'model__class...   \n9                   1645  {'model__C': 1.0691593986059968e-06, 'model__c...   \n12                  4849  {'model__C': 1e-06, 'model__class_weight': Non...   \n\n    split0_test_score  split1_test_score  split2_test_score  \\\n36           0.881830           0.882600           0.882878   \n27           0.881937           0.882564           0.882772   \n49           0.882079           0.882544           0.882685   \n45           0.881909           0.882594           0.882723   \n35           0.881786           0.882472           0.882821   \n47           0.881580           0.882829           0.882827   \n37           0.881863           0.882568           0.882898   \n11           0.881729           0.882506           0.882689   \n48           0.881718           0.882376           0.882496   \n14           0.881767           0.882240           0.882496   \n28           0.881919           0.882247           0.882136   \n15           0.881718           0.882234           0.882013   \n13           0.881632           0.881261           0.881776   \n39           0.881578           0.880826           0.881686   \n25           0.879023           0.880105           0.881664   \n20           0.879046           0.880041           0.881628   \n21           0.878938           0.880005           0.881636   \n26           0.879087           0.880154           0.881656   \n33           0.879418           0.879749           0.881596   \n42           0.879382           0.879764           0.881632   \n23           0.879346           0.879985           0.881460   \n44           0.878979           0.880205           0.881492   \n46           0.879441           0.879708           0.881449   \n31           0.879447           0.879549           0.880992   \n29           0.879857           0.879225           0.880709   \n24           0.879345           0.878689           0.880570   \n32           0.878524           0.878848           0.880143   \n4            0.879086           0.877277           0.878736   \n30           0.876769           0.877248           0.878512   \n10           0.877201           0.878223           0.876580   \n22           0.875809           0.876218           0.878063   \n40           0.876064           0.876538           0.877775   \n16           0.874697           0.874909           0.877204   \n3            0.875531           0.873759           0.875420   \n18           0.861732           0.861345           0.864796   \n34           0.855074           0.854831           0.858475   \n38           0.825028           0.838569           0.827313   \n6            0.831175           0.832855           0.831931   \n7            0.831413           0.832437           0.832425   \n5            0.831197           0.830718           0.832438   \n2            0.830317           0.831122           0.832127   \n1            0.827334           0.830760           0.829129   \n41           0.825094           0.827138           0.828343   \n0            0.825322           0.827007           0.827450   \n19           0.831415           0.818033           0.822409   \n43           0.817673           0.818783           0.820520   \n17           0.812772           0.812948           0.806522   \n8            0.792139           0.763830           0.814554   \n9            0.723185           0.724696           0.731959   \n12           0.712968           0.711833           0.723109   \n\n    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n36           0.882838           0.883748         0.882779        0.000614   \n27           0.882911           0.883591         0.882755        0.000535   \n49           0.882860           0.883555         0.882745        0.000481   \n45           0.882769           0.883563         0.882712        0.000527   \n35           0.882866           0.883576         0.882704        0.000583   \n47           0.882883           0.883382         0.882700        0.000598   \n37           0.882849           0.883263         0.882688        0.000468   \n11           0.882601           0.883685         0.882642        0.000623   \n48           0.882735           0.883521         0.882569        0.000583   \n14           0.882813           0.883506         0.882565        0.000582   \n28           0.882529           0.883280         0.882422        0.000472   \n15           0.882680           0.883210         0.882371        0.000524   \n13           0.882463           0.883121         0.882051        0.000662   \n39           0.882264           0.882937         0.881858        0.000707   \n25           0.880563           0.881274         0.880526        0.000927   \n20           0.880584           0.881152         0.880490        0.000897   \n21           0.880563           0.881231         0.880475        0.000950   \n26           0.880283           0.881059         0.880448        0.000872   \n33           0.880457           0.880928         0.880430        0.000787   \n42           0.880401           0.880907         0.880417        0.000802   \n23           0.880051           0.881000         0.880369        0.000760   \n44           0.880175           0.880925         0.880355        0.000844   \n46           0.880188           0.880861         0.880329        0.000739   \n31           0.880087           0.880512         0.880118        0.000582   \n29           0.879695           0.880192         0.879935        0.000497   \n24           0.881008           0.879381         0.879799        0.000857   \n32           0.878466           0.878882         0.878972        0.000609   \n4            0.877208           0.878434         0.878148        0.000768   \n30           0.877551           0.877994         0.877615        0.000601   \n10           0.878403           0.875174         0.877116        0.001179   \n22           0.877372           0.877598         0.877012        0.000855   \n40           0.876647           0.877792         0.876963        0.000698   \n16           0.877044           0.876967         0.876164        0.001116   \n3            0.876503           0.875322         0.875307        0.000882   \n18           0.863012           0.862944         0.862766        0.001208   \n34           0.855066           0.856272         0.855944        0.001363   \n38           0.839358           0.834100         0.832874        0.005805   \n6            0.830593           0.831549         0.831621        0.000759   \n7            0.830435           0.830939         0.831530        0.000798   \n5            0.829093           0.830200         0.830729        0.001104   \n2            0.829261           0.829518         0.830469        0.001055   \n1            0.827239           0.828813         0.828655        0.001299   \n41           0.823516           0.823768         0.825572        0.001889   \n0            0.823443           0.823646         0.825374        0.001655   \n19           0.816078           0.825342         0.822655        0.005452   \n43           0.812560           0.815722         0.817052        0.002733   \n17           0.804379           0.801151         0.807554        0.004658   \n8            0.756638           0.809883         0.787409        0.023525   \n9            0.725389           0.721253         0.725296        0.003621   \n12           0.718041           0.713101         0.715810        0.004231   \n\n    rank_test_score  \n36                1  \n27                2  \n49                3  \n45                4  \n35                5  \n47                6  \n37                7  \n11                8  \n48                9  \n14               10  \n28               11  \n15               12  \n13               13  \n39               14  \n25               15  \n20               16  \n21               17  \n26               18  \n33               19  \n42               20  \n23               21  \n44               22  \n46               23  \n31               24  \n29               25  \n24               26  \n32               27  \n4                28  \n30               29  \n10               30  \n22               31  \n40               32  \n16               33  \n3                34  \n18               35  \n34               36  \n38               37  \n6                38  \n7                39  \n5                40  \n2                41  \n1                42  \n41               43  \n0                44  \n19               45  \n43               46  \n17               47  \n8                48  \n9                49  \n12               50  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_model__C</th>\n      <th>param_model__class_weight</th>\n      <th>param_model__loss</th>\n      <th>param_model__max_iter</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>36</th>\n      <td>56.176328</td>\n      <td>0.590413</td>\n      <td>0.090110</td>\n      <td>0.012284</td>\n      <td>0.138215</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>3708</td>\n      <td>{'model__C': 0.1382147549119633, 'model__class...</td>\n      <td>0.881830</td>\n      <td>0.882600</td>\n      <td>0.882878</td>\n      <td>0.882838</td>\n      <td>0.883748</td>\n      <td>0.882779</td>\n      <td>0.000614</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>33.806663</td>\n      <td>0.289807</td>\n      <td>0.105785</td>\n      <td>0.015044</td>\n      <td>0.07562</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>2098</td>\n      <td>{'model__C': 0.0756195398834118, 'model__class...</td>\n      <td>0.881937</td>\n      <td>0.882564</td>\n      <td>0.882772</td>\n      <td>0.882911</td>\n      <td>0.883591</td>\n      <td>0.882755</td>\n      <td>0.000535</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>51.403866</td>\n      <td>0.477602</td>\n      <td>0.092906</td>\n      <td>0.014288</td>\n      <td>0.118062</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 0.11806153951092785, 'model__clas...</td>\n      <td>0.882079</td>\n      <td>0.882544</td>\n      <td>0.882685</td>\n      <td>0.882860</td>\n      <td>0.883555</td>\n      <td>0.882745</td>\n      <td>0.000481</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>25.310576</td>\n      <td>0.198310</td>\n      <td>0.096962</td>\n      <td>0.011774</td>\n      <td>0.046281</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>3624</td>\n      <td>{'model__C': 0.0462806124078546, 'model__class...</td>\n      <td>0.881909</td>\n      <td>0.882594</td>\n      <td>0.882723</td>\n      <td>0.882769</td>\n      <td>0.883563</td>\n      <td>0.882712</td>\n      <td>0.000527</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>67.970470</td>\n      <td>0.654737</td>\n      <td>0.100172</td>\n      <td>0.007908</td>\n      <td>0.172145</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>4946</td>\n      <td>{'model__C': 0.1721453720296977, 'model__class...</td>\n      <td>0.881786</td>\n      <td>0.882472</td>\n      <td>0.882821</td>\n      <td>0.882866</td>\n      <td>0.883576</td>\n      <td>0.882704</td>\n      <td>0.000583</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>139.493681</td>\n      <td>1.239127</td>\n      <td>0.093835</td>\n      <td>0.017263</td>\n      <td>0.435116</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 0.43511575726811647, 'model__clas...</td>\n      <td>0.881580</td>\n      <td>0.882829</td>\n      <td>0.882827</td>\n      <td>0.882883</td>\n      <td>0.883382</td>\n      <td>0.882700</td>\n      <td>0.000598</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>19.985416</td>\n      <td>0.191292</td>\n      <td>0.106314</td>\n      <td>0.030365</td>\n      <td>0.052798</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>500</td>\n      <td>{'model__C': 0.052797956980008054, 'model__cla...</td>\n      <td>0.881863</td>\n      <td>0.882568</td>\n      <td>0.882898</td>\n      <td>0.882849</td>\n      <td>0.883263</td>\n      <td>0.882688</td>\n      <td>0.000468</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>203.923365</td>\n      <td>1.299732</td>\n      <td>0.087499</td>\n      <td>0.012495</td>\n      <td>0.743033</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>4770</td>\n      <td>{'model__C': 0.7430332957496445, 'model__class...</td>\n      <td>0.881729</td>\n      <td>0.882506</td>\n      <td>0.882689</td>\n      <td>0.882601</td>\n      <td>0.883685</td>\n      <td>0.882642</td>\n      <td>0.000623</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>16.388446</td>\n      <td>0.204221</td>\n      <td>0.110348</td>\n      <td>0.022170</td>\n      <td>0.029429</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>1428</td>\n      <td>{'model__C': 0.02942902337296776, 'model__clas...</td>\n      <td>0.881718</td>\n      <td>0.882376</td>\n      <td>0.882496</td>\n      <td>0.882735</td>\n      <td>0.883521</td>\n      <td>0.882569</td>\n      <td>0.000583</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>21.256865</td>\n      <td>0.154275</td>\n      <td>0.139289</td>\n      <td>0.033784</td>\n      <td>0.032193</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 0.03219332465407559, 'model__clas...</td>\n      <td>0.881767</td>\n      <td>0.882240</td>\n      <td>0.882496</td>\n      <td>0.882813</td>\n      <td>0.883506</td>\n      <td>0.882565</td>\n      <td>0.000582</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>11.951910</td>\n      <td>0.101657</td>\n      <td>0.147947</td>\n      <td>0.025192</td>\n      <td>0.014742</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>2872</td>\n      <td>{'model__C': 0.014742304593320238, 'model__cla...</td>\n      <td>0.881919</td>\n      <td>0.882247</td>\n      <td>0.882136</td>\n      <td>0.882529</td>\n      <td>0.883280</td>\n      <td>0.882422</td>\n      <td>0.000472</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>8.975395</td>\n      <td>0.090677</td>\n      <td>0.135965</td>\n      <td>0.011124</td>\n      <td>0.013968</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>513</td>\n      <td>{'model__C': 0.013967868241974836, 'model__cla...</td>\n      <td>0.881718</td>\n      <td>0.882234</td>\n      <td>0.882013</td>\n      <td>0.882680</td>\n      <td>0.883210</td>\n      <td>0.882371</td>\n      <td>0.000524</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>9.660700</td>\n      <td>0.088542</td>\n      <td>0.131497</td>\n      <td>0.021201</td>\n      <td>0.005555</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>4936</td>\n      <td>{'model__C': 0.00555534437947526, 'model__clas...</td>\n      <td>0.881632</td>\n      <td>0.881261</td>\n      <td>0.881776</td>\n      <td>0.882463</td>\n      <td>0.883121</td>\n      <td>0.882051</td>\n      <td>0.000662</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>7.012258</td>\n      <td>0.081592</td>\n      <td>0.141951</td>\n      <td>0.021330</td>\n      <td>0.004813</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>1605</td>\n      <td>{'model__C': 0.004813113256345993, 'model__cla...</td>\n      <td>0.881578</td>\n      <td>0.880826</td>\n      <td>0.881686</td>\n      <td>0.882264</td>\n      <td>0.882937</td>\n      <td>0.881858</td>\n      <td>0.000707</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>69.926335</td>\n      <td>0.210122</td>\n      <td>0.112261</td>\n      <td>0.015613</td>\n      <td>0.038871</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>500</td>\n      <td>{'model__C': 0.03887079325988662, 'model__clas...</td>\n      <td>0.879023</td>\n      <td>0.880105</td>\n      <td>0.881664</td>\n      <td>0.880563</td>\n      <td>0.881274</td>\n      <td>0.880526</td>\n      <td>0.000927</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>671.042691</td>\n      <td>1.531498</td>\n      <td>0.099674</td>\n      <td>0.028682</td>\n      <td>0.26397</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 0.26396976812513734, 'model__clas...</td>\n      <td>0.879046</td>\n      <td>0.880041</td>\n      <td>0.881628</td>\n      <td>0.880584</td>\n      <td>0.881152</td>\n      <td>0.880490</td>\n      <td>0.000897</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>337.186943</td>\n      <td>0.696989</td>\n      <td>0.087318</td>\n      <td>0.007514</td>\n      <td>0.081173</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>2521</td>\n      <td>{'model__C': 0.08117259691282183, 'model__clas...</td>\n      <td>0.878938</td>\n      <td>0.880005</td>\n      <td>0.881636</td>\n      <td>0.880563</td>\n      <td>0.881231</td>\n      <td>0.880475</td>\n      <td>0.000950</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>426.694321</td>\n      <td>0.960507</td>\n      <td>0.081484</td>\n      <td>0.006134</td>\n      <td>0.459543</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>3060</td>\n      <td>{'model__C': 0.45954321027181433, 'model__clas...</td>\n      <td>0.879087</td>\n      <td>0.880154</td>\n      <td>0.881656</td>\n      <td>0.880283</td>\n      <td>0.881059</td>\n      <td>0.880448</td>\n      <td>0.000872</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>54.527078</td>\n      <td>9.390650</td>\n      <td>0.082766</td>\n      <td>0.009138</td>\n      <td>0.00674</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 0.006740278232626255, 'model__cla...</td>\n      <td>0.879418</td>\n      <td>0.879749</td>\n      <td>0.881596</td>\n      <td>0.880457</td>\n      <td>0.880928</td>\n      <td>0.880430</td>\n      <td>0.000787</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>50.422560</td>\n      <td>2.893474</td>\n      <td>0.112381</td>\n      <td>0.011798</td>\n      <td>0.006045</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>500</td>\n      <td>{'model__C': 0.006044645492859773, 'model__cla...</td>\n      <td>0.879382</td>\n      <td>0.879764</td>\n      <td>0.881632</td>\n      <td>0.880401</td>\n      <td>0.880907</td>\n      <td>0.880417</td>\n      <td>0.000802</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>704.579067</td>\n      <td>1.481194</td>\n      <td>0.092688</td>\n      <td>0.019104</td>\n      <td>1.130454</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 1.1304537728759494, 'model__class...</td>\n      <td>0.879346</td>\n      <td>0.879985</td>\n      <td>0.881460</td>\n      <td>0.880051</td>\n      <td>0.881000</td>\n      <td>0.880369</td>\n      <td>0.000760</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>73.453864</td>\n      <td>0.186641</td>\n      <td>0.081353</td>\n      <td>0.018345</td>\n      <td>0.121737</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>500</td>\n      <td>{'model__C': 0.12173717071547675, 'model__clas...</td>\n      <td>0.878979</td>\n      <td>0.880205</td>\n      <td>0.881492</td>\n      <td>0.880175</td>\n      <td>0.880925</td>\n      <td>0.880355</td>\n      <td>0.000844</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>26.026245</td>\n      <td>1.622022</td>\n      <td>0.104204</td>\n      <td>0.016086</td>\n      <td>0.003238</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>2901</td>\n      <td>{'model__C': 0.003238143906970181, 'model__cla...</td>\n      <td>0.879441</td>\n      <td>0.879708</td>\n      <td>0.881449</td>\n      <td>0.880188</td>\n      <td>0.880861</td>\n      <td>0.880329</td>\n      <td>0.000739</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>10.181759</td>\n      <td>0.554889</td>\n      <td>0.125934</td>\n      <td>0.022807</td>\n      <td>0.001043</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>500</td>\n      <td>{'model__C': 0.0010433193504394752, 'model__cl...</td>\n      <td>0.879447</td>\n      <td>0.879549</td>\n      <td>0.880992</td>\n      <td>0.880087</td>\n      <td>0.880512</td>\n      <td>0.880118</td>\n      <td>0.000582</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>6.709389</td>\n      <td>0.225541</td>\n      <td>0.092176</td>\n      <td>0.004685</td>\n      <td>0.000586</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 0.0005863758015860119, 'model__cl...</td>\n      <td>0.879857</td>\n      <td>0.879225</td>\n      <td>0.880709</td>\n      <td>0.879695</td>\n      <td>0.880192</td>\n      <td>0.879935</td>\n      <td>0.000497</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>6.199446</td>\n      <td>0.376596</td>\n      <td>0.099676</td>\n      <td>0.025890</td>\n      <td>0.001405</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>2697</td>\n      <td>{'model__C': 0.0014053795758951387, 'model__cl...</td>\n      <td>0.879345</td>\n      <td>0.878689</td>\n      <td>0.880570</td>\n      <td>0.881008</td>\n      <td>0.879381</td>\n      <td>0.879799</td>\n      <td>0.000857</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>4.105729</td>\n      <td>0.160150</td>\n      <td>0.106231</td>\n      <td>0.015323</td>\n      <td>0.000214</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>2730</td>\n      <td>{'model__C': 0.00021356215061759992, 'model__c...</td>\n      <td>0.878524</td>\n      <td>0.878848</td>\n      <td>0.880143</td>\n      <td>0.878466</td>\n      <td>0.878882</td>\n      <td>0.878972</td>\n      <td>0.000609</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>553.292869</td>\n      <td>0.780325</td>\n      <td>0.095806</td>\n      <td>0.015487</td>\n      <td>2.491309</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>3721</td>\n      <td>{'model__C': 2.491308632420524, 'model__class_...</td>\n      <td>0.879086</td>\n      <td>0.877277</td>\n      <td>0.878736</td>\n      <td>0.877208</td>\n      <td>0.878434</td>\n      <td>0.878148</td>\n      <td>0.000768</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>3.616593</td>\n      <td>0.032485</td>\n      <td>0.198605</td>\n      <td>0.011852</td>\n      <td>0.000096</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>500</td>\n      <td>{'model__C': 9.601709443113477e-05, 'model__cl...</td>\n      <td>0.876769</td>\n      <td>0.877248</td>\n      <td>0.878512</td>\n      <td>0.877551</td>\n      <td>0.877994</td>\n      <td>0.877615</td>\n      <td>0.000601</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>76.717862</td>\n      <td>0.155473</td>\n      <td>0.105587</td>\n      <td>0.013570</td>\n      <td>0.350239</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>500</td>\n      <td>{'model__C': 0.3502393891452447, 'model__class...</td>\n      <td>0.877201</td>\n      <td>0.878223</td>\n      <td>0.876580</td>\n      <td>0.878403</td>\n      <td>0.875174</td>\n      <td>0.877116</td>\n      <td>0.001179</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>5.925119</td>\n      <td>1.127531</td>\n      <td>0.118421</td>\n      <td>0.034701</td>\n      <td>0.000618</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 0.0006183813748776595, 'model__cl...</td>\n      <td>0.875809</td>\n      <td>0.876218</td>\n      <td>0.878063</td>\n      <td>0.877372</td>\n      <td>0.877598</td>\n      <td>0.877012</td>\n      <td>0.000855</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>3.510504</td>\n      <td>0.108804</td>\n      <td>0.130510</td>\n      <td>0.030450</td>\n      <td>0.000062</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 6.239539190529237e-05, 'model__cl...</td>\n      <td>0.876064</td>\n      <td>0.876538</td>\n      <td>0.877775</td>\n      <td>0.876647</td>\n      <td>0.877792</td>\n      <td>0.876963</td>\n      <td>0.000698</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>3.109341</td>\n      <td>0.035431</td>\n      <td>0.178220</td>\n      <td>0.010656</td>\n      <td>0.000485</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>500</td>\n      <td>{'model__C': 0.00048547084465555573, 'model__c...</td>\n      <td>0.874697</td>\n      <td>0.874909</td>\n      <td>0.877204</td>\n      <td>0.877044</td>\n      <td>0.876967</td>\n      <td>0.876164</td>\n      <td>0.001116</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>613.262495</td>\n      <td>0.784190</td>\n      <td>0.102618</td>\n      <td>0.024211</td>\n      <td>3.156225</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>4112</td>\n      <td>{'model__C': 3.1562246465541888, 'model__class...</td>\n      <td>0.875531</td>\n      <td>0.873759</td>\n      <td>0.875420</td>\n      <td>0.876503</td>\n      <td>0.875322</td>\n      <td>0.875307</td>\n      <td>0.000882</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>3.537884</td>\n      <td>0.143888</td>\n      <td>0.127483</td>\n      <td>0.025831</td>\n      <td>0.000076</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>4856</td>\n      <td>{'model__C': 7.605225223648453e-05, 'model__cl...</td>\n      <td>0.861732</td>\n      <td>0.861345</td>\n      <td>0.864796</td>\n      <td>0.863012</td>\n      <td>0.862944</td>\n      <td>0.862766</td>\n      <td>0.001208</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>2.982127</td>\n      <td>0.428373</td>\n      <td>0.098149</td>\n      <td>0.017387</td>\n      <td>0.000032</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>500</td>\n      <td>{'model__C': 3.165606599337715e-05, 'model__cl...</td>\n      <td>0.855074</td>\n      <td>0.854831</td>\n      <td>0.858475</td>\n      <td>0.855066</td>\n      <td>0.856272</td>\n      <td>0.855944</td>\n      <td>0.001363</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>754.463311</td>\n      <td>0.632445</td>\n      <td>0.106528</td>\n      <td>0.024238</td>\n      <td>19.190776</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>4991</td>\n      <td>{'model__C': 19.190776178531312, 'model__class...</td>\n      <td>0.825028</td>\n      <td>0.838569</td>\n      <td>0.827313</td>\n      <td>0.839358</td>\n      <td>0.834100</td>\n      <td>0.832874</td>\n      <td>0.005805</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>51.229421</td>\n      <td>0.262132</td>\n      <td>0.103901</td>\n      <td>0.019237</td>\n      <td>0.086424</td>\n      <td>balanced</td>\n      <td>hinge</td>\n      <td>4434</td>\n      <td>{'model__C': 0.08642410048155082, 'model__clas...</td>\n      <td>0.831175</td>\n      <td>0.832855</td>\n      <td>0.831931</td>\n      <td>0.830593</td>\n      <td>0.831549</td>\n      <td>0.831621</td>\n      <td>0.000759</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>19.466794</td>\n      <td>0.180296</td>\n      <td>0.093759</td>\n      <td>0.009882</td>\n      <td>0.022245</td>\n      <td>balanced</td>\n      <td>hinge</td>\n      <td>4269</td>\n      <td>{'model__C': 0.022244596968016832, 'model__cla...</td>\n      <td>0.831413</td>\n      <td>0.832437</td>\n      <td>0.832425</td>\n      <td>0.830435</td>\n      <td>0.830939</td>\n      <td>0.831530</td>\n      <td>0.000798</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>159.681896</td>\n      <td>0.847766</td>\n      <td>0.096924</td>\n      <td>0.017299</td>\n      <td>0.745116</td>\n      <td>balanced</td>\n      <td>hinge</td>\n      <td>1348</td>\n      <td>{'model__C': 0.7451164370027008, 'model__class...</td>\n      <td>0.831197</td>\n      <td>0.830718</td>\n      <td>0.832438</td>\n      <td>0.829093</td>\n      <td>0.830200</td>\n      <td>0.830729</td>\n      <td>0.001104</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.931138</td>\n      <td>0.112161</td>\n      <td>0.106308</td>\n      <td>0.015392</td>\n      <td>0.00362</td>\n      <td>balanced</td>\n      <td>hinge</td>\n      <td>2450</td>\n      <td>{'model__C': 0.003619595990038508, 'model__cla...</td>\n      <td>0.830317</td>\n      <td>0.831122</td>\n      <td>0.832127</td>\n      <td>0.829261</td>\n      <td>0.829518</td>\n      <td>0.830469</td>\n      <td>0.001055</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>640.397510</td>\n      <td>0.448489</td>\n      <td>0.094972</td>\n      <td>0.010590</td>\n      <td>5.001576</td>\n      <td>balanced</td>\n      <td>hinge</td>\n      <td>4781</td>\n      <td>{'model__C': 5.001575677983704, 'model__class_...</td>\n      <td>0.827334</td>\n      <td>0.830760</td>\n      <td>0.829129</td>\n      <td>0.827239</td>\n      <td>0.828813</td>\n      <td>0.828655</td>\n      <td>0.001299</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>616.517097</td>\n      <td>1.007811</td>\n      <td>0.094654</td>\n      <td>0.021616</td>\n      <td>0.150903</td>\n      <td>balanced</td>\n      <td>squared_hinge</td>\n      <td>4246</td>\n      <td>{'model__C': 0.15090267940935065, 'model__clas...</td>\n      <td>0.825094</td>\n      <td>0.827138</td>\n      <td>0.828343</td>\n      <td>0.823516</td>\n      <td>0.823768</td>\n      <td>0.825572</td>\n      <td>0.001889</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>22.415431</td>\n      <td>1.355501</td>\n      <td>0.095111</td>\n      <td>0.017102</td>\n      <td>0.001909</td>\n      <td>balanced</td>\n      <td>squared_hinge</td>\n      <td>1921</td>\n      <td>{'model__C': 0.0019091131576909443, 'model__cl...</td>\n      <td>0.825322</td>\n      <td>0.827007</td>\n      <td>0.827450</td>\n      <td>0.823443</td>\n      <td>0.823646</td>\n      <td>0.825374</td>\n      <td>0.001655</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>79.585758</td>\n      <td>0.157060</td>\n      <td>0.121877</td>\n      <td>0.018225</td>\n      <td>2.576424</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>513</td>\n      <td>{'model__C': 2.576423799733396, 'model__class_...</td>\n      <td>0.831415</td>\n      <td>0.818033</td>\n      <td>0.822409</td>\n      <td>0.816078</td>\n      <td>0.825342</td>\n      <td>0.822655</td>\n      <td>0.005452</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>3.730349</td>\n      <td>0.118625</td>\n      <td>0.125002</td>\n      <td>0.009875</td>\n      <td>0.000067</td>\n      <td>balanced</td>\n      <td>squared_hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 6.671270500639629e-05, 'model__cl...</td>\n      <td>0.817673</td>\n      <td>0.818783</td>\n      <td>0.820520</td>\n      <td>0.812560</td>\n      <td>0.815722</td>\n      <td>0.817052</td>\n      <td>0.002733</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>621.730066</td>\n      <td>0.386899</td>\n      <td>0.079338</td>\n      <td>0.010154</td>\n      <td>99.334634</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>4103</td>\n      <td>{'model__C': 99.33463392847965, 'model__class_...</td>\n      <td>0.812772</td>\n      <td>0.812948</td>\n      <td>0.806522</td>\n      <td>0.804379</td>\n      <td>0.801151</td>\n      <td>0.807554</td>\n      <td>0.004658</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>361.046766</td>\n      <td>0.392778</td>\n      <td>0.103269</td>\n      <td>0.025414</td>\n      <td>44.037625</td>\n      <td>balanced</td>\n      <td>squared_hinge</td>\n      <td>2371</td>\n      <td>{'model__C': 44.037625157309144, 'model__class...</td>\n      <td>0.792139</td>\n      <td>0.763830</td>\n      <td>0.814554</td>\n      <td>0.756638</td>\n      <td>0.809883</td>\n      <td>0.787409</td>\n      <td>0.023525</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4.134569</td>\n      <td>0.022969</td>\n      <td>0.181245</td>\n      <td>0.012526</td>\n      <td>0.000001</td>\n      <td>balanced</td>\n      <td>squared_hinge</td>\n      <td>1645</td>\n      <td>{'model__C': 1.0691593986059968e-06, 'model__c...</td>\n      <td>0.723185</td>\n      <td>0.724696</td>\n      <td>0.731959</td>\n      <td>0.725389</td>\n      <td>0.721253</td>\n      <td>0.725296</td>\n      <td>0.003621</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2.300901</td>\n      <td>0.087070</td>\n      <td>0.150464</td>\n      <td>0.012353</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>4849</td>\n      <td>{'model__C': 1e-06, 'model__class_weight': Non...</td>\n      <td>0.712968</td>\n      <td>0.711833</td>\n      <td>0.723109</td>\n      <td>0.718041</td>\n      <td>0.713101</td>\n      <td>0.715810</td>\n      <td>0.004231</td>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_grid_search_dataframe = pd.DataFrame(\n",
    "    np.load(\"Dataset_Files/Baseline_Models/Classification/optimised_lsvc_cv_results.npy\", allow_pickle=True).tolist())\n",
    "lsvc_grid_search_dataframe.sort_values(by=[\"rank_test_score\"], inplace=True)\n",
    "lsvc_grid_search_dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 500\n",
      "--------------------------------------------------------\n",
      "Median Recall: 0.88 with a 95% confidence interval of [0.84,0.91]\n",
      "Median Precision: 0.77 with a 95% confidence interval of [0.73,0.81]\n",
      "Median F1: 0.82 with a 95% confidence interval of [0.79,0.85]\n",
      "Median Accuracy: 0.74 with a 95% confidence interval of [0.69,0.77]\n",
      "Median MCC: 0.33 with a 95% confidence interval of [0.23,0.42]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_lsvc, X_test, y_test, 500, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K-Nearest Neighbors Classifier (KNNC)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()), ('model', KNeighborsClassifier())],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': KNeighborsClassifier(),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__algorithm': 'auto',\n 'model__leaf_size': 30,\n 'model__metric': 'minkowski',\n 'model__metric_params': None,\n 'model__n_jobs': None,\n 'model__n_neighbors': 5,\n 'model__p': 2,\n 'model__weights': 'uniform'}"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scale', StandardScaler()),\n",
    "        ('model', KNeighborsClassifier())\n",
    "    ]\n",
    ")\n",
    "pipe.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "model = BayesSearchCV(estimator=pipe,\n",
    "                      search_spaces=\n",
    "                      {'model__n_neighbors': Integer(4, 20),\n",
    "                       'model__weights': Categorical(['uniform', 'distance']),\n",
    "                       'model__algorithm': Categorical(['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "                       },\n",
    "                      scoring='f1',\n",
    "                      cv=5,\n",
    "                      error_score=np.nan,\n",
    "                      n_jobs=-1,\n",
    "                      pre_dispatch='2*n_jobs',\n",
    "                      random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# index = 1\n",
    "# model.fit(X_train, y_train, callback=on_step)\n",
    "#\n",
    "# optimised_knnc = model.best_estimator_\n",
    "#\n",
    "# y_train_pred = optimised_knnc.predict(X_train)\n",
    "# calculate_metrics_classification(y_train, y_train_pred)\n",
    "#\n",
    "# # Save Model & CV Results\n",
    "# dump(optimised_knnc, 'Dataset_Files/Baseline_Models/Classification/optimised_knnc.joblib')\n",
    "# np.save(\"Dataset_Files/Baseline_Models/Classification/optimised_knnc_cv_results.npy\", model.cv_results_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Load Model\n",
    "optimised_knnc = load('Dataset_Files/Baseline_Models/Classification/optimised_knnc.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 1000\n",
      "--------------------------------------------------------\n",
      "Median Recall: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median Precision: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median F1: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median Accuracy: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median MCC: 1.00 with a 95% confidence interval of [1.00,1.00]\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"Dataset_Files/Baseline_Models/Classification/optimised_knnc_train_metrics.txt\"):\n",
    "    with open(\"Dataset_Files/Baseline_Models/Classification/optimised_knnc_train_metrics.txt\", \"r\") as file:\n",
    "        print(file.read())\n",
    "else:\n",
    "    get_confidence_intervals(optimised_knnc, X_train, y_train, 1000, \"Classification\", print_iterator=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model',\n   KNeighborsClassifier(algorithm='kd_tree', n_neighbors=6, weights='distance'))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': KNeighborsClassifier(algorithm='kd_tree', n_neighbors=6, weights='distance'),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__algorithm': 'kd_tree',\n 'model__leaf_size': 30,\n 'model__metric': 'minkowski',\n 'model__metric_params': None,\n 'model__n_jobs': None,\n 'model__n_neighbors': 6,\n 'model__p': 2,\n 'model__weights': 'distance'}"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimised_knnc.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n49       3.604291      0.097547       757.737860       25.242931   \n15       3.629958      0.080214       709.126471       12.281687   \n33       0.802446      0.118402         9.522272        0.100709   \n35       3.610951      0.094378       750.344408       41.719547   \n36       0.837429      0.040939         9.372987        0.132019   \n31       0.800072      0.107493         9.454483        0.084098   \n43       3.604221      0.117799       759.601214       13.977584   \n44       0.834071      0.053298         9.468205        0.066967   \n45       3.643211      0.050724       708.767467       15.428243   \n47       0.786727      0.089076         9.471032        0.045987   \n20       3.739042      0.105781       646.442069       23.990349   \n12       0.844805      0.063028        11.347060        0.469916   \n13       4.825671      0.644733       618.078259       10.927762   \n16       3.462461      0.158115      1484.698528       65.987110   \n30       3.618991      0.072378       798.738130       31.254754   \n14       0.826711      0.065383         9.429964        0.101993   \n23       3.650966      0.062360       887.859800       35.547599   \n29       3.838287      0.133394       865.229046       39.478508   \n34       0.800227      0.077730         9.613662        0.078528   \n11       3.680395      0.083073      1033.304241       26.288778   \n37       0.806139      0.078487         9.562158        0.106631   \n25       0.802841      0.080136         9.553687        0.108988   \n24       0.806668      0.079223         9.494308        0.066486   \n27       0.832036      0.061938         9.818816        0.119300   \n41       3.613422      0.075743      1009.713103       35.284644   \n21       0.824192      0.052333         9.495814        0.074938   \n6        0.820453      0.091314         9.523354        0.128206   \n10       0.815254      0.079505         9.845857        0.062759   \n22       3.748479      0.126856       619.882970        5.701544   \n3        0.813562      0.134702         9.700144        0.037504   \n40       3.766723      0.129931       703.990595       33.017934   \n46       0.822874      0.078201         9.518140        0.088457   \n1        3.817454      0.131383      1069.596490       14.268449   \n42       3.566399      0.084287       833.203025       19.021186   \n2        3.290150      0.246332      1502.191075       98.844789   \n5        0.844000      0.057345         9.597870        0.105102   \n7        0.835400      0.067543         9.469249        0.060715   \n28       3.704356      0.089816      1103.301155       44.189361   \n26       0.834374      0.069718         9.738489        0.063404   \n48       3.801198      0.114209       905.020984       16.122923   \n4        0.811790      0.078214         9.974040        0.165639   \n19       3.287191      0.103684      1461.377380       77.773976   \n32       3.662197      0.135928       896.900370        8.341091   \n18       0.783073      0.126450         9.711746        0.085562   \n8        3.829689      0.122632      1085.876165       35.600886   \n0        3.505279      0.127642      1573.930819       46.199141   \n9        0.852999      0.072944         9.645307        0.097676   \n38       3.661122      0.101505      1069.713923       44.167479   \n17       3.625975      0.095549      1106.628634       26.090674   \n39       0.825013      0.052824         9.673314        0.095813   \n\n   param_model__algorithm param_model__n_neighbors param_model__weights  \\\n49                kd_tree                        6             distance   \n15                kd_tree                        6             distance   \n33                   auto                        6             distance   \n35                kd_tree                        6             distance   \n36                   auto                        6             distance   \n31                   auto                        6             distance   \n43                kd_tree                        6             distance   \n44                   auto                        6             distance   \n45                kd_tree                        6             distance   \n47                   auto                        6             distance   \n20                kd_tree                        4             distance   \n12                   auto                        4             distance   \n13                kd_tree                        4             distance   \n16              ball_tree                        5             distance   \n30                kd_tree                        7             distance   \n14                   auto                        8             distance   \n23                kd_tree                       10             distance   \n29                kd_tree                        9             distance   \n34                   auto                       11             distance   \n11                kd_tree                       12             distance   \n37                   auto                       13             distance   \n25                  brute                       14             distance   \n24                   auto                       14             distance   \n27                   auto                        5              uniform   \n41                kd_tree                       15             distance   \n21                   auto                       16             distance   \n6                   brute                       16             distance   \n10                   auto                        4              uniform   \n22                kd_tree                        4              uniform   \n3                   brute                        7              uniform   \n40                kd_tree                        6              uniform   \n46                   auto                       17             distance   \n1                 kd_tree                       18             distance   \n42                kd_tree                        8              uniform   \n2               ball_tree                       19             distance   \n5                   brute                       19             distance   \n7                   brute                       19             distance   \n28                kd_tree                       20             distance   \n26                   auto                        9              uniform   \n48                kd_tree                       10              uniform   \n4                   brute                       11              uniform   \n19              ball_tree                       11              uniform   \n32                kd_tree                       12              uniform   \n18                  brute                       14              uniform   \n8                 kd_tree                       15              uniform   \n0               ball_tree                       16              uniform   \n9                    auto                       17              uniform   \n38                kd_tree                       18              uniform   \n17                kd_tree                       20              uniform   \n39                   auto                       20              uniform   \n\n                                               params  split0_test_score  \\\n49  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.939270   \n15  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.939270   \n33  {'model__algorithm': 'auto', 'model__n_neighbo...           0.939270   \n35  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.939270   \n36  {'model__algorithm': 'auto', 'model__n_neighbo...           0.939270   \n31  {'model__algorithm': 'auto', 'model__n_neighbo...           0.939270   \n43  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.939270   \n44  {'model__algorithm': 'auto', 'model__n_neighbo...           0.939270   \n45  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.939270   \n47  {'model__algorithm': 'auto', 'model__n_neighbo...           0.939270   \n20  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.939290   \n12  {'model__algorithm': 'auto', 'model__n_neighbo...           0.939290   \n13  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.939290   \n16  {'model__algorithm': 'ball_tree', 'model__n_ne...           0.939725   \n30  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.939031   \n14  {'model__algorithm': 'auto', 'model__n_neighbo...           0.939777   \n23  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.938953   \n29  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.938413   \n34  {'model__algorithm': 'auto', 'model__n_neighbo...           0.937851   \n11  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.937903   \n37  {'model__algorithm': 'auto', 'model__n_neighbo...           0.936606   \n25  {'model__algorithm': 'brute', 'model__n_neighb...           0.936412   \n24  {'model__algorithm': 'auto', 'model__n_neighbo...           0.936412   \n27  {'model__algorithm': 'auto', 'model__n_neighbo...           0.935727   \n41  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.935189   \n21  {'model__algorithm': 'auto', 'model__n_neighbo...           0.935441   \n6   {'model__algorithm': 'brute', 'model__n_neighb...           0.935441   \n10  {'model__algorithm': 'auto', 'model__n_neighbo...           0.932611   \n22  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.932611   \n3   {'model__algorithm': 'brute', 'model__n_neighb...           0.934416   \n40  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.933766   \n46  {'model__algorithm': 'auto', 'model__n_neighbo...           0.933735   \n1   {'model__algorithm': 'kd_tree', 'model__n_neig...           0.934009   \n42  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.932634   \n2   {'model__algorithm': 'ball_tree', 'model__n_ne...           0.932945   \n5   {'model__algorithm': 'brute', 'model__n_neighb...           0.932945   \n7   {'model__algorithm': 'brute', 'model__n_neighb...           0.932945   \n28  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.932782   \n26  {'model__algorithm': 'auto', 'model__n_neighbo...           0.932130   \n48  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.931119   \n4   {'model__algorithm': 'brute', 'model__n_neighb...           0.931177   \n19  {'model__algorithm': 'ball_tree', 'model__n_ne...           0.931177   \n32  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.930004   \n18  {'model__algorithm': 'brute', 'model__n_neighb...           0.928376   \n8   {'model__algorithm': 'kd_tree', 'model__n_neig...           0.927294   \n0   {'model__algorithm': 'ball_tree', 'model__n_ne...           0.924548   \n9   {'model__algorithm': 'auto', 'model__n_neighbo...           0.923769   \n38  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.921478   \n17  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.920265   \n39  {'model__algorithm': 'auto', 'model__n_neighbo...           0.920265   \n\n    split1_test_score  split2_test_score  split3_test_score  \\\n49           0.935738           0.938946           0.939656   \n15           0.935738           0.938946           0.939656   \n33           0.935738           0.938946           0.939656   \n35           0.935738           0.938946           0.939656   \n36           0.935738           0.938946           0.939656   \n31           0.935738           0.938946           0.939656   \n43           0.935738           0.938946           0.939656   \n44           0.935738           0.938946           0.939656   \n45           0.935738           0.938946           0.939656   \n47           0.935738           0.938946           0.939656   \n20           0.936396           0.938866           0.939069   \n12           0.936396           0.938866           0.939069   \n13           0.936396           0.938866           0.939069   \n16           0.935901           0.937638           0.938979   \n30           0.935222           0.937983           0.940183   \n14           0.935052           0.937849           0.939784   \n23           0.933740           0.936559           0.939320   \n29           0.933878           0.936567           0.939326   \n34           0.933360           0.935617           0.937552   \n11           0.933227           0.935678           0.937527   \n37           0.932340           0.934465           0.935872   \n25           0.932234           0.933921           0.935885   \n24           0.932234           0.933921           0.935885   \n27           0.932425           0.934061           0.935727   \n41           0.931671           0.933051           0.935074   \n21           0.931569           0.932897           0.934311   \n6            0.931569           0.932897           0.934311   \n10           0.932297           0.932753           0.934665   \n22           0.932297           0.932753           0.934628   \n3            0.930706           0.933125           0.935406   \n40           0.930913           0.933414           0.934320   \n46           0.930760           0.932152           0.933555   \n1            0.930437           0.931954           0.933218   \n42           0.929363           0.932189           0.933253   \n2            0.929893           0.931334           0.932458   \n5            0.929893           0.931334           0.932458   \n7            0.929893           0.931334           0.932458   \n28           0.929844           0.931585           0.931998   \n26           0.928460           0.930870           0.933865   \n48           0.927041           0.929792           0.931881   \n4            0.927483           0.928900           0.931682   \n19           0.927483           0.928900           0.931682   \n32           0.925757           0.927993           0.929044   \n18           0.924034           0.926037           0.926186   \n8            0.923748           0.924235           0.926395   \n0            0.920714           0.922550           0.923910   \n9            0.920643           0.921457           0.923798   \n38           0.919248           0.919605           0.921277   \n17           0.917406           0.918084           0.920437   \n39           0.917406           0.918084           0.920437   \n\n    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n49           0.938927         0.938507        0.001410                1  \n15           0.938927         0.938507        0.001410                1  \n33           0.938927         0.938507        0.001410                1  \n35           0.938927         0.938507        0.001410                1  \n36           0.938927         0.938507        0.001410                1  \n31           0.938927         0.938507        0.001410                1  \n43           0.938927         0.938507        0.001410                1  \n44           0.938927         0.938507        0.001410                1  \n45           0.938927         0.938507        0.001410                1  \n47           0.938927         0.938507        0.001410                1  \n20           0.938829         0.938490        0.001060               11  \n12           0.938829         0.938490        0.001060               11  \n13           0.938829         0.938490        0.001060               11  \n16           0.938336         0.938116        0.001305               14  \n30           0.937214         0.937927        0.001681               15  \n14           0.937020         0.937896        0.001787               16  \n23           0.936705         0.937056        0.002005               17  \n29           0.936335         0.936904        0.001884               18  \n34           0.934912         0.935858        0.001675               19  \n11           0.934853         0.935838        0.001728               20  \n37           0.934162         0.934689        0.001478               21  \n25           0.933887         0.934468        0.001511               22  \n24           0.933887         0.934468        0.001511               22  \n27           0.934326         0.934453        0.001227               24  \n41           0.933462         0.933689        0.001319               25  \n21           0.932807         0.933405        0.001338               26  \n6            0.932807         0.933405        0.001338               26  \n10           0.933424         0.933150        0.000842               28  \n22           0.933424         0.933143        0.000829               29  \n3            0.931961         0.933123        0.001678               30  \n40           0.931923         0.932867        0.001259               31  \n46           0.932630         0.932567        0.001075               32  \n1            0.931880         0.932300        0.001227               33  \n42           0.931222         0.931732        0.001357               34  \n2            0.931646         0.931655        0.001050               35  \n5            0.931646         0.931655        0.001050               35  \n7            0.931646         0.931655        0.001050               35  \n28           0.931451         0.931532        0.000963               38  \n26           0.931344         0.931334        0.001761               39  \n48           0.929050         0.929777        0.001688               40  \n4            0.928818         0.929612        0.001575               41  \n19           0.928818         0.929612        0.001575               41  \n32           0.927540         0.928068        0.001437               43  \n18           0.925522         0.926031        0.001398               44  \n8            0.925289         0.925392        0.001317               45  \n0            0.923097         0.922964        0.001316               46  \n9            0.922358         0.922405        0.001249               47  \n38           0.919602         0.920242        0.000938               48  \n17           0.918710         0.918980        0.001194               49  \n39           0.918710         0.918980        0.001194               49  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_model__algorithm</th>\n      <th>param_model__n_neighbors</th>\n      <th>param_model__weights</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>49</th>\n      <td>3.604291</td>\n      <td>0.097547</td>\n      <td>757.737860</td>\n      <td>25.242931</td>\n      <td>kd_tree</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>3.629958</td>\n      <td>0.080214</td>\n      <td>709.126471</td>\n      <td>12.281687</td>\n      <td>kd_tree</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0.802446</td>\n      <td>0.118402</td>\n      <td>9.522272</td>\n      <td>0.100709</td>\n      <td>auto</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>3.610951</td>\n      <td>0.094378</td>\n      <td>750.344408</td>\n      <td>41.719547</td>\n      <td>kd_tree</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0.837429</td>\n      <td>0.040939</td>\n      <td>9.372987</td>\n      <td>0.132019</td>\n      <td>auto</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0.800072</td>\n      <td>0.107493</td>\n      <td>9.454483</td>\n      <td>0.084098</td>\n      <td>auto</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>3.604221</td>\n      <td>0.117799</td>\n      <td>759.601214</td>\n      <td>13.977584</td>\n      <td>kd_tree</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>0.834071</td>\n      <td>0.053298</td>\n      <td>9.468205</td>\n      <td>0.066967</td>\n      <td>auto</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>3.643211</td>\n      <td>0.050724</td>\n      <td>708.767467</td>\n      <td>15.428243</td>\n      <td>kd_tree</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>0.786727</td>\n      <td>0.089076</td>\n      <td>9.471032</td>\n      <td>0.045987</td>\n      <td>auto</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>3.739042</td>\n      <td>0.105781</td>\n      <td>646.442069</td>\n      <td>23.990349</td>\n      <td>kd_tree</td>\n      <td>4</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.939290</td>\n      <td>0.936396</td>\n      <td>0.938866</td>\n      <td>0.939069</td>\n      <td>0.938829</td>\n      <td>0.938490</td>\n      <td>0.001060</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.844805</td>\n      <td>0.063028</td>\n      <td>11.347060</td>\n      <td>0.469916</td>\n      <td>auto</td>\n      <td>4</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.939290</td>\n      <td>0.936396</td>\n      <td>0.938866</td>\n      <td>0.939069</td>\n      <td>0.938829</td>\n      <td>0.938490</td>\n      <td>0.001060</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>4.825671</td>\n      <td>0.644733</td>\n      <td>618.078259</td>\n      <td>10.927762</td>\n      <td>kd_tree</td>\n      <td>4</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.939290</td>\n      <td>0.936396</td>\n      <td>0.938866</td>\n      <td>0.939069</td>\n      <td>0.938829</td>\n      <td>0.938490</td>\n      <td>0.001060</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>3.462461</td>\n      <td>0.158115</td>\n      <td>1484.698528</td>\n      <td>65.987110</td>\n      <td>ball_tree</td>\n      <td>5</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'ball_tree', 'model__n_ne...</td>\n      <td>0.939725</td>\n      <td>0.935901</td>\n      <td>0.937638</td>\n      <td>0.938979</td>\n      <td>0.938336</td>\n      <td>0.938116</td>\n      <td>0.001305</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>3.618991</td>\n      <td>0.072378</td>\n      <td>798.738130</td>\n      <td>31.254754</td>\n      <td>kd_tree</td>\n      <td>7</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.939031</td>\n      <td>0.935222</td>\n      <td>0.937983</td>\n      <td>0.940183</td>\n      <td>0.937214</td>\n      <td>0.937927</td>\n      <td>0.001681</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.826711</td>\n      <td>0.065383</td>\n      <td>9.429964</td>\n      <td>0.101993</td>\n      <td>auto</td>\n      <td>8</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.939777</td>\n      <td>0.935052</td>\n      <td>0.937849</td>\n      <td>0.939784</td>\n      <td>0.937020</td>\n      <td>0.937896</td>\n      <td>0.001787</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>3.650966</td>\n      <td>0.062360</td>\n      <td>887.859800</td>\n      <td>35.547599</td>\n      <td>kd_tree</td>\n      <td>10</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.938953</td>\n      <td>0.933740</td>\n      <td>0.936559</td>\n      <td>0.939320</td>\n      <td>0.936705</td>\n      <td>0.937056</td>\n      <td>0.002005</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>3.838287</td>\n      <td>0.133394</td>\n      <td>865.229046</td>\n      <td>39.478508</td>\n      <td>kd_tree</td>\n      <td>9</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.938413</td>\n      <td>0.933878</td>\n      <td>0.936567</td>\n      <td>0.939326</td>\n      <td>0.936335</td>\n      <td>0.936904</td>\n      <td>0.001884</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>0.800227</td>\n      <td>0.077730</td>\n      <td>9.613662</td>\n      <td>0.078528</td>\n      <td>auto</td>\n      <td>11</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.937851</td>\n      <td>0.933360</td>\n      <td>0.935617</td>\n      <td>0.937552</td>\n      <td>0.934912</td>\n      <td>0.935858</td>\n      <td>0.001675</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3.680395</td>\n      <td>0.083073</td>\n      <td>1033.304241</td>\n      <td>26.288778</td>\n      <td>kd_tree</td>\n      <td>12</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.937903</td>\n      <td>0.933227</td>\n      <td>0.935678</td>\n      <td>0.937527</td>\n      <td>0.934853</td>\n      <td>0.935838</td>\n      <td>0.001728</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>0.806139</td>\n      <td>0.078487</td>\n      <td>9.562158</td>\n      <td>0.106631</td>\n      <td>auto</td>\n      <td>13</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.936606</td>\n      <td>0.932340</td>\n      <td>0.934465</td>\n      <td>0.935872</td>\n      <td>0.934162</td>\n      <td>0.934689</td>\n      <td>0.001478</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.802841</td>\n      <td>0.080136</td>\n      <td>9.553687</td>\n      <td>0.108988</td>\n      <td>brute</td>\n      <td>14</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'brute', 'model__n_neighb...</td>\n      <td>0.936412</td>\n      <td>0.932234</td>\n      <td>0.933921</td>\n      <td>0.935885</td>\n      <td>0.933887</td>\n      <td>0.934468</td>\n      <td>0.001511</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.806668</td>\n      <td>0.079223</td>\n      <td>9.494308</td>\n      <td>0.066486</td>\n      <td>auto</td>\n      <td>14</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.936412</td>\n      <td>0.932234</td>\n      <td>0.933921</td>\n      <td>0.935885</td>\n      <td>0.933887</td>\n      <td>0.934468</td>\n      <td>0.001511</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.832036</td>\n      <td>0.061938</td>\n      <td>9.818816</td>\n      <td>0.119300</td>\n      <td>auto</td>\n      <td>5</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.935727</td>\n      <td>0.932425</td>\n      <td>0.934061</td>\n      <td>0.935727</td>\n      <td>0.934326</td>\n      <td>0.934453</td>\n      <td>0.001227</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>3.613422</td>\n      <td>0.075743</td>\n      <td>1009.713103</td>\n      <td>35.284644</td>\n      <td>kd_tree</td>\n      <td>15</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.935189</td>\n      <td>0.931671</td>\n      <td>0.933051</td>\n      <td>0.935074</td>\n      <td>0.933462</td>\n      <td>0.933689</td>\n      <td>0.001319</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.824192</td>\n      <td>0.052333</td>\n      <td>9.495814</td>\n      <td>0.074938</td>\n      <td>auto</td>\n      <td>16</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.935441</td>\n      <td>0.931569</td>\n      <td>0.932897</td>\n      <td>0.934311</td>\n      <td>0.932807</td>\n      <td>0.933405</td>\n      <td>0.001338</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.820453</td>\n      <td>0.091314</td>\n      <td>9.523354</td>\n      <td>0.128206</td>\n      <td>brute</td>\n      <td>16</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'brute', 'model__n_neighb...</td>\n      <td>0.935441</td>\n      <td>0.931569</td>\n      <td>0.932897</td>\n      <td>0.934311</td>\n      <td>0.932807</td>\n      <td>0.933405</td>\n      <td>0.001338</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.815254</td>\n      <td>0.079505</td>\n      <td>9.845857</td>\n      <td>0.062759</td>\n      <td>auto</td>\n      <td>4</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.932611</td>\n      <td>0.932297</td>\n      <td>0.932753</td>\n      <td>0.934665</td>\n      <td>0.933424</td>\n      <td>0.933150</td>\n      <td>0.000842</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>3.748479</td>\n      <td>0.126856</td>\n      <td>619.882970</td>\n      <td>5.701544</td>\n      <td>kd_tree</td>\n      <td>4</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.932611</td>\n      <td>0.932297</td>\n      <td>0.932753</td>\n      <td>0.934628</td>\n      <td>0.933424</td>\n      <td>0.933143</td>\n      <td>0.000829</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.813562</td>\n      <td>0.134702</td>\n      <td>9.700144</td>\n      <td>0.037504</td>\n      <td>brute</td>\n      <td>7</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'brute', 'model__n_neighb...</td>\n      <td>0.934416</td>\n      <td>0.930706</td>\n      <td>0.933125</td>\n      <td>0.935406</td>\n      <td>0.931961</td>\n      <td>0.933123</td>\n      <td>0.001678</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>3.766723</td>\n      <td>0.129931</td>\n      <td>703.990595</td>\n      <td>33.017934</td>\n      <td>kd_tree</td>\n      <td>6</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.933766</td>\n      <td>0.930913</td>\n      <td>0.933414</td>\n      <td>0.934320</td>\n      <td>0.931923</td>\n      <td>0.932867</td>\n      <td>0.001259</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>0.822874</td>\n      <td>0.078201</td>\n      <td>9.518140</td>\n      <td>0.088457</td>\n      <td>auto</td>\n      <td>17</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.933735</td>\n      <td>0.930760</td>\n      <td>0.932152</td>\n      <td>0.933555</td>\n      <td>0.932630</td>\n      <td>0.932567</td>\n      <td>0.001075</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.817454</td>\n      <td>0.131383</td>\n      <td>1069.596490</td>\n      <td>14.268449</td>\n      <td>kd_tree</td>\n      <td>18</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.934009</td>\n      <td>0.930437</td>\n      <td>0.931954</td>\n      <td>0.933218</td>\n      <td>0.931880</td>\n      <td>0.932300</td>\n      <td>0.001227</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>3.566399</td>\n      <td>0.084287</td>\n      <td>833.203025</td>\n      <td>19.021186</td>\n      <td>kd_tree</td>\n      <td>8</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.932634</td>\n      <td>0.929363</td>\n      <td>0.932189</td>\n      <td>0.933253</td>\n      <td>0.931222</td>\n      <td>0.931732</td>\n      <td>0.001357</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.290150</td>\n      <td>0.246332</td>\n      <td>1502.191075</td>\n      <td>98.844789</td>\n      <td>ball_tree</td>\n      <td>19</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'ball_tree', 'model__n_ne...</td>\n      <td>0.932945</td>\n      <td>0.929893</td>\n      <td>0.931334</td>\n      <td>0.932458</td>\n      <td>0.931646</td>\n      <td>0.931655</td>\n      <td>0.001050</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.844000</td>\n      <td>0.057345</td>\n      <td>9.597870</td>\n      <td>0.105102</td>\n      <td>brute</td>\n      <td>19</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'brute', 'model__n_neighb...</td>\n      <td>0.932945</td>\n      <td>0.929893</td>\n      <td>0.931334</td>\n      <td>0.932458</td>\n      <td>0.931646</td>\n      <td>0.931655</td>\n      <td>0.001050</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.835400</td>\n      <td>0.067543</td>\n      <td>9.469249</td>\n      <td>0.060715</td>\n      <td>brute</td>\n      <td>19</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'brute', 'model__n_neighb...</td>\n      <td>0.932945</td>\n      <td>0.929893</td>\n      <td>0.931334</td>\n      <td>0.932458</td>\n      <td>0.931646</td>\n      <td>0.931655</td>\n      <td>0.001050</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>3.704356</td>\n      <td>0.089816</td>\n      <td>1103.301155</td>\n      <td>44.189361</td>\n      <td>kd_tree</td>\n      <td>20</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.932782</td>\n      <td>0.929844</td>\n      <td>0.931585</td>\n      <td>0.931998</td>\n      <td>0.931451</td>\n      <td>0.931532</td>\n      <td>0.000963</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.834374</td>\n      <td>0.069718</td>\n      <td>9.738489</td>\n      <td>0.063404</td>\n      <td>auto</td>\n      <td>9</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.932130</td>\n      <td>0.928460</td>\n      <td>0.930870</td>\n      <td>0.933865</td>\n      <td>0.931344</td>\n      <td>0.931334</td>\n      <td>0.001761</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>3.801198</td>\n      <td>0.114209</td>\n      <td>905.020984</td>\n      <td>16.122923</td>\n      <td>kd_tree</td>\n      <td>10</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.931119</td>\n      <td>0.927041</td>\n      <td>0.929792</td>\n      <td>0.931881</td>\n      <td>0.929050</td>\n      <td>0.929777</td>\n      <td>0.001688</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.811790</td>\n      <td>0.078214</td>\n      <td>9.974040</td>\n      <td>0.165639</td>\n      <td>brute</td>\n      <td>11</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'brute', 'model__n_neighb...</td>\n      <td>0.931177</td>\n      <td>0.927483</td>\n      <td>0.928900</td>\n      <td>0.931682</td>\n      <td>0.928818</td>\n      <td>0.929612</td>\n      <td>0.001575</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>3.287191</td>\n      <td>0.103684</td>\n      <td>1461.377380</td>\n      <td>77.773976</td>\n      <td>ball_tree</td>\n      <td>11</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'ball_tree', 'model__n_ne...</td>\n      <td>0.931177</td>\n      <td>0.927483</td>\n      <td>0.928900</td>\n      <td>0.931682</td>\n      <td>0.928818</td>\n      <td>0.929612</td>\n      <td>0.001575</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>3.662197</td>\n      <td>0.135928</td>\n      <td>896.900370</td>\n      <td>8.341091</td>\n      <td>kd_tree</td>\n      <td>12</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.930004</td>\n      <td>0.925757</td>\n      <td>0.927993</td>\n      <td>0.929044</td>\n      <td>0.927540</td>\n      <td>0.928068</td>\n      <td>0.001437</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.783073</td>\n      <td>0.126450</td>\n      <td>9.711746</td>\n      <td>0.085562</td>\n      <td>brute</td>\n      <td>14</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'brute', 'model__n_neighb...</td>\n      <td>0.928376</td>\n      <td>0.924034</td>\n      <td>0.926037</td>\n      <td>0.926186</td>\n      <td>0.925522</td>\n      <td>0.926031</td>\n      <td>0.001398</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3.829689</td>\n      <td>0.122632</td>\n      <td>1085.876165</td>\n      <td>35.600886</td>\n      <td>kd_tree</td>\n      <td>15</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.927294</td>\n      <td>0.923748</td>\n      <td>0.924235</td>\n      <td>0.926395</td>\n      <td>0.925289</td>\n      <td>0.925392</td>\n      <td>0.001317</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>3.505279</td>\n      <td>0.127642</td>\n      <td>1573.930819</td>\n      <td>46.199141</td>\n      <td>ball_tree</td>\n      <td>16</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'ball_tree', 'model__n_ne...</td>\n      <td>0.924548</td>\n      <td>0.920714</td>\n      <td>0.922550</td>\n      <td>0.923910</td>\n      <td>0.923097</td>\n      <td>0.922964</td>\n      <td>0.001316</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.852999</td>\n      <td>0.072944</td>\n      <td>9.645307</td>\n      <td>0.097676</td>\n      <td>auto</td>\n      <td>17</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.923769</td>\n      <td>0.920643</td>\n      <td>0.921457</td>\n      <td>0.923798</td>\n      <td>0.922358</td>\n      <td>0.922405</td>\n      <td>0.001249</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>3.661122</td>\n      <td>0.101505</td>\n      <td>1069.713923</td>\n      <td>44.167479</td>\n      <td>kd_tree</td>\n      <td>18</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.921478</td>\n      <td>0.919248</td>\n      <td>0.919605</td>\n      <td>0.921277</td>\n      <td>0.919602</td>\n      <td>0.920242</td>\n      <td>0.000938</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>3.625975</td>\n      <td>0.095549</td>\n      <td>1106.628634</td>\n      <td>26.090674</td>\n      <td>kd_tree</td>\n      <td>20</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.920265</td>\n      <td>0.917406</td>\n      <td>0.918084</td>\n      <td>0.920437</td>\n      <td>0.918710</td>\n      <td>0.918980</td>\n      <td>0.001194</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>0.825013</td>\n      <td>0.052824</td>\n      <td>9.673314</td>\n      <td>0.095813</td>\n      <td>auto</td>\n      <td>20</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.920265</td>\n      <td>0.917406</td>\n      <td>0.918084</td>\n      <td>0.920437</td>\n      <td>0.918710</td>\n      <td>0.918980</td>\n      <td>0.001194</td>\n      <td>49</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnc_grid_search_dataframe = pd.DataFrame(\n",
    "    np.load(\"Dataset_Files/Baseline_Models/Classification/optimised_knnc_cv_results.npy\", allow_pickle=True).tolist())\n",
    "knnc_grid_search_dataframe.sort_values(by=[\"rank_test_score\"], inplace=True)\n",
    "knnc_grid_search_dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 500\n",
      "--------------------------------------------------------\n",
      "Median Recall: 0.83 with a 95% confidence interval of [0.79,0.87]\n",
      "Median Precision: 0.82 with a 95% confidence interval of [0.78,0.86]\n",
      "Median F1: 0.82 with a 95% confidence interval of [0.79,0.85]\n",
      "Median Accuracy: 0.76 with a 95% confidence interval of [0.72,0.79]\n",
      "Median MCC: 0.42 with a 95% confidence interval of [0.33,0.50]\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"Dataset_Files/Baseline_Models/Classification/optimised_knnc_test_metrics.txt\"):\n",
    "    with open(\"Dataset_Files/Baseline_Models/Classification/optimised_knnc_test_metrics.txt\", \"r\") as file:\n",
    "        print(file.read())\n",
    "else:\n",
    "    get_confidence_intervals(optimised_knnc, X_test, y_test, 500, \"Classification\", print_iterator=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree Classifier (DTC)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model', DecisionTreeClassifier(random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': DecisionTreeClassifier(random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__ccp_alpha': 0.0,\n 'model__class_weight': None,\n 'model__criterion': 'gini',\n 'model__max_depth': None,\n 'model__max_features': None,\n 'model__max_leaf_nodes': None,\n 'model__min_impurity_decrease': 0.0,\n 'model__min_samples_leaf': 1,\n 'model__min_samples_split': 2,\n 'model__min_weight_fraction_leaf': 0.0,\n 'model__random_state': 42,\n 'model__splitter': 'best'}"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scale', StandardScaler()),\n",
    "        ('model', DecisionTreeClassifier(random_state=42))\n",
    "    ]\n",
    ")\n",
    "pipe.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "model = BayesSearchCV(estimator=pipe,\n",
    "                      search_spaces=\n",
    "                      {'model__criterion': Categorical(['gini', 'entropy']),\n",
    "                       'model__splitter': Categorical(['best', 'random']),\n",
    "                       'model__max_features': Categorical([None, 'sqrt', 'log2']),\n",
    "                       'model__class_weight': Categorical([None, 'balanced'])\n",
    "                       },\n",
    "                      scoring='f1',\n",
    "                      cv=5,\n",
    "                      error_score=np.nan,\n",
    "                      n_jobs=-1,\n",
    "                      pre_dispatch='2*n_jobs',\n",
    "                      random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# index = 1\n",
    "# model.fit(X_train, y_train, callback=on_step)\n",
    "#\n",
    "# optimised_dtc = model.best_estimator_\n",
    "#\n",
    "# y_train_pred = optimised_dtc.predict(X_train)\n",
    "# calculate_metrics_classification(y_train, y_train_pred)\n",
    "#\n",
    "# # Save Model & CV Results\n",
    "# dump(optimised_dtc, 'Dataset_Files/Baseline_Models/Classification/optimised_dtc.joblib')\n",
    "# np.save(\"Dataset_Files/Baseline_Models/Classification/optimised_dtc_cv_results.npy\", model.cv_results_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Load Model\n",
    "optimised_dtc = load('Dataset_Files/Baseline_Models/Classification/optimised_dtc.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# visualise_decision_tree(optimised_dtc['model'], feature_selection_columns, [\"Inactive\", \"Active\"],\n",
    "#                         \"Dataset_Files/Baseline_Models/Classification/optimised_dtc.dot\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 1000\n",
      "--------------------------------------------------------\n",
      "Median Recall: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median Precision: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median F1: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median Accuracy: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median MCC: 1.00 with a 95% confidence interval of [1.00,1.00]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_dtc, X_train, y_train, 1000, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model',\n   DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n                          random_state=42, splitter='random'))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n                        random_state=42, splitter='random'),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__ccp_alpha': 0.0,\n 'model__class_weight': 'balanced',\n 'model__criterion': 'entropy',\n 'model__max_depth': None,\n 'model__max_features': None,\n 'model__max_leaf_nodes': None,\n 'model__min_impurity_decrease': 0.0,\n 'model__min_samples_leaf': 1,\n 'model__min_samples_split': 2,\n 'model__min_weight_fraction_leaf': 0.0,\n 'model__random_state': 42,\n 'model__splitter': 'random'}"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimised_dtc.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n49      14.322085      0.273997         0.069076        0.006317   \n23      16.159878      0.382061         0.081241        0.015318   \n48      20.176426      0.483790         0.106820        0.040917   \n11      14.677525      0.285513         0.084819        0.011418   \n27      13.145007      0.232202         0.065607        0.006246   \n31      13.524995      0.243572         0.065640        0.011702   \n19      13.936948      0.341420         0.079766        0.007252   \n33      12.989052      0.375393         0.078204        0.017049   \n36      13.206737      0.285128         0.071863        0.018745   \n37      13.683733      0.311930         0.067947        0.008435   \n39      15.933205      0.303794         0.078517        0.005495   \n44      15.513610      0.303358         0.071573        0.012711   \n45      14.075476      0.346205         0.067088        0.008247   \n47      13.334327      0.352288         0.072797        0.019861   \n34      12.865936      0.303787         0.070165        0.015299   \n16      12.767201      0.349974         0.068739        0.015954   \n12      16.468110      0.659361         0.062478        0.009855   \n24      22.467845      0.296153         0.077106        0.009279   \n15      12.187874      0.226683         0.074539        0.011087   \n1        1.665156      0.066589         0.084373        0.018762   \n6        2.032451      0.052580         0.090937        0.011641   \n7        1.836684      0.059951         0.071476        0.009823   \n13       2.521271      0.091183         0.088476        0.019730   \n14      27.860261      0.677811         0.069075        0.012756   \n5       39.024775      1.448638         0.075581        0.017594   \n26      26.204581      0.269518         0.062224        0.014813   \n38       2.510410      0.062617         0.114131        0.015633   \n28       1.590597      0.028440         0.082581        0.013701   \n43       2.084386      0.032184         0.096866        0.011699   \n42       2.922245      0.043067         0.103121        0.007653   \n21       2.938674      0.077682         0.129518        0.024957   \n18       1.635222      0.045715         0.087226        0.007999   \n46       1.813871      0.053130         0.087879        0.008203   \n29       1.812026      0.050532         0.088226        0.009536   \n3        1.831046      0.032913         0.089099        0.005388   \n35       1.949614      0.096762         0.086862        0.016134   \n4        1.795029      0.067047         0.074287        0.003184   \n32       2.261358      0.069271         0.062359        0.000344   \n9        3.063832      0.105933         0.089819        0.012530   \n20       2.019071      0.095856         0.127375        0.030150   \n25       2.263769      0.077964         0.087937        0.014045   \n2       52.214778      4.962452         0.079195        0.021955   \n0        1.752689      0.042426         0.087583        0.007553   \n40       1.876343      0.052849         0.093750        0.009883   \n8        1.830297      0.049257         0.096872        0.011689   \n22       1.539174      0.041014         0.084368        0.007669   \n10       1.597664      0.047396         0.109545        0.009607   \n30       1.501594      0.070837         0.081250        0.011695   \n41       1.485541      0.041453         0.090619        0.011696   \n17       1.353637      0.026881         0.087499        0.007653   \n\n   param_model__class_weight param_model__criterion param_model__max_features  \\\n49                  balanced                entropy                      None   \n23                  balanced                entropy                      None   \n48                  balanced                entropy                      None   \n11                  balanced                entropy                      None   \n27                  balanced                entropy                      None   \n31                  balanced                entropy                      None   \n19                  balanced                entropy                      None   \n33                  balanced                entropy                      None   \n36                  balanced                entropy                      None   \n37                  balanced                entropy                      None   \n39                  balanced                entropy                      None   \n44                  balanced                entropy                      None   \n45                  balanced                entropy                      None   \n47                  balanced                entropy                      None   \n34                  balanced                entropy                      None   \n16                  balanced                entropy                      None   \n12                  balanced                   gini                      None   \n24                      None                   gini                      None   \n15                      None                entropy                      None   \n1                   balanced                   gini                      sqrt   \n6                   balanced                   gini                      sqrt   \n7                   balanced                   gini                      sqrt   \n13                  balanced                entropy                      sqrt   \n14                  balanced                entropy                      None   \n5                   balanced                   gini                      None   \n26                      None                entropy                      None   \n38                      None                entropy                      sqrt   \n28                      None                entropy                      sqrt   \n43                      None                entropy                      sqrt   \n42                  balanced                   gini                      sqrt   \n21                  balanced                   gini                      sqrt   \n18                      None                   gini                      sqrt   \n46                  balanced                entropy                      log2   \n29                  balanced                entropy                      log2   \n3                   balanced                entropy                      sqrt   \n35                  balanced                entropy                      sqrt   \n4                   balanced                entropy                      sqrt   \n32                      None                   gini                      sqrt   \n9                       None                   gini                      sqrt   \n20                      None                entropy                      log2   \n25                      None                entropy                      sqrt   \n2                       None                   gini                      None   \n0                       None                   gini                      log2   \n40                  balanced                   gini                      log2   \n8                   balanced                   gini                      log2   \n22                  balanced                entropy                      log2   \n10                  balanced                   gini                      log2   \n30                      None                   gini                      log2   \n41                      None                   gini                      log2   \n17                      None                entropy                      log2   \n\n   param_model__splitter                                             params  \\\n49                random  {'model__class_weight': 'balanced', 'model__cr...   \n23                random  {'model__class_weight': 'balanced', 'model__cr...   \n48                random  {'model__class_weight': 'balanced', 'model__cr...   \n11                random  {'model__class_weight': 'balanced', 'model__cr...   \n27                random  {'model__class_weight': 'balanced', 'model__cr...   \n31                random  {'model__class_weight': 'balanced', 'model__cr...   \n19                random  {'model__class_weight': 'balanced', 'model__cr...   \n33                random  {'model__class_weight': 'balanced', 'model__cr...   \n36                random  {'model__class_weight': 'balanced', 'model__cr...   \n37                random  {'model__class_weight': 'balanced', 'model__cr...   \n39                random  {'model__class_weight': 'balanced', 'model__cr...   \n44                random  {'model__class_weight': 'balanced', 'model__cr...   \n45                random  {'model__class_weight': 'balanced', 'model__cr...   \n47                random  {'model__class_weight': 'balanced', 'model__cr...   \n34                random  {'model__class_weight': 'balanced', 'model__cr...   \n16                random  {'model__class_weight': 'balanced', 'model__cr...   \n12                random  {'model__class_weight': 'balanced', 'model__cr...   \n24                random  {'model__class_weight': None, 'model__criterio...   \n15                random  {'model__class_weight': None, 'model__criterio...   \n1                 random  {'model__class_weight': 'balanced', 'model__cr...   \n6                 random  {'model__class_weight': 'balanced', 'model__cr...   \n7                 random  {'model__class_weight': 'balanced', 'model__cr...   \n13                  best  {'model__class_weight': 'balanced', 'model__cr...   \n14                  best  {'model__class_weight': 'balanced', 'model__cr...   \n5                   best  {'model__class_weight': 'balanced', 'model__cr...   \n26                  best  {'model__class_weight': None, 'model__criterio...   \n38                random  {'model__class_weight': None, 'model__criterio...   \n28                random  {'model__class_weight': None, 'model__criterio...   \n43                random  {'model__class_weight': None, 'model__criterio...   \n42                  best  {'model__class_weight': 'balanced', 'model__cr...   \n21                  best  {'model__class_weight': 'balanced', 'model__cr...   \n18                random  {'model__class_weight': None, 'model__criterio...   \n46                  best  {'model__class_weight': 'balanced', 'model__cr...   \n29                  best  {'model__class_weight': 'balanced', 'model__cr...   \n3                 random  {'model__class_weight': 'balanced', 'model__cr...   \n35                random  {'model__class_weight': 'balanced', 'model__cr...   \n4                 random  {'model__class_weight': 'balanced', 'model__cr...   \n32                  best  {'model__class_weight': None, 'model__criterio...   \n9                   best  {'model__class_weight': None, 'model__criterio...   \n20                  best  {'model__class_weight': None, 'model__criterio...   \n25                  best  {'model__class_weight': None, 'model__criterio...   \n2                   best  {'model__class_weight': None, 'model__criterio...   \n0                   best  {'model__class_weight': None, 'model__criterio...   \n40                  best  {'model__class_weight': 'balanced', 'model__cr...   \n8                   best  {'model__class_weight': 'balanced', 'model__cr...   \n22                random  {'model__class_weight': 'balanced', 'model__cr...   \n10                random  {'model__class_weight': 'balanced', 'model__cr...   \n30                random  {'model__class_weight': None, 'model__criterio...   \n41                random  {'model__class_weight': None, 'model__criterio...   \n17                random  {'model__class_weight': None, 'model__criterio...   \n\n    split0_test_score  split1_test_score  split2_test_score  \\\n49           0.921640           0.920335           0.923301   \n23           0.921640           0.920335           0.923301   \n48           0.921640           0.920335           0.923301   \n11           0.921640           0.920335           0.923301   \n27           0.921640           0.920335           0.923301   \n31           0.921640           0.920335           0.923301   \n19           0.921640           0.920335           0.923301   \n33           0.921640           0.920335           0.923301   \n36           0.921640           0.920335           0.923301   \n37           0.921640           0.920335           0.923301   \n39           0.921640           0.920335           0.923301   \n44           0.921640           0.920335           0.923301   \n45           0.921640           0.920335           0.923301   \n47           0.921640           0.920335           0.923301   \n34           0.921640           0.920335           0.923301   \n16           0.921640           0.920335           0.923301   \n12           0.923660           0.919801           0.920203   \n24           0.922634           0.919121           0.921826   \n15           0.921292           0.921110           0.921053   \n1            0.922020           0.916447           0.918884   \n6            0.922020           0.916447           0.918884   \n7            0.922020           0.916447           0.918884   \n13           0.919897           0.918304           0.919394   \n14           0.917068           0.919193           0.919025   \n5            0.917934           0.917204           0.920893   \n26           0.918913           0.916596           0.919045   \n38           0.920312           0.916054           0.918227   \n28           0.920312           0.916054           0.918227   \n43           0.920312           0.916054           0.918227   \n42           0.916890           0.917979           0.917700   \n21           0.916890           0.917979           0.917700   \n18           0.920538           0.915398           0.917283   \n46           0.919209           0.917630           0.917716   \n29           0.919209           0.917630           0.917716   \n3            0.917337           0.917360           0.920061   \n35           0.917337           0.917360           0.920061   \n4            0.917337           0.917360           0.920061   \n32           0.919536           0.915692           0.918304   \n9            0.919536           0.915692           0.918304   \n20           0.918279           0.916726           0.914402   \n25           0.917956           0.916734           0.918159   \n2            0.915449           0.915814           0.917675   \n0            0.918609           0.916059           0.916138   \n40           0.915772           0.915482           0.917644   \n8            0.915772           0.915482           0.917644   \n22           0.914456           0.915331           0.911781   \n10           0.912816           0.910685           0.911686   \n30           0.911983           0.907660           0.913700   \n41           0.911983           0.907660           0.913700   \n17           0.910545           0.908601           0.910647   \n\n    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n49           0.921825           0.922775         0.921975        0.001022   \n23           0.921825           0.922775         0.921975        0.001022   \n48           0.921825           0.922775         0.921975        0.001022   \n11           0.921825           0.922775         0.921975        0.001022   \n27           0.921825           0.922775         0.921975        0.001022   \n31           0.921825           0.922775         0.921975        0.001022   \n19           0.921825           0.922775         0.921975        0.001022   \n33           0.921825           0.922775         0.921975        0.001022   \n36           0.921825           0.922775         0.921975        0.001022   \n37           0.921825           0.922775         0.921975        0.001022   \n39           0.921825           0.922775         0.921975        0.001022   \n44           0.921825           0.922775         0.921975        0.001022   \n45           0.921825           0.922775         0.921975        0.001022   \n47           0.921825           0.922775         0.921975        0.001022   \n34           0.921825           0.922775         0.921975        0.001022   \n16           0.921825           0.922775         0.921975        0.001022   \n12           0.920596           0.920739         0.921000        0.001370   \n24           0.920049           0.919495         0.920625        0.001367   \n15           0.920177           0.918437         0.920414        0.001061   \n1            0.921035           0.920265         0.919730        0.001935   \n6            0.921035           0.920265         0.919730        0.001935   \n7            0.921035           0.920265         0.919730        0.001935   \n13           0.919244           0.918228         0.919013        0.000648   \n14           0.919311           0.919448         0.918809        0.000882   \n5            0.919621           0.917341         0.918599        0.001434   \n26           0.920020           0.918135         0.918542        0.001143   \n38           0.918374           0.918255         0.918244        0.001348   \n28           0.918374           0.918255         0.918244        0.001348   \n43           0.918374           0.918255         0.918244        0.001348   \n42           0.918868           0.919644         0.918216        0.000954   \n21           0.918868           0.919644         0.918216        0.000954   \n18           0.918307           0.919254         0.918156        0.001748   \n46           0.918299           0.917478         0.918066        0.000635   \n29           0.918299           0.917478         0.918066        0.000635   \n3            0.917298           0.917075         0.917826        0.001122   \n35           0.917298           0.917075         0.917826        0.001122   \n4            0.917298           0.917075         0.917826        0.001122   \n32           0.919768           0.915791         0.917818        0.001767   \n9            0.919768           0.915791         0.917818        0.001767   \n20           0.919466           0.919188         0.917612        0.001869   \n25           0.916819           0.917447         0.917423        0.000577   \n2            0.920324           0.917419         0.917336        0.001728   \n0            0.919158           0.916238         0.917240        0.001354   \n40           0.917200           0.916008         0.916421        0.000846   \n8            0.917200           0.916008         0.916421        0.000846   \n22           0.918421           0.912047         0.914407        0.002426   \n10           0.916633           0.912178         0.912800        0.002039   \n30           0.913307           0.911735         0.911677        0.002144   \n41           0.913307           0.911735         0.911677        0.002144   \n17           0.911585           0.914793         0.911234        0.002027   \n\n    rank_test_score  \n49                1  \n23                1  \n48                1  \n11                1  \n27                1  \n31                1  \n19                1  \n33                1  \n36                1  \n37                1  \n39                1  \n44                1  \n45                1  \n47                1  \n34                1  \n16                1  \n12               17  \n24               18  \n15               19  \n1                20  \n6                20  \n7                20  \n13               23  \n14               24  \n5                25  \n26               26  \n38               27  \n28               27  \n43               27  \n42               30  \n21               30  \n18               32  \n46               33  \n29               33  \n3                35  \n35               35  \n4                35  \n32               38  \n9                38  \n20               40  \n25               41  \n2                42  \n0                43  \n40               44  \n8                44  \n22               46  \n10               47  \n30               48  \n41               48  \n17               50  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_model__class_weight</th>\n      <th>param_model__criterion</th>\n      <th>param_model__max_features</th>\n      <th>param_model__splitter</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>49</th>\n      <td>14.322085</td>\n      <td>0.273997</td>\n      <td>0.069076</td>\n      <td>0.006317</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>16.159878</td>\n      <td>0.382061</td>\n      <td>0.081241</td>\n      <td>0.015318</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>20.176426</td>\n      <td>0.483790</td>\n      <td>0.106820</td>\n      <td>0.040917</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>14.677525</td>\n      <td>0.285513</td>\n      <td>0.084819</td>\n      <td>0.011418</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>13.145007</td>\n      <td>0.232202</td>\n      <td>0.065607</td>\n      <td>0.006246</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>13.524995</td>\n      <td>0.243572</td>\n      <td>0.065640</td>\n      <td>0.011702</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>13.936948</td>\n      <td>0.341420</td>\n      <td>0.079766</td>\n      <td>0.007252</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>12.989052</td>\n      <td>0.375393</td>\n      <td>0.078204</td>\n      <td>0.017049</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>13.206737</td>\n      <td>0.285128</td>\n      <td>0.071863</td>\n      <td>0.018745</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>13.683733</td>\n      <td>0.311930</td>\n      <td>0.067947</td>\n      <td>0.008435</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>15.933205</td>\n      <td>0.303794</td>\n      <td>0.078517</td>\n      <td>0.005495</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>15.513610</td>\n      <td>0.303358</td>\n      <td>0.071573</td>\n      <td>0.012711</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>14.075476</td>\n      <td>0.346205</td>\n      <td>0.067088</td>\n      <td>0.008247</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>13.334327</td>\n      <td>0.352288</td>\n      <td>0.072797</td>\n      <td>0.019861</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>12.865936</td>\n      <td>0.303787</td>\n      <td>0.070165</td>\n      <td>0.015299</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>12.767201</td>\n      <td>0.349974</td>\n      <td>0.068739</td>\n      <td>0.015954</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>16.468110</td>\n      <td>0.659361</td>\n      <td>0.062478</td>\n      <td>0.009855</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.923660</td>\n      <td>0.919801</td>\n      <td>0.920203</td>\n      <td>0.920596</td>\n      <td>0.920739</td>\n      <td>0.921000</td>\n      <td>0.001370</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>22.467845</td>\n      <td>0.296153</td>\n      <td>0.077106</td>\n      <td>0.009279</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.922634</td>\n      <td>0.919121</td>\n      <td>0.921826</td>\n      <td>0.920049</td>\n      <td>0.919495</td>\n      <td>0.920625</td>\n      <td>0.001367</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>12.187874</td>\n      <td>0.226683</td>\n      <td>0.074539</td>\n      <td>0.011087</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.921292</td>\n      <td>0.921110</td>\n      <td>0.921053</td>\n      <td>0.920177</td>\n      <td>0.918437</td>\n      <td>0.920414</td>\n      <td>0.001061</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.665156</td>\n      <td>0.066589</td>\n      <td>0.084373</td>\n      <td>0.018762</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.922020</td>\n      <td>0.916447</td>\n      <td>0.918884</td>\n      <td>0.921035</td>\n      <td>0.920265</td>\n      <td>0.919730</td>\n      <td>0.001935</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2.032451</td>\n      <td>0.052580</td>\n      <td>0.090937</td>\n      <td>0.011641</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.922020</td>\n      <td>0.916447</td>\n      <td>0.918884</td>\n      <td>0.921035</td>\n      <td>0.920265</td>\n      <td>0.919730</td>\n      <td>0.001935</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.836684</td>\n      <td>0.059951</td>\n      <td>0.071476</td>\n      <td>0.009823</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.922020</td>\n      <td>0.916447</td>\n      <td>0.918884</td>\n      <td>0.921035</td>\n      <td>0.920265</td>\n      <td>0.919730</td>\n      <td>0.001935</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2.521271</td>\n      <td>0.091183</td>\n      <td>0.088476</td>\n      <td>0.019730</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>best</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.919897</td>\n      <td>0.918304</td>\n      <td>0.919394</td>\n      <td>0.919244</td>\n      <td>0.918228</td>\n      <td>0.919013</td>\n      <td>0.000648</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>27.860261</td>\n      <td>0.677811</td>\n      <td>0.069075</td>\n      <td>0.012756</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>best</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.917068</td>\n      <td>0.919193</td>\n      <td>0.919025</td>\n      <td>0.919311</td>\n      <td>0.919448</td>\n      <td>0.918809</td>\n      <td>0.000882</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>39.024775</td>\n      <td>1.448638</td>\n      <td>0.075581</td>\n      <td>0.017594</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>None</td>\n      <td>best</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.917934</td>\n      <td>0.917204</td>\n      <td>0.920893</td>\n      <td>0.919621</td>\n      <td>0.917341</td>\n      <td>0.918599</td>\n      <td>0.001434</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>26.204581</td>\n      <td>0.269518</td>\n      <td>0.062224</td>\n      <td>0.014813</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>best</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.918913</td>\n      <td>0.916596</td>\n      <td>0.919045</td>\n      <td>0.920020</td>\n      <td>0.918135</td>\n      <td>0.918542</td>\n      <td>0.001143</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>2.510410</td>\n      <td>0.062617</td>\n      <td>0.114131</td>\n      <td>0.015633</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.920312</td>\n      <td>0.916054</td>\n      <td>0.918227</td>\n      <td>0.918374</td>\n      <td>0.918255</td>\n      <td>0.918244</td>\n      <td>0.001348</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>1.590597</td>\n      <td>0.028440</td>\n      <td>0.082581</td>\n      <td>0.013701</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.920312</td>\n      <td>0.916054</td>\n      <td>0.918227</td>\n      <td>0.918374</td>\n      <td>0.918255</td>\n      <td>0.918244</td>\n      <td>0.001348</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>2.084386</td>\n      <td>0.032184</td>\n      <td>0.096866</td>\n      <td>0.011699</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.920312</td>\n      <td>0.916054</td>\n      <td>0.918227</td>\n      <td>0.918374</td>\n      <td>0.918255</td>\n      <td>0.918244</td>\n      <td>0.001348</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>2.922245</td>\n      <td>0.043067</td>\n      <td>0.103121</td>\n      <td>0.007653</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>best</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.916890</td>\n      <td>0.917979</td>\n      <td>0.917700</td>\n      <td>0.918868</td>\n      <td>0.919644</td>\n      <td>0.918216</td>\n      <td>0.000954</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2.938674</td>\n      <td>0.077682</td>\n      <td>0.129518</td>\n      <td>0.024957</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>best</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.916890</td>\n      <td>0.917979</td>\n      <td>0.917700</td>\n      <td>0.918868</td>\n      <td>0.919644</td>\n      <td>0.918216</td>\n      <td>0.000954</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1.635222</td>\n      <td>0.045715</td>\n      <td>0.087226</td>\n      <td>0.007999</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.920538</td>\n      <td>0.915398</td>\n      <td>0.917283</td>\n      <td>0.918307</td>\n      <td>0.919254</td>\n      <td>0.918156</td>\n      <td>0.001748</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>1.813871</td>\n      <td>0.053130</td>\n      <td>0.087879</td>\n      <td>0.008203</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>log2</td>\n      <td>best</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.919209</td>\n      <td>0.917630</td>\n      <td>0.917716</td>\n      <td>0.918299</td>\n      <td>0.917478</td>\n      <td>0.918066</td>\n      <td>0.000635</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>1.812026</td>\n      <td>0.050532</td>\n      <td>0.088226</td>\n      <td>0.009536</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>log2</td>\n      <td>best</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.919209</td>\n      <td>0.917630</td>\n      <td>0.917716</td>\n      <td>0.918299</td>\n      <td>0.917478</td>\n      <td>0.918066</td>\n      <td>0.000635</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.831046</td>\n      <td>0.032913</td>\n      <td>0.089099</td>\n      <td>0.005388</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.917337</td>\n      <td>0.917360</td>\n      <td>0.920061</td>\n      <td>0.917298</td>\n      <td>0.917075</td>\n      <td>0.917826</td>\n      <td>0.001122</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>1.949614</td>\n      <td>0.096762</td>\n      <td>0.086862</td>\n      <td>0.016134</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.917337</td>\n      <td>0.917360</td>\n      <td>0.920061</td>\n      <td>0.917298</td>\n      <td>0.917075</td>\n      <td>0.917826</td>\n      <td>0.001122</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.795029</td>\n      <td>0.067047</td>\n      <td>0.074287</td>\n      <td>0.003184</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.917337</td>\n      <td>0.917360</td>\n      <td>0.920061</td>\n      <td>0.917298</td>\n      <td>0.917075</td>\n      <td>0.917826</td>\n      <td>0.001122</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>2.261358</td>\n      <td>0.069271</td>\n      <td>0.062359</td>\n      <td>0.000344</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>best</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.919536</td>\n      <td>0.915692</td>\n      <td>0.918304</td>\n      <td>0.919768</td>\n      <td>0.915791</td>\n      <td>0.917818</td>\n      <td>0.001767</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3.063832</td>\n      <td>0.105933</td>\n      <td>0.089819</td>\n      <td>0.012530</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>best</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.919536</td>\n      <td>0.915692</td>\n      <td>0.918304</td>\n      <td>0.919768</td>\n      <td>0.915791</td>\n      <td>0.917818</td>\n      <td>0.001767</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2.019071</td>\n      <td>0.095856</td>\n      <td>0.127375</td>\n      <td>0.030150</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>log2</td>\n      <td>best</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.918279</td>\n      <td>0.916726</td>\n      <td>0.914402</td>\n      <td>0.919466</td>\n      <td>0.919188</td>\n      <td>0.917612</td>\n      <td>0.001869</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2.263769</td>\n      <td>0.077964</td>\n      <td>0.087937</td>\n      <td>0.014045</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>best</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.917956</td>\n      <td>0.916734</td>\n      <td>0.918159</td>\n      <td>0.916819</td>\n      <td>0.917447</td>\n      <td>0.917423</td>\n      <td>0.000577</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>52.214778</td>\n      <td>4.962452</td>\n      <td>0.079195</td>\n      <td>0.021955</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>None</td>\n      <td>best</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.915449</td>\n      <td>0.915814</td>\n      <td>0.917675</td>\n      <td>0.920324</td>\n      <td>0.917419</td>\n      <td>0.917336</td>\n      <td>0.001728</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1.752689</td>\n      <td>0.042426</td>\n      <td>0.087583</td>\n      <td>0.007553</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>best</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.918609</td>\n      <td>0.916059</td>\n      <td>0.916138</td>\n      <td>0.919158</td>\n      <td>0.916238</td>\n      <td>0.917240</td>\n      <td>0.001354</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>1.876343</td>\n      <td>0.052849</td>\n      <td>0.093750</td>\n      <td>0.009883</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>best</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.915772</td>\n      <td>0.915482</td>\n      <td>0.917644</td>\n      <td>0.917200</td>\n      <td>0.916008</td>\n      <td>0.916421</td>\n      <td>0.000846</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.830297</td>\n      <td>0.049257</td>\n      <td>0.096872</td>\n      <td>0.011689</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>best</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.915772</td>\n      <td>0.915482</td>\n      <td>0.917644</td>\n      <td>0.917200</td>\n      <td>0.916008</td>\n      <td>0.916421</td>\n      <td>0.000846</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1.539174</td>\n      <td>0.041014</td>\n      <td>0.084368</td>\n      <td>0.007669</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>log2</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.914456</td>\n      <td>0.915331</td>\n      <td>0.911781</td>\n      <td>0.918421</td>\n      <td>0.912047</td>\n      <td>0.914407</td>\n      <td>0.002426</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.597664</td>\n      <td>0.047396</td>\n      <td>0.109545</td>\n      <td>0.009607</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.912816</td>\n      <td>0.910685</td>\n      <td>0.911686</td>\n      <td>0.916633</td>\n      <td>0.912178</td>\n      <td>0.912800</td>\n      <td>0.002039</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>1.501594</td>\n      <td>0.070837</td>\n      <td>0.081250</td>\n      <td>0.011695</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>random</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.911983</td>\n      <td>0.907660</td>\n      <td>0.913700</td>\n      <td>0.913307</td>\n      <td>0.911735</td>\n      <td>0.911677</td>\n      <td>0.002144</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>1.485541</td>\n      <td>0.041453</td>\n      <td>0.090619</td>\n      <td>0.011696</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>random</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.911983</td>\n      <td>0.907660</td>\n      <td>0.913700</td>\n      <td>0.913307</td>\n      <td>0.911735</td>\n      <td>0.911677</td>\n      <td>0.002144</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1.353637</td>\n      <td>0.026881</td>\n      <td>0.087499</td>\n      <td>0.007653</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>log2</td>\n      <td>random</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.910545</td>\n      <td>0.908601</td>\n      <td>0.910647</td>\n      <td>0.911585</td>\n      <td>0.914793</td>\n      <td>0.911234</td>\n      <td>0.002027</td>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_grid_search_dataframe = pd.DataFrame(\n",
    "    np.load(\"Dataset_Files/Baseline_Models/Classification/optimised_dtc_cv_results.npy\", allow_pickle=True).tolist())\n",
    "dtc_grid_search_dataframe.sort_values(by=[\"rank_test_score\"], inplace=True)\n",
    "dtc_grid_search_dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 500\n",
      "--------------------------------------------------------\n",
      "Median Recall: 0.72 with a 95% confidence interval of [0.67,0.76]\n",
      "Median Precision: 0.75 with a 95% confidence interval of [0.71,0.80]\n",
      "Median F1: 0.73 with a 95% confidence interval of [0.70,0.77]\n",
      "Median Accuracy: 0.64 with a 95% confidence interval of [0.60,0.68]\n",
      "Median MCC: 0.18 with a 95% confidence interval of [0.09,0.27]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_dtc, X_test, y_test, 500, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest Classifier (RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model', RandomForestClassifier(random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': RandomForestClassifier(random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__bootstrap': True,\n 'model__ccp_alpha': 0.0,\n 'model__class_weight': None,\n 'model__criterion': 'gini',\n 'model__maxBins': 256,\n 'model__max_depth': None,\n 'model__max_features': 'auto',\n 'model__max_leaf_nodes': None,\n 'model__max_samples': None,\n 'model__minBinSize': 1,\n 'model__min_impurity_decrease': 0.0,\n 'model__min_samples_leaf': 1,\n 'model__min_samples_split': 2,\n 'model__min_weight_fraction_leaf': 0.0,\n 'model__n_estimators': 100,\n 'model__n_jobs': None,\n 'model__oob_score': False,\n 'model__random_state': 42,\n 'model__verbose': 0,\n 'model__warm_start': False}"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scale', StandardScaler()),\n",
    "        ('model', RandomForestClassifier(random_state=42))\n",
    "    ]\n",
    ")\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = BayesSearchCV(estimator=pipe,\n",
    "                      search_spaces=\n",
    "                      {'model__n_estimators': Integer(100, 1000),\n",
    "                       'model__criterion': Categorical(['gini', 'entropy', 'log_loss']),\n",
    "                       'model__max_features': Categorical([None, 'sqrt', 'log2']),\n",
    "                       'model__class_weight': Categorical([None, 'balanced', 'balanced_subsample'])\n",
    "                       },\n",
    "                      scoring='f1',\n",
    "                      cv=5,\n",
    "                      error_score=np.nan,\n",
    "                      n_jobs=-1,\n",
    "                      pre_dispatch='2*n_jobs',\n",
    "                      random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# index = 1\n",
    "# model.fit(X_train, y_train, callback=on_step)\n",
    "#\n",
    "# optimised_rfc = model.best_estimator_\n",
    "#\n",
    "# y_train_pred = optimised_rfc.predict(X_train)\n",
    "# calculate_metrics_classification(y_train, y_train_pred)\n",
    "#\n",
    "# # Save Model\n",
    "# dump(optimised_rfc, 'Dataset_Files/Baseline_Models/Classification/optimised_rfc.joblib')\n",
    "# np.save(\"Dataset_Files/Baseline_Models/Classification/optimised_rfc_cv_results.npy\", model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# Load Model\n",
    "optimised_rfc = load('Dataset_Files/Baseline_Models/Classification/optimised_rfc.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 1000\n",
      "--------------------------------------------------------\n",
      "Median Recall: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median Precision: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median F1: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median Accuracy: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median MCC: 1.00 with a 95% confidence interval of [1.00,1.00]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_rfc, X_train, y_train, 1000, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model',\n   RandomForestClassifier(criterion='log_loss', max_features=None,\n                          n_estimators=1000, random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': RandomForestClassifier(criterion='log_loss', max_features=None,\n                        n_estimators=1000, random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__bootstrap': True,\n 'model__ccp_alpha': 0.0,\n 'model__class_weight': None,\n 'model__criterion': 'log_loss',\n 'model__max_depth': None,\n 'model__max_features': None,\n 'model__max_leaf_nodes': None,\n 'model__max_samples': None,\n 'model__min_impurity_decrease': 0.0,\n 'model__min_samples_leaf': 1,\n 'model__min_samples_split': 2,\n 'model__min_weight_fraction_leaf': 0.0,\n 'model__n_estimators': 1000,\n 'model__n_jobs': None,\n 'model__oob_score': False,\n 'model__random_state': 42,\n 'model__verbose': 0,\n 'model__warm_start': False}"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimised_rfc.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n49    7956.526073     62.811718         4.496517        0.206688   \n48    8644.882016     60.026430         4.492718        0.051159   \n44    8033.716068     62.966427         6.483778        0.105352   \n16    7329.961614     60.161373         4.258674        0.169524   \n45    9345.696466     32.081029         6.404726        0.066233   \n27    8113.213372     50.627227         4.478413        0.085655   \n31    7787.961137     34.722299         4.840943        0.366981   \n47    9225.737369     65.444442         6.458594        0.120409   \n23    8650.654940     87.274675         5.811025        0.172880   \n36    7692.423509     73.687519         4.647925        0.283529   \n37    7954.901520     61.199862         4.463526        0.152994   \n39    7944.548282     57.829212         4.786539        0.336623   \n34    7479.377991     74.576649         4.168063        0.097916   \n33    7401.301954     40.085123         5.408268        0.312915   \n10    7217.493030     50.797286         4.098341        0.079279   \n2     3637.005670     32.748108         2.372898        0.254864   \n5     1994.607656     12.507586         1.445605        0.215782   \n29    1793.845347     24.114879         1.208948        0.105559   \n28    2345.581164     12.047057         1.446064        0.013750   \n19     683.180812      4.840797         0.443179        0.004442   \n11    8542.324392     61.698760         4.627393        0.158231   \n20    5578.415267     30.300237         3.198759        0.209614   \n14    2922.676686     14.350126         1.628158        0.035439   \n25     151.300782      1.159345         2.240680        0.124821   \n6      353.809178      5.931504         4.820188        0.642616   \n7      321.861491      5.028275         3.939461        0.051174   \n13     125.096612      0.657390         1.821313        0.077324   \n35     323.672162      4.193390         4.333499        0.239929   \n32     218.726333      4.337543         2.814788        0.213839   \n38     229.140187      3.497689         2.942485        0.116100   \n3      335.965422      4.024115         4.333259        0.386300   \n1      388.287003      1.615417         5.724129        0.328713   \n9      123.876866      1.531620         1.677142        0.130283   \n43     460.567457      7.907139         5.462335        0.270097   \n22     211.743164      3.175301         2.877823        0.228980   \n4      306.138328      1.335969         4.084033        0.232638   \n42      69.209004      1.417121         0.988415        0.077766   \n41     119.862751      1.497835         3.838131        0.437908   \n18     172.135041      1.983420         5.726546        0.336490   \n17     174.590546      2.272531         5.571829        0.348150   \n12     184.893963      3.076965         5.528333        0.176997   \n21      58.667304      1.251298         1.859282        0.081877   \n24     118.416734      1.657232         3.996184        0.250964   \n26      60.398334      0.263983         2.342218        0.063988   \n8       84.597536      0.858631         2.467852        0.049916   \n0       69.702910      1.359215         2.273160        0.127279   \n40      25.368183      0.939883         0.732985        0.024651   \n46      24.070850      0.152882         0.812047        0.029952   \n15      43.868344      0.457918         1.382779        0.089444   \n30      20.832122      0.737621         0.637436        0.033536   \n\n   param_model__class_weight param_model__criterion param_model__max_features  \\\n49                      None                entropy                      None   \n48                      None                entropy                      None   \n44                      None               log_loss                      None   \n16                      None               log_loss                      None   \n45                      None               log_loss                      None   \n27                      None               log_loss                      None   \n31                      None               log_loss                      None   \n47                      None               log_loss                      None   \n23                      None                entropy                      None   \n36                      None               log_loss                      None   \n37                      None               log_loss                      None   \n39                      None               log_loss                      None   \n34        balanced_subsample                entropy                      None   \n33        balanced_subsample               log_loss                      None   \n10                      None                entropy                      None   \n2                   balanced               log_loss                      None   \n5                   balanced               log_loss                      None   \n29        balanced_subsample               log_loss                      None   \n28                  balanced                entropy                      None   \n19        balanced_subsample                entropy                      None   \n11        balanced_subsample                   gini                      None   \n20        balanced_subsample                   gini                      None   \n14                  balanced                   gini                      None   \n25                  balanced               log_loss                      sqrt   \n6                   balanced               log_loss                      sqrt   \n7                   balanced               log_loss                      sqrt   \n13                  balanced                entropy                      sqrt   \n35                  balanced                entropy                      sqrt   \n32                      None               log_loss                      sqrt   \n38                      None                entropy                      sqrt   \n3         balanced_subsample                entropy                      sqrt   \n1         balanced_subsample               log_loss                      sqrt   \n9                       None               log_loss                      sqrt   \n43                      None                   gini                      sqrt   \n22        balanced_subsample                   gini                      sqrt   \n4         balanced_subsample                   gini                      sqrt   \n42                  balanced                   gini                      sqrt   \n41                      None               log_loss                      log2   \n18                  balanced                entropy                      log2   \n17                      None               log_loss                      log2   \n12                      None                   gini                      log2   \n21                  balanced                   gini                      log2   \n24                  balanced               log_loss                      log2   \n26                  balanced                   gini                      log2   \n8         balanced_subsample                   gini                      log2   \n0                   balanced                   gini                      log2   \n40                  balanced                   gini                      log2   \n46                  balanced                entropy                      log2   \n15        balanced_subsample                   gini                      log2   \n30                  balanced                   gini                      log2   \n\n   param_model__n_estimators  \\\n49                      1000   \n48                      1000   \n44                      1000   \n16                      1000   \n45                      1000   \n27                      1000   \n31                      1000   \n47                      1000   \n23                      1000   \n36                      1000   \n37                      1000   \n39                      1000   \n34                      1000   \n33                      1000   \n10                       985   \n2                        490   \n5                        270   \n29                       248   \n28                       323   \n19                       100   \n11                       999   \n20                       639   \n14                       344   \n25                       327   \n6                        887   \n7                        854   \n13                       342   \n35                       888   \n32                       540   \n38                       562   \n3                        822   \n1                        956   \n9                        329   \n43                       940   \n22                       513   \n4                        744   \n42                       169   \n41                       619   \n18                       998   \n17                       999   \n12                      1000   \n21                       320   \n24                       541   \n26                       283   \n8                        474   \n0                        384   \n40                       131   \n46                       107   \n15                       244   \n30                       112   \n\n                                               params  split0_test_score  \\\n49  {'model__class_weight': None, 'model__criterio...           0.949060   \n48  {'model__class_weight': None, 'model__criterio...           0.949060   \n44  {'model__class_weight': None, 'model__criterio...           0.949060   \n16  {'model__class_weight': None, 'model__criterio...           0.949060   \n45  {'model__class_weight': None, 'model__criterio...           0.949060   \n27  {'model__class_weight': None, 'model__criterio...           0.949060   \n31  {'model__class_weight': None, 'model__criterio...           0.949060   \n47  {'model__class_weight': None, 'model__criterio...           0.949060   \n23  {'model__class_weight': None, 'model__criterio...           0.949060   \n36  {'model__class_weight': None, 'model__criterio...           0.949060   \n37  {'model__class_weight': None, 'model__criterio...           0.949060   \n39  {'model__class_weight': None, 'model__criterio...           0.949060   \n34  {'model__class_weight': 'balanced_subsample', ...           0.949457   \n33  {'model__class_weight': 'balanced_subsample', ...           0.949457   \n10  {'model__class_weight': None, 'model__criterio...           0.949028   \n2   {'model__class_weight': 'balanced', 'model__cr...           0.949216   \n5   {'model__class_weight': 'balanced', 'model__cr...           0.948802   \n29  {'model__class_weight': 'balanced_subsample', ...           0.949334   \n28  {'model__class_weight': 'balanced', 'model__cr...           0.948717   \n19  {'model__class_weight': 'balanced_subsample', ...           0.949277   \n11  {'model__class_weight': 'balanced_subsample', ...           0.948507   \n20  {'model__class_weight': 'balanced_subsample', ...           0.948683   \n14  {'model__class_weight': 'balanced', 'model__cr...           0.948294   \n25  {'model__class_weight': 'balanced', 'model__cr...           0.946191   \n6   {'model__class_weight': 'balanced', 'model__cr...           0.946415   \n7   {'model__class_weight': 'balanced', 'model__cr...           0.946345   \n13  {'model__class_weight': 'balanced', 'model__cr...           0.946219   \n35  {'model__class_weight': 'balanced', 'model__cr...           0.946345   \n32  {'model__class_weight': None, 'model__criterio...           0.946868   \n38  {'model__class_weight': None, 'model__criterio...           0.946738   \n3   {'model__class_weight': 'balanced_subsample', ...           0.946232   \n1   {'model__class_weight': 'balanced_subsample', ...           0.946331   \n9   {'model__class_weight': None, 'model__criterio...           0.946393   \n43  {'model__class_weight': None, 'model__criterio...           0.946382   \n22  {'model__class_weight': 'balanced_subsample', ...           0.946018   \n4   {'model__class_weight': 'balanced_subsample', ...           0.945646   \n42  {'model__class_weight': 'balanced', 'model__cr...           0.945458   \n41  {'model__class_weight': None, 'model__criterio...           0.944056   \n18  {'model__class_weight': 'balanced', 'model__cr...           0.944773   \n17  {'model__class_weight': None, 'model__criterio...           0.944047   \n12  {'model__class_weight': None, 'model__criterio...           0.944558   \n21  {'model__class_weight': 'balanced', 'model__cr...           0.944487   \n24  {'model__class_weight': 'balanced', 'model__cr...           0.944331   \n26  {'model__class_weight': 'balanced', 'model__cr...           0.944065   \n8   {'model__class_weight': 'balanced_subsample', ...           0.944199   \n0   {'model__class_weight': 'balanced', 'model__cr...           0.944199   \n40  {'model__class_weight': 'balanced', 'model__cr...           0.944385   \n46  {'model__class_weight': 'balanced', 'model__cr...           0.944136   \n15  {'model__class_weight': 'balanced_subsample', ...           0.944459   \n30  {'model__class_weight': 'balanced', 'model__cr...           0.944320   \n\n    split1_test_score  split2_test_score  split3_test_score  \\\n49           0.946107           0.948579           0.949584   \n48           0.946107           0.948579           0.949584   \n44           0.946107           0.948579           0.949584   \n16           0.946107           0.948579           0.949584   \n45           0.946107           0.948579           0.949584   \n27           0.946107           0.948579           0.949584   \n31           0.946107           0.948579           0.949584   \n47           0.946107           0.948579           0.949584   \n23           0.946107           0.948579           0.949584   \n36           0.946107           0.948579           0.949584   \n37           0.946107           0.948579           0.949584   \n39           0.946107           0.948579           0.949584   \n34           0.946061           0.948244           0.949301   \n33           0.946061           0.948244           0.949301   \n10           0.945970           0.948393           0.949651   \n2            0.945764           0.947743           0.949224   \n5            0.945608           0.947862           0.949316   \n29           0.945482           0.947666           0.949017   \n28           0.945956           0.947582           0.949107   \n19           0.944973           0.947351           0.948293   \n11           0.945576           0.947365           0.948302   \n20           0.945245           0.947106           0.948085   \n14           0.945184           0.947039           0.948222   \n25           0.943320           0.944797           0.945788   \n6            0.943303           0.944841           0.945809   \n7            0.943323           0.944845           0.945710   \n13           0.943010           0.944793           0.945837   \n35           0.943225           0.944873           0.945805   \n32           0.943079           0.944233           0.945284   \n38           0.943111           0.944056           0.945422   \n3            0.943116           0.944624           0.945615   \n1            0.943144           0.944519           0.945446   \n9            0.943138           0.944207           0.945414   \n43           0.943159           0.944175           0.945096   \n22           0.942587           0.944387           0.945221   \n4            0.942783           0.944313           0.944978   \n42           0.942532           0.944344           0.944615   \n41           0.941561           0.944097           0.944329   \n18           0.941416           0.943520           0.944324   \n17           0.941439           0.943896           0.944374   \n12           0.941373           0.943485           0.944577   \n21           0.941864           0.943614           0.944270   \n24           0.941533           0.943334           0.944257   \n26           0.941789           0.943453           0.944422   \n8            0.941404           0.942930           0.944376   \n0            0.941526           0.943174           0.943938   \n40           0.941027           0.942977           0.944054   \n46           0.940800           0.943288           0.944087   \n15           0.941428           0.942730           0.943654   \n30           0.940328           0.942349           0.944074   \n\n    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n49           0.947003         0.948067        0.001306                1  \n48           0.947003         0.948067        0.001306                1  \n44           0.947003         0.948067        0.001306                1  \n16           0.947003         0.948067        0.001306                1  \n45           0.947003         0.948067        0.001306                1  \n27           0.947003         0.948067        0.001306                1  \n31           0.947003         0.948067        0.001306                1  \n47           0.947003         0.948067        0.001306                1  \n23           0.947003         0.948067        0.001306                1  \n36           0.947003         0.948067        0.001306                1  \n37           0.947003         0.948067        0.001306                1  \n39           0.947003         0.948067        0.001306                1  \n34           0.946902         0.947993        0.001330               13  \n33           0.946902         0.947993        0.001330               13  \n10           0.946884         0.947985        0.001364               15  \n2            0.946832         0.947756        0.001350               16  \n5            0.946874         0.947692        0.001335               17  \n29           0.946852         0.947670        0.001417               18  \n28           0.946829         0.947638        0.001167               19  \n19           0.946729         0.947324        0.001458               20  \n11           0.946002         0.947151        0.001184               21  \n20           0.946282         0.947080        0.001232               22  \n14           0.945310         0.946810        0.001352               23  \n25           0.944693         0.944958        0.000999               24  \n6            0.944134         0.944901        0.001119               25  \n7            0.944162         0.944877        0.001075               26  \n13           0.944485         0.944869        0.001128               27  \n35           0.944091         0.944868        0.001128               28  \n32           0.944057         0.944704        0.001288               29  \n38           0.944029         0.944671        0.001270               30  \n3            0.943623         0.944642        0.001170               31  \n1            0.943699         0.944628        0.001153               32  \n9            0.943762         0.944583        0.001172               33  \n43           0.943255         0.944413        0.001209               34  \n22           0.943669         0.944376        0.001193               35  \n4            0.943629         0.944270        0.001002               36  \n42           0.942824         0.943955        0.001109               37  \n41           0.942796         0.943368        0.001051               38  \n18           0.942759         0.943358        0.001191               39  \n17           0.943032         0.943358        0.001057               40  \n12           0.942624         0.943323        0.001218               41  \n21           0.942318         0.943311        0.001046               42  \n24           0.942727         0.943237        0.001040               43  \n26           0.942313         0.943209        0.001008               44  \n8            0.942625         0.943107        0.001092               45  \n0            0.942463         0.943060        0.000979               46  \n40           0.942625         0.943014        0.001188               47  \n46           0.942279         0.942918        0.001256               48  \n15           0.942180         0.942890        0.001069               49  \n30           0.942633         0.942741        0.001432               50  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_model__class_weight</th>\n      <th>param_model__criterion</th>\n      <th>param_model__max_features</th>\n      <th>param_model__n_estimators</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>49</th>\n      <td>7956.526073</td>\n      <td>62.811718</td>\n      <td>4.496517</td>\n      <td>0.206688</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>1000</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949060</td>\n      <td>0.946107</td>\n      <td>0.948579</td>\n      <td>0.949584</td>\n      <td>0.947003</td>\n      <td>0.948067</td>\n      <td>0.001306</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>8644.882016</td>\n      <td>60.026430</td>\n      <td>4.492718</td>\n      <td>0.051159</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>1000</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949060</td>\n      <td>0.946107</td>\n      <td>0.948579</td>\n      <td>0.949584</td>\n      <td>0.947003</td>\n      <td>0.948067</td>\n      <td>0.001306</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>8033.716068</td>\n      <td>62.966427</td>\n      <td>6.483778</td>\n      <td>0.105352</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>1000</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949060</td>\n      <td>0.946107</td>\n      <td>0.948579</td>\n      <td>0.949584</td>\n      <td>0.947003</td>\n      <td>0.948067</td>\n      <td>0.001306</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>7329.961614</td>\n      <td>60.161373</td>\n      <td>4.258674</td>\n      <td>0.169524</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>1000</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949060</td>\n      <td>0.946107</td>\n      <td>0.948579</td>\n      <td>0.949584</td>\n      <td>0.947003</td>\n      <td>0.948067</td>\n      <td>0.001306</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>9345.696466</td>\n      <td>32.081029</td>\n      <td>6.404726</td>\n      <td>0.066233</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>1000</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949060</td>\n      <td>0.946107</td>\n      <td>0.948579</td>\n      <td>0.949584</td>\n      <td>0.947003</td>\n      <td>0.948067</td>\n      <td>0.001306</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>8113.213372</td>\n      <td>50.627227</td>\n      <td>4.478413</td>\n      <td>0.085655</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>1000</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949060</td>\n      <td>0.946107</td>\n      <td>0.948579</td>\n      <td>0.949584</td>\n      <td>0.947003</td>\n      <td>0.948067</td>\n      <td>0.001306</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>7787.961137</td>\n      <td>34.722299</td>\n      <td>4.840943</td>\n      <td>0.366981</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>1000</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949060</td>\n      <td>0.946107</td>\n      <td>0.948579</td>\n      <td>0.949584</td>\n      <td>0.947003</td>\n      <td>0.948067</td>\n      <td>0.001306</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>9225.737369</td>\n      <td>65.444442</td>\n      <td>6.458594</td>\n      <td>0.120409</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>1000</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949060</td>\n      <td>0.946107</td>\n      <td>0.948579</td>\n      <td>0.949584</td>\n      <td>0.947003</td>\n      <td>0.948067</td>\n      <td>0.001306</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>8650.654940</td>\n      <td>87.274675</td>\n      <td>5.811025</td>\n      <td>0.172880</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>1000</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949060</td>\n      <td>0.946107</td>\n      <td>0.948579</td>\n      <td>0.949584</td>\n      <td>0.947003</td>\n      <td>0.948067</td>\n      <td>0.001306</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>7692.423509</td>\n      <td>73.687519</td>\n      <td>4.647925</td>\n      <td>0.283529</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>1000</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949060</td>\n      <td>0.946107</td>\n      <td>0.948579</td>\n      <td>0.949584</td>\n      <td>0.947003</td>\n      <td>0.948067</td>\n      <td>0.001306</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>7954.901520</td>\n      <td>61.199862</td>\n      <td>4.463526</td>\n      <td>0.152994</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>1000</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949060</td>\n      <td>0.946107</td>\n      <td>0.948579</td>\n      <td>0.949584</td>\n      <td>0.947003</td>\n      <td>0.948067</td>\n      <td>0.001306</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>7944.548282</td>\n      <td>57.829212</td>\n      <td>4.786539</td>\n      <td>0.336623</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>1000</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949060</td>\n      <td>0.946107</td>\n      <td>0.948579</td>\n      <td>0.949584</td>\n      <td>0.947003</td>\n      <td>0.948067</td>\n      <td>0.001306</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>7479.377991</td>\n      <td>74.576649</td>\n      <td>4.168063</td>\n      <td>0.097916</td>\n      <td>balanced_subsample</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>1000</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.949457</td>\n      <td>0.946061</td>\n      <td>0.948244</td>\n      <td>0.949301</td>\n      <td>0.946902</td>\n      <td>0.947993</td>\n      <td>0.001330</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>7401.301954</td>\n      <td>40.085123</td>\n      <td>5.408268</td>\n      <td>0.312915</td>\n      <td>balanced_subsample</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>1000</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.949457</td>\n      <td>0.946061</td>\n      <td>0.948244</td>\n      <td>0.949301</td>\n      <td>0.946902</td>\n      <td>0.947993</td>\n      <td>0.001330</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>7217.493030</td>\n      <td>50.797286</td>\n      <td>4.098341</td>\n      <td>0.079279</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>985</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949028</td>\n      <td>0.945970</td>\n      <td>0.948393</td>\n      <td>0.949651</td>\n      <td>0.946884</td>\n      <td>0.947985</td>\n      <td>0.001364</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3637.005670</td>\n      <td>32.748108</td>\n      <td>2.372898</td>\n      <td>0.254864</td>\n      <td>balanced</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>490</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.949216</td>\n      <td>0.945764</td>\n      <td>0.947743</td>\n      <td>0.949224</td>\n      <td>0.946832</td>\n      <td>0.947756</td>\n      <td>0.001350</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1994.607656</td>\n      <td>12.507586</td>\n      <td>1.445605</td>\n      <td>0.215782</td>\n      <td>balanced</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>270</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.948802</td>\n      <td>0.945608</td>\n      <td>0.947862</td>\n      <td>0.949316</td>\n      <td>0.946874</td>\n      <td>0.947692</td>\n      <td>0.001335</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>1793.845347</td>\n      <td>24.114879</td>\n      <td>1.208948</td>\n      <td>0.105559</td>\n      <td>balanced_subsample</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>248</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.949334</td>\n      <td>0.945482</td>\n      <td>0.947666</td>\n      <td>0.949017</td>\n      <td>0.946852</td>\n      <td>0.947670</td>\n      <td>0.001417</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>2345.581164</td>\n      <td>12.047057</td>\n      <td>1.446064</td>\n      <td>0.013750</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>323</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.948717</td>\n      <td>0.945956</td>\n      <td>0.947582</td>\n      <td>0.949107</td>\n      <td>0.946829</td>\n      <td>0.947638</td>\n      <td>0.001167</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>683.180812</td>\n      <td>4.840797</td>\n      <td>0.443179</td>\n      <td>0.004442</td>\n      <td>balanced_subsample</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>100</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.949277</td>\n      <td>0.944973</td>\n      <td>0.947351</td>\n      <td>0.948293</td>\n      <td>0.946729</td>\n      <td>0.947324</td>\n      <td>0.001458</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>8542.324392</td>\n      <td>61.698760</td>\n      <td>4.627393</td>\n      <td>0.158231</td>\n      <td>balanced_subsample</td>\n      <td>gini</td>\n      <td>None</td>\n      <td>999</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.948507</td>\n      <td>0.945576</td>\n      <td>0.947365</td>\n      <td>0.948302</td>\n      <td>0.946002</td>\n      <td>0.947151</td>\n      <td>0.001184</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>5578.415267</td>\n      <td>30.300237</td>\n      <td>3.198759</td>\n      <td>0.209614</td>\n      <td>balanced_subsample</td>\n      <td>gini</td>\n      <td>None</td>\n      <td>639</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.948683</td>\n      <td>0.945245</td>\n      <td>0.947106</td>\n      <td>0.948085</td>\n      <td>0.946282</td>\n      <td>0.947080</td>\n      <td>0.001232</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2922.676686</td>\n      <td>14.350126</td>\n      <td>1.628158</td>\n      <td>0.035439</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>None</td>\n      <td>344</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.948294</td>\n      <td>0.945184</td>\n      <td>0.947039</td>\n      <td>0.948222</td>\n      <td>0.945310</td>\n      <td>0.946810</td>\n      <td>0.001352</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>151.300782</td>\n      <td>1.159345</td>\n      <td>2.240680</td>\n      <td>0.124821</td>\n      <td>balanced</td>\n      <td>log_loss</td>\n      <td>sqrt</td>\n      <td>327</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.946191</td>\n      <td>0.943320</td>\n      <td>0.944797</td>\n      <td>0.945788</td>\n      <td>0.944693</td>\n      <td>0.944958</td>\n      <td>0.000999</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>353.809178</td>\n      <td>5.931504</td>\n      <td>4.820188</td>\n      <td>0.642616</td>\n      <td>balanced</td>\n      <td>log_loss</td>\n      <td>sqrt</td>\n      <td>887</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.946415</td>\n      <td>0.943303</td>\n      <td>0.944841</td>\n      <td>0.945809</td>\n      <td>0.944134</td>\n      <td>0.944901</td>\n      <td>0.001119</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>321.861491</td>\n      <td>5.028275</td>\n      <td>3.939461</td>\n      <td>0.051174</td>\n      <td>balanced</td>\n      <td>log_loss</td>\n      <td>sqrt</td>\n      <td>854</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.946345</td>\n      <td>0.943323</td>\n      <td>0.944845</td>\n      <td>0.945710</td>\n      <td>0.944162</td>\n      <td>0.944877</td>\n      <td>0.001075</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>125.096612</td>\n      <td>0.657390</td>\n      <td>1.821313</td>\n      <td>0.077324</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>342</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.946219</td>\n      <td>0.943010</td>\n      <td>0.944793</td>\n      <td>0.945837</td>\n      <td>0.944485</td>\n      <td>0.944869</td>\n      <td>0.001128</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>323.672162</td>\n      <td>4.193390</td>\n      <td>4.333499</td>\n      <td>0.239929</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>888</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.946345</td>\n      <td>0.943225</td>\n      <td>0.944873</td>\n      <td>0.945805</td>\n      <td>0.944091</td>\n      <td>0.944868</td>\n      <td>0.001128</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>218.726333</td>\n      <td>4.337543</td>\n      <td>2.814788</td>\n      <td>0.213839</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>sqrt</td>\n      <td>540</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.946868</td>\n      <td>0.943079</td>\n      <td>0.944233</td>\n      <td>0.945284</td>\n      <td>0.944057</td>\n      <td>0.944704</td>\n      <td>0.001288</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>229.140187</td>\n      <td>3.497689</td>\n      <td>2.942485</td>\n      <td>0.116100</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>562</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.946738</td>\n      <td>0.943111</td>\n      <td>0.944056</td>\n      <td>0.945422</td>\n      <td>0.944029</td>\n      <td>0.944671</td>\n      <td>0.001270</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>335.965422</td>\n      <td>4.024115</td>\n      <td>4.333259</td>\n      <td>0.386300</td>\n      <td>balanced_subsample</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>822</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.946232</td>\n      <td>0.943116</td>\n      <td>0.944624</td>\n      <td>0.945615</td>\n      <td>0.943623</td>\n      <td>0.944642</td>\n      <td>0.001170</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>388.287003</td>\n      <td>1.615417</td>\n      <td>5.724129</td>\n      <td>0.328713</td>\n      <td>balanced_subsample</td>\n      <td>log_loss</td>\n      <td>sqrt</td>\n      <td>956</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.946331</td>\n      <td>0.943144</td>\n      <td>0.944519</td>\n      <td>0.945446</td>\n      <td>0.943699</td>\n      <td>0.944628</td>\n      <td>0.001153</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>123.876866</td>\n      <td>1.531620</td>\n      <td>1.677142</td>\n      <td>0.130283</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>sqrt</td>\n      <td>329</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.946393</td>\n      <td>0.943138</td>\n      <td>0.944207</td>\n      <td>0.945414</td>\n      <td>0.943762</td>\n      <td>0.944583</td>\n      <td>0.001172</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>460.567457</td>\n      <td>7.907139</td>\n      <td>5.462335</td>\n      <td>0.270097</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>940</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.946382</td>\n      <td>0.943159</td>\n      <td>0.944175</td>\n      <td>0.945096</td>\n      <td>0.943255</td>\n      <td>0.944413</td>\n      <td>0.001209</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>211.743164</td>\n      <td>3.175301</td>\n      <td>2.877823</td>\n      <td>0.228980</td>\n      <td>balanced_subsample</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>513</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.946018</td>\n      <td>0.942587</td>\n      <td>0.944387</td>\n      <td>0.945221</td>\n      <td>0.943669</td>\n      <td>0.944376</td>\n      <td>0.001193</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>306.138328</td>\n      <td>1.335969</td>\n      <td>4.084033</td>\n      <td>0.232638</td>\n      <td>balanced_subsample</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>744</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.945646</td>\n      <td>0.942783</td>\n      <td>0.944313</td>\n      <td>0.944978</td>\n      <td>0.943629</td>\n      <td>0.944270</td>\n      <td>0.001002</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>69.209004</td>\n      <td>1.417121</td>\n      <td>0.988415</td>\n      <td>0.077766</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>169</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.945458</td>\n      <td>0.942532</td>\n      <td>0.944344</td>\n      <td>0.944615</td>\n      <td>0.942824</td>\n      <td>0.943955</td>\n      <td>0.001109</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>119.862751</td>\n      <td>1.497835</td>\n      <td>3.838131</td>\n      <td>0.437908</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>log2</td>\n      <td>619</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.944056</td>\n      <td>0.941561</td>\n      <td>0.944097</td>\n      <td>0.944329</td>\n      <td>0.942796</td>\n      <td>0.943368</td>\n      <td>0.001051</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>172.135041</td>\n      <td>1.983420</td>\n      <td>5.726546</td>\n      <td>0.336490</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>log2</td>\n      <td>998</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.944773</td>\n      <td>0.941416</td>\n      <td>0.943520</td>\n      <td>0.944324</td>\n      <td>0.942759</td>\n      <td>0.943358</td>\n      <td>0.001191</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>174.590546</td>\n      <td>2.272531</td>\n      <td>5.571829</td>\n      <td>0.348150</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>log2</td>\n      <td>999</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.944047</td>\n      <td>0.941439</td>\n      <td>0.943896</td>\n      <td>0.944374</td>\n      <td>0.943032</td>\n      <td>0.943358</td>\n      <td>0.001057</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>184.893963</td>\n      <td>3.076965</td>\n      <td>5.528333</td>\n      <td>0.176997</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>1000</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.944558</td>\n      <td>0.941373</td>\n      <td>0.943485</td>\n      <td>0.944577</td>\n      <td>0.942624</td>\n      <td>0.943323</td>\n      <td>0.001218</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>58.667304</td>\n      <td>1.251298</td>\n      <td>1.859282</td>\n      <td>0.081877</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>320</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.944487</td>\n      <td>0.941864</td>\n      <td>0.943614</td>\n      <td>0.944270</td>\n      <td>0.942318</td>\n      <td>0.943311</td>\n      <td>0.001046</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>118.416734</td>\n      <td>1.657232</td>\n      <td>3.996184</td>\n      <td>0.250964</td>\n      <td>balanced</td>\n      <td>log_loss</td>\n      <td>log2</td>\n      <td>541</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.944331</td>\n      <td>0.941533</td>\n      <td>0.943334</td>\n      <td>0.944257</td>\n      <td>0.942727</td>\n      <td>0.943237</td>\n      <td>0.001040</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>60.398334</td>\n      <td>0.263983</td>\n      <td>2.342218</td>\n      <td>0.063988</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>283</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.944065</td>\n      <td>0.941789</td>\n      <td>0.943453</td>\n      <td>0.944422</td>\n      <td>0.942313</td>\n      <td>0.943209</td>\n      <td>0.001008</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>84.597536</td>\n      <td>0.858631</td>\n      <td>2.467852</td>\n      <td>0.049916</td>\n      <td>balanced_subsample</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>474</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.944199</td>\n      <td>0.941404</td>\n      <td>0.942930</td>\n      <td>0.944376</td>\n      <td>0.942625</td>\n      <td>0.943107</td>\n      <td>0.001092</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>69.702910</td>\n      <td>1.359215</td>\n      <td>2.273160</td>\n      <td>0.127279</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>384</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.944199</td>\n      <td>0.941526</td>\n      <td>0.943174</td>\n      <td>0.943938</td>\n      <td>0.942463</td>\n      <td>0.943060</td>\n      <td>0.000979</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>25.368183</td>\n      <td>0.939883</td>\n      <td>0.732985</td>\n      <td>0.024651</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>131</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.944385</td>\n      <td>0.941027</td>\n      <td>0.942977</td>\n      <td>0.944054</td>\n      <td>0.942625</td>\n      <td>0.943014</td>\n      <td>0.001188</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>24.070850</td>\n      <td>0.152882</td>\n      <td>0.812047</td>\n      <td>0.029952</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>log2</td>\n      <td>107</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.944136</td>\n      <td>0.940800</td>\n      <td>0.943288</td>\n      <td>0.944087</td>\n      <td>0.942279</td>\n      <td>0.942918</td>\n      <td>0.001256</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>43.868344</td>\n      <td>0.457918</td>\n      <td>1.382779</td>\n      <td>0.089444</td>\n      <td>balanced_subsample</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>244</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.944459</td>\n      <td>0.941428</td>\n      <td>0.942730</td>\n      <td>0.943654</td>\n      <td>0.942180</td>\n      <td>0.942890</td>\n      <td>0.001069</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>20.832122</td>\n      <td>0.737621</td>\n      <td>0.637436</td>\n      <td>0.033536</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>112</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.944320</td>\n      <td>0.940328</td>\n      <td>0.942349</td>\n      <td>0.944074</td>\n      <td>0.942633</td>\n      <td>0.942741</td>\n      <td>0.001432</td>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_grid_search_dataframe = pd.DataFrame(\n",
    "    np.load(\"Dataset_Files/Baseline_Models/Classification/optimised_rfc_cv_results.npy\", allow_pickle=True).tolist())\n",
    "rfc_grid_search_dataframe.sort_values(by=[\"rank_test_score\"], inplace=True)\n",
    "rfc_grid_search_dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 500\n",
      "--------------------------------------------------------\n",
      "Median Recall: 0.93 with a 95% confidence interval of [0.90,0.96]\n",
      "Median Precision: 0.76 with a 95% confidence interval of [0.72,0.80]\n",
      "Median F1: 0.84 with a 95% confidence interval of [0.81,0.86]\n",
      "Median Accuracy: 0.75 with a 95% confidence interval of [0.72,0.79]\n",
      "Median MCC: 0.36 with a 95% confidence interval of [0.26,0.44]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_rfc, X_test, y_test, 500, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stochastic Gradient Descent Classifier (SGDC)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model', SGDClassifier(random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': SGDClassifier(random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__alpha': 0.0001,\n 'model__average': False,\n 'model__class_weight': None,\n 'model__early_stopping': False,\n 'model__epsilon': 0.1,\n 'model__eta0': 0.0,\n 'model__fit_intercept': True,\n 'model__l1_ratio': 0.15,\n 'model__learning_rate': 'optimal',\n 'model__loss': 'hinge',\n 'model__max_iter': 1000,\n 'model__n_iter_no_change': 5,\n 'model__n_jobs': None,\n 'model__penalty': 'l2',\n 'model__power_t': 0.5,\n 'model__random_state': 42,\n 'model__shuffle': True,\n 'model__tol': 0.001,\n 'model__validation_fraction': 0.1,\n 'model__verbose': 0,\n 'model__warm_start': False}"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scale', StandardScaler()),\n",
    "        ('model', SGDClassifier(random_state=42))\n",
    "    ]\n",
    ")\n",
    "pipe.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "model = BayesSearchCV(estimator=pipe,\n",
    "                      search_spaces=\n",
    "                      {'model__loss': Categorical(\n",
    "                          ['hinge', 'log_loss', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error',\n",
    "                           'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']),\n",
    "                          'model__penalty': Categorical(['l2', 'l1', 'elasticnet']),\n",
    "                          'model__alpha': Real(1e-6, 1e-1, prior='log-uniform'),\n",
    "                          'model__learning_rate': Categorical(['constant', 'optimal', 'invscaling', 'adaptive']),\n",
    "                          'model__eta0': Real(1e-6, 1e-1, prior='log-uniform'),\n",
    "                          'model__class_weight': Categorical([None, 'balanced'])\n",
    "                      },\n",
    "                      scoring='f1',\n",
    "                      cv=5,\n",
    "                      error_score=np.nan,\n",
    "                      n_jobs=-1,\n",
    "                      pre_dispatch='2*n_jobs',\n",
    "                      random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# index = 1\n",
    "# model.fit(X_train, y_train, callback=on_step)\n",
    "#\n",
    "# optimised_sgdc = model.best_estimator_\n",
    "#\n",
    "# y_train_pred = optimised_sgdc.predict(X_train)\n",
    "# calculate_metrics_classification(y_train, y_train_pred)\n",
    "#\n",
    "# # Save Model\n",
    "# dump(optimised_sgdc, 'Dataset_Files/Baseline_Models/Classification/optimised_sgdc.joblib')\n",
    "# np.save(\"Dataset_Files/Baseline_Models/Classification/optimised_sgdc_cv_results.npy\", model.cv_results_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Load Model\n",
    "optimised_sgdc = load('Dataset_Files/Baseline_Models/Classification/optimised_sgdc.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 1000\n",
      "--------------------------------------------------------\n",
      "Median Recall: 0.93 with a 95% confidence interval of [0.91,0.95]\n",
      "Median Precision: 0.84 with a 95% confidence interval of [0.81,0.86]\n",
      "Median F1: 0.88 with a 95% confidence interval of [0.87,0.90]\n",
      "Median Accuracy: 0.82 with a 95% confidence interval of [0.79,0.84]\n",
      "Median MCC: 0.49 with a 95% confidence interval of [0.42,0.55]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_sgdc, X_train, y_train, 1000, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model',\n   SGDClassifier(alpha=1e-06, eta0=0.0009866506104658564, learning_rate='adaptive',\n                 loss='log_loss', penalty='elasticnet', random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': SGDClassifier(alpha=1e-06, eta0=0.0009866506104658564, learning_rate='adaptive',\n               loss='log_loss', penalty='elasticnet', random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__alpha': 1e-06,\n 'model__average': False,\n 'model__class_weight': None,\n 'model__early_stopping': False,\n 'model__epsilon': 0.1,\n 'model__eta0': 0.0009866506104658564,\n 'model__fit_intercept': True,\n 'model__l1_ratio': 0.15,\n 'model__learning_rate': 'adaptive',\n 'model__loss': 'log_loss',\n 'model__max_iter': 1000,\n 'model__n_iter_no_change': 5,\n 'model__n_jobs': None,\n 'model__penalty': 'elasticnet',\n 'model__power_t': 0.5,\n 'model__random_state': 42,\n 'model__shuffle': True,\n 'model__tol': 0.001,\n 'model__validation_fraction': 0.1,\n 'model__verbose': 0,\n 'model__warm_start': False}"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimised_sgdc.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n42      11.540089      0.135104         0.101924        0.012556   \n43      10.143243      0.087633         0.115110        0.020024   \n11      13.461571      0.712058         0.095239        0.012657   \n21      12.815429      0.754772         0.094556        0.020193   \n14      22.981915      1.521373         0.084933        0.014329   \n29      22.162114      1.094737         0.090007        0.016814   \n22      10.612993      0.127675         0.118659        0.011845   \n35       7.129987      0.202482         0.106182        0.010396   \n47      16.977139      1.366065         0.087503        0.012953   \n38       7.647229      0.101210         0.107968        0.013210   \n37       7.674940      0.126536         0.115730        0.010119   \n40       8.446660      0.136616         0.099708        0.015107   \n24       4.839014      0.111349         0.100382        0.014686   \n12       7.729733      0.162592         0.104750        0.007520   \n46       2.450732      0.091324         0.108252        0.008745   \n27       7.238729      0.130560         0.111458        0.017860   \n20       6.751539      0.063021         0.169013        0.015796   \n45      10.698849      0.129318         0.106439        0.011632   \n16       4.870979      0.151285         0.171610        0.043110   \n26       7.634787      0.050829         0.138515        0.008774   \n3        6.021076      0.056410         0.152104        0.012401   \n17       9.969043      0.084749         0.128120        0.010469   \n41      13.539746      0.078644         0.128673        0.010444   \n4       12.744205      0.167670         0.126531        0.020128   \n39      21.221439      0.039679         0.154127        0.004818   \n19      11.369349      3.437662         0.098759        0.016708   \n32      19.750719      0.078656         0.143224        0.011398   \n31       2.592643      0.038281         0.150293        0.008825   \n5        8.057070      0.960305         0.100893        0.010960   \n7       16.466755      1.316583         0.111603        0.017989   \n25       2.919617      0.069355         0.141338        0.014454   \n30       9.581718      1.247561         0.088993        0.013287   \n28     167.265213     22.007503         0.112907        0.029585   \n49      59.840258     13.930628         0.080434        0.009048   \n10       2.804966      0.013805         0.168298        0.013170   \n9        9.181869      4.065360         0.104187        0.021100   \n48     104.772197      0.209169         0.086122        0.009601   \n8        7.321564      0.627405         0.149416        0.020583   \n6        8.578145      0.486180         0.103963        0.010412   \n23       7.502859      0.108874         0.120712        0.009206   \n0        7.398085      0.887352         0.103516        0.022230   \n36       2.516436      0.122895         0.112285        0.013916   \n2        5.058184      0.038117         0.157502        0.007238   \n34     120.565648     25.952456         0.089698        0.011245   \n18       3.710610      0.686722         0.112147        0.016332   \n13      53.762612      3.873236         0.089229        0.014692   \n1      298.486402      0.621144         0.117977        0.017865   \n33     286.520971      1.246275         0.095616        0.015227   \n15     278.651748      1.067038         0.089523        0.017071   \n44       3.907871      0.764192         0.106823        0.023423   \n\n   param_model__alpha param_model__class_weight param_model__eta0  \\\n42           0.000001                      None          0.000987   \n43           0.000001                      None          0.000494   \n11           0.000001                      None          0.000727   \n21           0.000001                      None          0.000657   \n14           0.000001                      None          0.034326   \n29           0.000001                      None          0.076401   \n22           0.000001                      None          0.000197   \n35           0.000156                      None          0.000019   \n47           0.000261                      None          0.001169   \n38           0.000023                      None          0.000014   \n37           0.000006                      None          0.000011   \n40           0.010342                      None          0.000014   \n24           0.000015                      None          0.000007   \n12            0.00039                      None          0.000004   \n46                0.1                      None          0.010704   \n27           0.000009                      None          0.000003   \n20           0.000001                      None          0.000023   \n45           0.000001                      None          0.000011   \n16           0.002118                      None          0.001112   \n26           0.000008                      None          0.000001   \n3            0.011534                      None          0.000978   \n17           0.005855                      None          0.000328   \n41           0.053992                      None           0.00008   \n4            0.009949                      None           0.00043   \n39           0.071471                      None          0.085677   \n19           0.000009                      None          0.011026   \n32           0.000833                      None          0.000045   \n31           0.000001                      None          0.000001   \n5            0.004679                  balanced          0.000007   \n7            0.000521                  balanced          0.000304   \n25           0.000007                      None          0.000014   \n30           0.000125                      None          0.004578   \n28           0.000005                      None          0.000005   \n49            0.00002                      None          0.000001   \n10           0.075042                      None          0.000759   \n9            0.000001                  balanced          0.005086   \n48            0.08768                  balanced          0.002819   \n8            0.059895                  balanced          0.022817   \n6            0.001217                  balanced          0.000062   \n23           0.009889                      None          0.000002   \n0            0.000112                  balanced          0.046168   \n36           0.000006                      None          0.000001   \n2            0.000168                  balanced          0.000003   \n34           0.000002                      None          0.049354   \n18           0.001494                      None          0.019815   \n13           0.000001                      None          0.054998   \n1            0.015379                  balanced          0.000033   \n33           0.000069                      None          0.038085   \n15                0.1                      None          0.000051   \n44            0.00001                      None               0.1   \n\n   param_model__learning_rate            param_model__loss  \\\n42                   adaptive                     log_loss   \n43                   adaptive                     log_loss   \n11                   adaptive               modified_huber   \n21                   adaptive               modified_huber   \n14                   adaptive               modified_huber   \n29                   adaptive               modified_huber   \n22                   adaptive                     log_loss   \n35                   adaptive               modified_huber   \n47                   adaptive                squared_hinge   \n38                   adaptive               modified_huber   \n37                   adaptive               modified_huber   \n40                   adaptive               modified_huber   \n24                   constant  squared_epsilon_insensitive   \n12                   adaptive               modified_huber   \n46                 invscaling                squared_hinge   \n27                   adaptive  squared_epsilon_insensitive   \n20                   constant                     log_loss   \n45                   adaptive                     log_loss   \n16                   constant                     log_loss   \n26                   adaptive  squared_epsilon_insensitive   \n3                  invscaling               modified_huber   \n17                 invscaling               modified_huber   \n41                   adaptive                     log_loss   \n4                  invscaling                squared_error   \n39                   adaptive                     log_loss   \n19                   constant                     log_loss   \n32                 invscaling               modified_huber   \n31                   constant                   perceptron   \n5                    constant  squared_epsilon_insensitive   \n7                     optimal                     log_loss   \n25                   constant                   perceptron   \n30                   constant                   perceptron   \n28                    optimal                squared_hinge   \n49                    optimal          epsilon_insensitive   \n10                 invscaling                   perceptron   \n9                    constant                   perceptron   \n48                    optimal                squared_hinge   \n8                    constant                     log_loss   \n6                     optimal                   perceptron   \n23                   adaptive                        huber   \n0                    constant                   perceptron   \n36                 invscaling                squared_error   \n2                    constant                        huber   \n34                   constant          epsilon_insensitive   \n18                   constant                squared_error   \n13                   adaptive                squared_error   \n1                     optimal                squared_error   \n33                   adaptive  squared_epsilon_insensitive   \n15                    optimal                squared_error   \n44                   constant  squared_epsilon_insensitive   \n\n   param_model__penalty                                             params  \\\n42           elasticnet  {'model__alpha': 1e-06, 'model__class_weight':...   \n43           elasticnet  {'model__alpha': 1e-06, 'model__class_weight':...   \n11           elasticnet  {'model__alpha': 1e-06, 'model__class_weight':...   \n21           elasticnet  {'model__alpha': 1e-06, 'model__class_weight':...   \n14           elasticnet  {'model__alpha': 1.208433613059891e-06, 'model...   \n29           elasticnet  {'model__alpha': 1e-06, 'model__class_weight':...   \n22           elasticnet  {'model__alpha': 1e-06, 'model__class_weight':...   \n35           elasticnet  {'model__alpha': 0.0001558896341561995, 'model...   \n47                   l1  {'model__alpha': 0.00026050658160080433, 'mode...   \n38           elasticnet  {'model__alpha': 2.3185490575738482e-05, 'mode...   \n37           elasticnet  {'model__alpha': 5.542025661946043e-06, 'model...   \n40           elasticnet  {'model__alpha': 0.010341539918142708, 'model_...   \n24           elasticnet  {'model__alpha': 1.5102696652058713e-05, 'mode...   \n12           elasticnet  {'model__alpha': 0.0003900951285443547, 'model...   \n46                   l2  {'model__alpha': 0.1, 'model__class_weight': N...   \n27           elasticnet  {'model__alpha': 9.482542507347432e-06, 'model...   \n20           elasticnet  {'model__alpha': 1.1052532881525498e-06, 'mode...   \n45           elasticnet  {'model__alpha': 1e-06, 'model__class_weight':...   \n16           elasticnet  {'model__alpha': 0.0021178262313998253, 'model...   \n26           elasticnet  {'model__alpha': 8.292082179554043e-06, 'model...   \n3            elasticnet  {'model__alpha': 0.011533999859559564, 'model_...   \n17           elasticnet  {'model__alpha': 0.005854632104963596, 'model_...   \n41           elasticnet  {'model__alpha': 0.053991933494224216, 'model_...   \n4                    l1  {'model__alpha': 0.009948719998234101, 'model_...   \n39                   l1  {'model__alpha': 0.07147057173391871, 'model__...   \n19           elasticnet  {'model__alpha': 9.053436778046378e-06, 'model...   \n32           elasticnet  {'model__alpha': 0.000832614559844781, 'model_...   \n31           elasticnet  {'model__alpha': 1e-06, 'model__class_weight':...   \n5                    l1  {'model__alpha': 0.0046788604247112444, 'model...   \n7            elasticnet  {'model__alpha': 0.0005212131190318165, 'model...   \n25           elasticnet  {'model__alpha': 6.590713623713951e-06, 'model...   \n30           elasticnet  {'model__alpha': 0.0001246610255516929, 'model...   \n28           elasticnet  {'model__alpha': 5.3678104049400005e-06, 'mode...   \n49                   l1  {'model__alpha': 2.042094287865455e-05, 'model...   \n10           elasticnet  {'model__alpha': 0.07504203081370357, 'model__...   \n9                    l1  {'model__alpha': 1.0426811836320545e-06, 'mode...   \n48                   l2  {'model__alpha': 0.08768010922961404, 'model__...   \n8            elasticnet  {'model__alpha': 0.05989491205267932, 'model__...   \n6                    l1  {'model__alpha': 0.0012172976749510152, 'model...   \n23           elasticnet  {'model__alpha': 0.009889417540774548, 'model_...   \n0                    l1  {'model__alpha': 0.00011233621690895234, 'mode...   \n36           elasticnet  {'model__alpha': 5.823893699289275e-06, 'model...   \n2                    l1  {'model__alpha': 0.00016755699440936588, 'mode...   \n34           elasticnet  {'model__alpha': 1.907041988802392e-06, 'model...   \n18                   l1  {'model__alpha': 0.0014937568205662616, 'model...   \n13                   l1  {'model__alpha': 1.0613730087581182e-06, 'mode...   \n1            elasticnet  {'model__alpha': 0.01537948446580078, 'model__...   \n33           elasticnet  {'model__alpha': 6.937084058445544e-05, 'model...   \n15                   l1  {'model__alpha': 0.1, 'model__class_weight': N...   \n44           elasticnet  {'model__alpha': 9.560509917296386e-06, 'model...   \n\n    split0_test_score  split1_test_score  split2_test_score  \\\n42           0.881067           0.879696           0.882391   \n43           0.881225           0.879568           0.882046   \n11           0.879445           0.880200           0.882000   \n21           0.879345           0.880241           0.881935   \n14           0.879728           0.879959           0.882158   \n29           0.879402           0.880403           0.882088   \n22           0.880972           0.879777           0.881438   \n35           0.880213           0.879695           0.881146   \n47           0.879344           0.880223           0.881504   \n38           0.880143           0.879849           0.880830   \n37           0.879706           0.879470           0.880589   \n40           0.878602           0.879309           0.880296   \n24           0.878005           0.878128           0.879540   \n12           0.877724           0.878218           0.879487   \n46           0.876894           0.876623           0.880410   \n27           0.877010           0.876669           0.878913   \n20           0.877355           0.877030           0.879074   \n45           0.875654           0.874753           0.878214   \n16           0.875093           0.876707           0.878307   \n26           0.874561           0.874462           0.877267   \n3            0.874558           0.873954           0.877467   \n17           0.869510           0.870075           0.874288   \n41           0.864656           0.862577           0.864093   \n4            0.861706           0.861486           0.864858   \n39           0.848705           0.848705           0.848705   \n19           0.849436           0.829524           0.847808   \n32           0.833769           0.834161           0.840318   \n31           0.810883           0.832623           0.822124   \n5            0.820764           0.823778           0.821549   \n7            0.815203           0.821658           0.821956   \n25           0.803554           0.815368           0.819242   \n30           0.794003           0.820598           0.838286   \n28           0.794833           0.795862           0.807527   \n49           0.795141           0.787408           0.825270   \n10           0.772447           0.651155           0.755722   \n9            0.724418           0.775093           0.755478   \n48           0.738224           0.746623           0.744615   \n8            0.735046           0.735476           0.729748   \n6            0.753267           0.746865           0.711102   \n23           0.729440           0.728789           0.738857   \n0            0.751342           0.707263           0.743205   \n36           0.716819           0.713706           0.724965   \n2            0.691503           0.694829           0.697351   \n34           0.582830           0.620532           0.635457   \n18           0.558026           0.629260           0.618340   \n13           0.571582           0.608444           0.625949   \n1            0.602855           0.603559           0.586773   \n33           0.602704           0.613147           0.577065   \n15           0.597503           0.595771           0.586406   \n44           0.599617           0.584659           0.589793   \n\n    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n42           0.880865           0.880873         0.880978        0.000857   \n43           0.880833           0.880974         0.880929        0.000800   \n11           0.880759           0.881322         0.880745        0.000882   \n21           0.880702           0.881422         0.880729        0.000904   \n14           0.880658           0.880842         0.880669        0.000853   \n29           0.880064           0.880907         0.880573        0.000902   \n22           0.880232           0.880146         0.880513        0.000603   \n35           0.880475           0.880904         0.880487        0.000512   \n47           0.880303           0.880417         0.880358        0.000688   \n38           0.879818           0.880419         0.880212        0.000379   \n37           0.879743           0.880184         0.879938        0.000399   \n40           0.878776           0.879221         0.879241        0.000590   \n24           0.877573           0.878697         0.878389        0.000678   \n12           0.877498           0.878997         0.878385        0.000754   \n46           0.877984           0.878793         0.878141        0.001375   \n27           0.876956           0.878041         0.877518        0.000838   \n20           0.876582           0.877332         0.877475        0.000847   \n45           0.875544           0.876788         0.876191        0.001202   \n16           0.874782           0.874400         0.875858        0.001455   \n26           0.874952           0.875745         0.875397        0.001038   \n3            0.874660           0.875502         0.875228        0.001223   \n17           0.871516           0.871708         0.871420        0.001660   \n41           0.864025           0.863719         0.863814        0.000689   \n4            0.862569           0.862826         0.862689        0.001196   \n39           0.848672           0.848672         0.848692        0.000016   \n19           0.835244           0.826797         0.837762        0.009291   \n32           0.833241           0.835487         0.835395        0.002571   \n31           0.832820           0.828595         0.825409        0.008233   \n5            0.816801           0.818738         0.820326        0.002390   \n7            0.816152           0.823749         0.819744        0.003409   \n25           0.836698           0.809443         0.816861        0.011256   \n30           0.791180           0.812198         0.811253        0.017433   \n28           0.793580           0.808601         0.800081        0.006567   \n49           0.794449           0.785762         0.797606        0.014322   \n10           0.789346           0.848672         0.763469        0.064318   \n9            0.707496           0.757212         0.743940        0.024450   \n48           0.739278           0.746236         0.742995        0.003546   \n8            0.748294           0.742245         0.738162        0.006435   \n6            0.761169           0.700737         0.734628        0.024098   \n23           0.733757           0.728350         0.731839        0.004004   \n0            0.722060           0.729883         0.730751        0.015537   \n36           0.720019           0.716570         0.718416        0.003837   \n2            0.693888           0.687074         0.692929        0.003475   \n34           0.597138           0.637601         0.614712        0.021510   \n18           0.631818           0.605645         0.608618        0.026934   \n13           0.595397           0.629338         0.606142        0.021192   \n1            0.593342           0.601164         0.597539        0.006499   \n33           0.603865           0.589174         0.597191        0.012640   \n15           0.581483           0.601205         0.592474        0.007349   \n44           0.556685           0.575613         0.581274        0.014541   \n\n    rank_test_score  \n42                1  \n43                2  \n11                3  \n21                4  \n14                5  \n29                6  \n22                7  \n35                8  \n47                9  \n38               10  \n37               11  \n40               12  \n24               13  \n12               14  \n46               15  \n27               16  \n20               17  \n45               18  \n16               19  \n26               20  \n3                21  \n17               22  \n41               23  \n4                24  \n39               25  \n19               26  \n32               27  \n31               28  \n5                29  \n7                30  \n25               31  \n30               32  \n28               33  \n49               34  \n10               35  \n9                36  \n48               37  \n8                38  \n6                39  \n23               40  \n0                41  \n36               42  \n2                43  \n34               44  \n18               45  \n13               46  \n1                47  \n33               48  \n15               49  \n44               50  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_model__alpha</th>\n      <th>param_model__class_weight</th>\n      <th>param_model__eta0</th>\n      <th>param_model__learning_rate</th>\n      <th>param_model__loss</th>\n      <th>param_model__penalty</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>42</th>\n      <td>11.540089</td>\n      <td>0.135104</td>\n      <td>0.101924</td>\n      <td>0.012556</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.000987</td>\n      <td>adaptive</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1e-06, 'model__class_weight':...</td>\n      <td>0.881067</td>\n      <td>0.879696</td>\n      <td>0.882391</td>\n      <td>0.880865</td>\n      <td>0.880873</td>\n      <td>0.880978</td>\n      <td>0.000857</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>10.143243</td>\n      <td>0.087633</td>\n      <td>0.115110</td>\n      <td>0.020024</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.000494</td>\n      <td>adaptive</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1e-06, 'model__class_weight':...</td>\n      <td>0.881225</td>\n      <td>0.879568</td>\n      <td>0.882046</td>\n      <td>0.880833</td>\n      <td>0.880974</td>\n      <td>0.880929</td>\n      <td>0.000800</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>13.461571</td>\n      <td>0.712058</td>\n      <td>0.095239</td>\n      <td>0.012657</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.000727</td>\n      <td>adaptive</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1e-06, 'model__class_weight':...</td>\n      <td>0.879445</td>\n      <td>0.880200</td>\n      <td>0.882000</td>\n      <td>0.880759</td>\n      <td>0.881322</td>\n      <td>0.880745</td>\n      <td>0.000882</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>12.815429</td>\n      <td>0.754772</td>\n      <td>0.094556</td>\n      <td>0.020193</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.000657</td>\n      <td>adaptive</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1e-06, 'model__class_weight':...</td>\n      <td>0.879345</td>\n      <td>0.880241</td>\n      <td>0.881935</td>\n      <td>0.880702</td>\n      <td>0.881422</td>\n      <td>0.880729</td>\n      <td>0.000904</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>22.981915</td>\n      <td>1.521373</td>\n      <td>0.084933</td>\n      <td>0.014329</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.034326</td>\n      <td>adaptive</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1.208433613059891e-06, 'model...</td>\n      <td>0.879728</td>\n      <td>0.879959</td>\n      <td>0.882158</td>\n      <td>0.880658</td>\n      <td>0.880842</td>\n      <td>0.880669</td>\n      <td>0.000853</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>22.162114</td>\n      <td>1.094737</td>\n      <td>0.090007</td>\n      <td>0.016814</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.076401</td>\n      <td>adaptive</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1e-06, 'model__class_weight':...</td>\n      <td>0.879402</td>\n      <td>0.880403</td>\n      <td>0.882088</td>\n      <td>0.880064</td>\n      <td>0.880907</td>\n      <td>0.880573</td>\n      <td>0.000902</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>10.612993</td>\n      <td>0.127675</td>\n      <td>0.118659</td>\n      <td>0.011845</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.000197</td>\n      <td>adaptive</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1e-06, 'model__class_weight':...</td>\n      <td>0.880972</td>\n      <td>0.879777</td>\n      <td>0.881438</td>\n      <td>0.880232</td>\n      <td>0.880146</td>\n      <td>0.880513</td>\n      <td>0.000603</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>7.129987</td>\n      <td>0.202482</td>\n      <td>0.106182</td>\n      <td>0.010396</td>\n      <td>0.000156</td>\n      <td>None</td>\n      <td>0.000019</td>\n      <td>adaptive</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.0001558896341561995, 'model...</td>\n      <td>0.880213</td>\n      <td>0.879695</td>\n      <td>0.881146</td>\n      <td>0.880475</td>\n      <td>0.880904</td>\n      <td>0.880487</td>\n      <td>0.000512</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>16.977139</td>\n      <td>1.366065</td>\n      <td>0.087503</td>\n      <td>0.012953</td>\n      <td>0.000261</td>\n      <td>None</td>\n      <td>0.001169</td>\n      <td>adaptive</td>\n      <td>squared_hinge</td>\n      <td>l1</td>\n      <td>{'model__alpha': 0.00026050658160080433, 'mode...</td>\n      <td>0.879344</td>\n      <td>0.880223</td>\n      <td>0.881504</td>\n      <td>0.880303</td>\n      <td>0.880417</td>\n      <td>0.880358</td>\n      <td>0.000688</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>7.647229</td>\n      <td>0.101210</td>\n      <td>0.107968</td>\n      <td>0.013210</td>\n      <td>0.000023</td>\n      <td>None</td>\n      <td>0.000014</td>\n      <td>adaptive</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 2.3185490575738482e-05, 'mode...</td>\n      <td>0.880143</td>\n      <td>0.879849</td>\n      <td>0.880830</td>\n      <td>0.879818</td>\n      <td>0.880419</td>\n      <td>0.880212</td>\n      <td>0.000379</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>7.674940</td>\n      <td>0.126536</td>\n      <td>0.115730</td>\n      <td>0.010119</td>\n      <td>0.000006</td>\n      <td>None</td>\n      <td>0.000011</td>\n      <td>adaptive</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 5.542025661946043e-06, 'model...</td>\n      <td>0.879706</td>\n      <td>0.879470</td>\n      <td>0.880589</td>\n      <td>0.879743</td>\n      <td>0.880184</td>\n      <td>0.879938</td>\n      <td>0.000399</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>8.446660</td>\n      <td>0.136616</td>\n      <td>0.099708</td>\n      <td>0.015107</td>\n      <td>0.010342</td>\n      <td>None</td>\n      <td>0.000014</td>\n      <td>adaptive</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.010341539918142708, 'model_...</td>\n      <td>0.878602</td>\n      <td>0.879309</td>\n      <td>0.880296</td>\n      <td>0.878776</td>\n      <td>0.879221</td>\n      <td>0.879241</td>\n      <td>0.000590</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>4.839014</td>\n      <td>0.111349</td>\n      <td>0.100382</td>\n      <td>0.014686</td>\n      <td>0.000015</td>\n      <td>None</td>\n      <td>0.000007</td>\n      <td>constant</td>\n      <td>squared_epsilon_insensitive</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1.5102696652058713e-05, 'mode...</td>\n      <td>0.878005</td>\n      <td>0.878128</td>\n      <td>0.879540</td>\n      <td>0.877573</td>\n      <td>0.878697</td>\n      <td>0.878389</td>\n      <td>0.000678</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>7.729733</td>\n      <td>0.162592</td>\n      <td>0.104750</td>\n      <td>0.007520</td>\n      <td>0.00039</td>\n      <td>None</td>\n      <td>0.000004</td>\n      <td>adaptive</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.0003900951285443547, 'model...</td>\n      <td>0.877724</td>\n      <td>0.878218</td>\n      <td>0.879487</td>\n      <td>0.877498</td>\n      <td>0.878997</td>\n      <td>0.878385</td>\n      <td>0.000754</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>2.450732</td>\n      <td>0.091324</td>\n      <td>0.108252</td>\n      <td>0.008745</td>\n      <td>0.1</td>\n      <td>None</td>\n      <td>0.010704</td>\n      <td>invscaling</td>\n      <td>squared_hinge</td>\n      <td>l2</td>\n      <td>{'model__alpha': 0.1, 'model__class_weight': N...</td>\n      <td>0.876894</td>\n      <td>0.876623</td>\n      <td>0.880410</td>\n      <td>0.877984</td>\n      <td>0.878793</td>\n      <td>0.878141</td>\n      <td>0.001375</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>7.238729</td>\n      <td>0.130560</td>\n      <td>0.111458</td>\n      <td>0.017860</td>\n      <td>0.000009</td>\n      <td>None</td>\n      <td>0.000003</td>\n      <td>adaptive</td>\n      <td>squared_epsilon_insensitive</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 9.482542507347432e-06, 'model...</td>\n      <td>0.877010</td>\n      <td>0.876669</td>\n      <td>0.878913</td>\n      <td>0.876956</td>\n      <td>0.878041</td>\n      <td>0.877518</td>\n      <td>0.000838</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>6.751539</td>\n      <td>0.063021</td>\n      <td>0.169013</td>\n      <td>0.015796</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.000023</td>\n      <td>constant</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1.1052532881525498e-06, 'mode...</td>\n      <td>0.877355</td>\n      <td>0.877030</td>\n      <td>0.879074</td>\n      <td>0.876582</td>\n      <td>0.877332</td>\n      <td>0.877475</td>\n      <td>0.000847</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>10.698849</td>\n      <td>0.129318</td>\n      <td>0.106439</td>\n      <td>0.011632</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.000011</td>\n      <td>adaptive</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1e-06, 'model__class_weight':...</td>\n      <td>0.875654</td>\n      <td>0.874753</td>\n      <td>0.878214</td>\n      <td>0.875544</td>\n      <td>0.876788</td>\n      <td>0.876191</td>\n      <td>0.001202</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>4.870979</td>\n      <td>0.151285</td>\n      <td>0.171610</td>\n      <td>0.043110</td>\n      <td>0.002118</td>\n      <td>None</td>\n      <td>0.001112</td>\n      <td>constant</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.0021178262313998253, 'model...</td>\n      <td>0.875093</td>\n      <td>0.876707</td>\n      <td>0.878307</td>\n      <td>0.874782</td>\n      <td>0.874400</td>\n      <td>0.875858</td>\n      <td>0.001455</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>7.634787</td>\n      <td>0.050829</td>\n      <td>0.138515</td>\n      <td>0.008774</td>\n      <td>0.000008</td>\n      <td>None</td>\n      <td>0.000001</td>\n      <td>adaptive</td>\n      <td>squared_epsilon_insensitive</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 8.292082179554043e-06, 'model...</td>\n      <td>0.874561</td>\n      <td>0.874462</td>\n      <td>0.877267</td>\n      <td>0.874952</td>\n      <td>0.875745</td>\n      <td>0.875397</td>\n      <td>0.001038</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6.021076</td>\n      <td>0.056410</td>\n      <td>0.152104</td>\n      <td>0.012401</td>\n      <td>0.011534</td>\n      <td>None</td>\n      <td>0.000978</td>\n      <td>invscaling</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.011533999859559564, 'model_...</td>\n      <td>0.874558</td>\n      <td>0.873954</td>\n      <td>0.877467</td>\n      <td>0.874660</td>\n      <td>0.875502</td>\n      <td>0.875228</td>\n      <td>0.001223</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>9.969043</td>\n      <td>0.084749</td>\n      <td>0.128120</td>\n      <td>0.010469</td>\n      <td>0.005855</td>\n      <td>None</td>\n      <td>0.000328</td>\n      <td>invscaling</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.005854632104963596, 'model_...</td>\n      <td>0.869510</td>\n      <td>0.870075</td>\n      <td>0.874288</td>\n      <td>0.871516</td>\n      <td>0.871708</td>\n      <td>0.871420</td>\n      <td>0.001660</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>13.539746</td>\n      <td>0.078644</td>\n      <td>0.128673</td>\n      <td>0.010444</td>\n      <td>0.053992</td>\n      <td>None</td>\n      <td>0.00008</td>\n      <td>adaptive</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.053991933494224216, 'model_...</td>\n      <td>0.864656</td>\n      <td>0.862577</td>\n      <td>0.864093</td>\n      <td>0.864025</td>\n      <td>0.863719</td>\n      <td>0.863814</td>\n      <td>0.000689</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12.744205</td>\n      <td>0.167670</td>\n      <td>0.126531</td>\n      <td>0.020128</td>\n      <td>0.009949</td>\n      <td>None</td>\n      <td>0.00043</td>\n      <td>invscaling</td>\n      <td>squared_error</td>\n      <td>l1</td>\n      <td>{'model__alpha': 0.009948719998234101, 'model_...</td>\n      <td>0.861706</td>\n      <td>0.861486</td>\n      <td>0.864858</td>\n      <td>0.862569</td>\n      <td>0.862826</td>\n      <td>0.862689</td>\n      <td>0.001196</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>21.221439</td>\n      <td>0.039679</td>\n      <td>0.154127</td>\n      <td>0.004818</td>\n      <td>0.071471</td>\n      <td>None</td>\n      <td>0.085677</td>\n      <td>adaptive</td>\n      <td>log_loss</td>\n      <td>l1</td>\n      <td>{'model__alpha': 0.07147057173391871, 'model__...</td>\n      <td>0.848705</td>\n      <td>0.848705</td>\n      <td>0.848705</td>\n      <td>0.848672</td>\n      <td>0.848672</td>\n      <td>0.848692</td>\n      <td>0.000016</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>11.369349</td>\n      <td>3.437662</td>\n      <td>0.098759</td>\n      <td>0.016708</td>\n      <td>0.000009</td>\n      <td>None</td>\n      <td>0.011026</td>\n      <td>constant</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 9.053436778046378e-06, 'model...</td>\n      <td>0.849436</td>\n      <td>0.829524</td>\n      <td>0.847808</td>\n      <td>0.835244</td>\n      <td>0.826797</td>\n      <td>0.837762</td>\n      <td>0.009291</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>19.750719</td>\n      <td>0.078656</td>\n      <td>0.143224</td>\n      <td>0.011398</td>\n      <td>0.000833</td>\n      <td>None</td>\n      <td>0.000045</td>\n      <td>invscaling</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.000832614559844781, 'model_...</td>\n      <td>0.833769</td>\n      <td>0.834161</td>\n      <td>0.840318</td>\n      <td>0.833241</td>\n      <td>0.835487</td>\n      <td>0.835395</td>\n      <td>0.002571</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>2.592643</td>\n      <td>0.038281</td>\n      <td>0.150293</td>\n      <td>0.008825</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.000001</td>\n      <td>constant</td>\n      <td>perceptron</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1e-06, 'model__class_weight':...</td>\n      <td>0.810883</td>\n      <td>0.832623</td>\n      <td>0.822124</td>\n      <td>0.832820</td>\n      <td>0.828595</td>\n      <td>0.825409</td>\n      <td>0.008233</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>8.057070</td>\n      <td>0.960305</td>\n      <td>0.100893</td>\n      <td>0.010960</td>\n      <td>0.004679</td>\n      <td>balanced</td>\n      <td>0.000007</td>\n      <td>constant</td>\n      <td>squared_epsilon_insensitive</td>\n      <td>l1</td>\n      <td>{'model__alpha': 0.0046788604247112444, 'model...</td>\n      <td>0.820764</td>\n      <td>0.823778</td>\n      <td>0.821549</td>\n      <td>0.816801</td>\n      <td>0.818738</td>\n      <td>0.820326</td>\n      <td>0.002390</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>16.466755</td>\n      <td>1.316583</td>\n      <td>0.111603</td>\n      <td>0.017989</td>\n      <td>0.000521</td>\n      <td>balanced</td>\n      <td>0.000304</td>\n      <td>optimal</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.0005212131190318165, 'model...</td>\n      <td>0.815203</td>\n      <td>0.821658</td>\n      <td>0.821956</td>\n      <td>0.816152</td>\n      <td>0.823749</td>\n      <td>0.819744</td>\n      <td>0.003409</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2.919617</td>\n      <td>0.069355</td>\n      <td>0.141338</td>\n      <td>0.014454</td>\n      <td>0.000007</td>\n      <td>None</td>\n      <td>0.000014</td>\n      <td>constant</td>\n      <td>perceptron</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 6.590713623713951e-06, 'model...</td>\n      <td>0.803554</td>\n      <td>0.815368</td>\n      <td>0.819242</td>\n      <td>0.836698</td>\n      <td>0.809443</td>\n      <td>0.816861</td>\n      <td>0.011256</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>9.581718</td>\n      <td>1.247561</td>\n      <td>0.088993</td>\n      <td>0.013287</td>\n      <td>0.000125</td>\n      <td>None</td>\n      <td>0.004578</td>\n      <td>constant</td>\n      <td>perceptron</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.0001246610255516929, 'model...</td>\n      <td>0.794003</td>\n      <td>0.820598</td>\n      <td>0.838286</td>\n      <td>0.791180</td>\n      <td>0.812198</td>\n      <td>0.811253</td>\n      <td>0.017433</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>167.265213</td>\n      <td>22.007503</td>\n      <td>0.112907</td>\n      <td>0.029585</td>\n      <td>0.000005</td>\n      <td>None</td>\n      <td>0.000005</td>\n      <td>optimal</td>\n      <td>squared_hinge</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 5.3678104049400005e-06, 'mode...</td>\n      <td>0.794833</td>\n      <td>0.795862</td>\n      <td>0.807527</td>\n      <td>0.793580</td>\n      <td>0.808601</td>\n      <td>0.800081</td>\n      <td>0.006567</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>59.840258</td>\n      <td>13.930628</td>\n      <td>0.080434</td>\n      <td>0.009048</td>\n      <td>0.00002</td>\n      <td>None</td>\n      <td>0.000001</td>\n      <td>optimal</td>\n      <td>epsilon_insensitive</td>\n      <td>l1</td>\n      <td>{'model__alpha': 2.042094287865455e-05, 'model...</td>\n      <td>0.795141</td>\n      <td>0.787408</td>\n      <td>0.825270</td>\n      <td>0.794449</td>\n      <td>0.785762</td>\n      <td>0.797606</td>\n      <td>0.014322</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2.804966</td>\n      <td>0.013805</td>\n      <td>0.168298</td>\n      <td>0.013170</td>\n      <td>0.075042</td>\n      <td>None</td>\n      <td>0.000759</td>\n      <td>invscaling</td>\n      <td>perceptron</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.07504203081370357, 'model__...</td>\n      <td>0.772447</td>\n      <td>0.651155</td>\n      <td>0.755722</td>\n      <td>0.789346</td>\n      <td>0.848672</td>\n      <td>0.763469</td>\n      <td>0.064318</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9.181869</td>\n      <td>4.065360</td>\n      <td>0.104187</td>\n      <td>0.021100</td>\n      <td>0.000001</td>\n      <td>balanced</td>\n      <td>0.005086</td>\n      <td>constant</td>\n      <td>perceptron</td>\n      <td>l1</td>\n      <td>{'model__alpha': 1.0426811836320545e-06, 'mode...</td>\n      <td>0.724418</td>\n      <td>0.775093</td>\n      <td>0.755478</td>\n      <td>0.707496</td>\n      <td>0.757212</td>\n      <td>0.743940</td>\n      <td>0.024450</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>104.772197</td>\n      <td>0.209169</td>\n      <td>0.086122</td>\n      <td>0.009601</td>\n      <td>0.08768</td>\n      <td>balanced</td>\n      <td>0.002819</td>\n      <td>optimal</td>\n      <td>squared_hinge</td>\n      <td>l2</td>\n      <td>{'model__alpha': 0.08768010922961404, 'model__...</td>\n      <td>0.738224</td>\n      <td>0.746623</td>\n      <td>0.744615</td>\n      <td>0.739278</td>\n      <td>0.746236</td>\n      <td>0.742995</td>\n      <td>0.003546</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7.321564</td>\n      <td>0.627405</td>\n      <td>0.149416</td>\n      <td>0.020583</td>\n      <td>0.059895</td>\n      <td>balanced</td>\n      <td>0.022817</td>\n      <td>constant</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.05989491205267932, 'model__...</td>\n      <td>0.735046</td>\n      <td>0.735476</td>\n      <td>0.729748</td>\n      <td>0.748294</td>\n      <td>0.742245</td>\n      <td>0.738162</td>\n      <td>0.006435</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>8.578145</td>\n      <td>0.486180</td>\n      <td>0.103963</td>\n      <td>0.010412</td>\n      <td>0.001217</td>\n      <td>balanced</td>\n      <td>0.000062</td>\n      <td>optimal</td>\n      <td>perceptron</td>\n      <td>l1</td>\n      <td>{'model__alpha': 0.0012172976749510152, 'model...</td>\n      <td>0.753267</td>\n      <td>0.746865</td>\n      <td>0.711102</td>\n      <td>0.761169</td>\n      <td>0.700737</td>\n      <td>0.734628</td>\n      <td>0.024098</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>7.502859</td>\n      <td>0.108874</td>\n      <td>0.120712</td>\n      <td>0.009206</td>\n      <td>0.009889</td>\n      <td>None</td>\n      <td>0.000002</td>\n      <td>adaptive</td>\n      <td>huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.009889417540774548, 'model_...</td>\n      <td>0.729440</td>\n      <td>0.728789</td>\n      <td>0.738857</td>\n      <td>0.733757</td>\n      <td>0.728350</td>\n      <td>0.731839</td>\n      <td>0.004004</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>7.398085</td>\n      <td>0.887352</td>\n      <td>0.103516</td>\n      <td>0.022230</td>\n      <td>0.000112</td>\n      <td>balanced</td>\n      <td>0.046168</td>\n      <td>constant</td>\n      <td>perceptron</td>\n      <td>l1</td>\n      <td>{'model__alpha': 0.00011233621690895234, 'mode...</td>\n      <td>0.751342</td>\n      <td>0.707263</td>\n      <td>0.743205</td>\n      <td>0.722060</td>\n      <td>0.729883</td>\n      <td>0.730751</td>\n      <td>0.015537</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>2.516436</td>\n      <td>0.122895</td>\n      <td>0.112285</td>\n      <td>0.013916</td>\n      <td>0.000006</td>\n      <td>None</td>\n      <td>0.000001</td>\n      <td>invscaling</td>\n      <td>squared_error</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 5.823893699289275e-06, 'model...</td>\n      <td>0.716819</td>\n      <td>0.713706</td>\n      <td>0.724965</td>\n      <td>0.720019</td>\n      <td>0.716570</td>\n      <td>0.718416</td>\n      <td>0.003837</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.058184</td>\n      <td>0.038117</td>\n      <td>0.157502</td>\n      <td>0.007238</td>\n      <td>0.000168</td>\n      <td>balanced</td>\n      <td>0.000003</td>\n      <td>constant</td>\n      <td>huber</td>\n      <td>l1</td>\n      <td>{'model__alpha': 0.00016755699440936588, 'mode...</td>\n      <td>0.691503</td>\n      <td>0.694829</td>\n      <td>0.697351</td>\n      <td>0.693888</td>\n      <td>0.687074</td>\n      <td>0.692929</td>\n      <td>0.003475</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>120.565648</td>\n      <td>25.952456</td>\n      <td>0.089698</td>\n      <td>0.011245</td>\n      <td>0.000002</td>\n      <td>None</td>\n      <td>0.049354</td>\n      <td>constant</td>\n      <td>epsilon_insensitive</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1.907041988802392e-06, 'model...</td>\n      <td>0.582830</td>\n      <td>0.620532</td>\n      <td>0.635457</td>\n      <td>0.597138</td>\n      <td>0.637601</td>\n      <td>0.614712</td>\n      <td>0.021510</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>3.710610</td>\n      <td>0.686722</td>\n      <td>0.112147</td>\n      <td>0.016332</td>\n      <td>0.001494</td>\n      <td>None</td>\n      <td>0.019815</td>\n      <td>constant</td>\n      <td>squared_error</td>\n      <td>l1</td>\n      <td>{'model__alpha': 0.0014937568205662616, 'model...</td>\n      <td>0.558026</td>\n      <td>0.629260</td>\n      <td>0.618340</td>\n      <td>0.631818</td>\n      <td>0.605645</td>\n      <td>0.608618</td>\n      <td>0.026934</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>53.762612</td>\n      <td>3.873236</td>\n      <td>0.089229</td>\n      <td>0.014692</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.054998</td>\n      <td>adaptive</td>\n      <td>squared_error</td>\n      <td>l1</td>\n      <td>{'model__alpha': 1.0613730087581182e-06, 'mode...</td>\n      <td>0.571582</td>\n      <td>0.608444</td>\n      <td>0.625949</td>\n      <td>0.595397</td>\n      <td>0.629338</td>\n      <td>0.606142</td>\n      <td>0.021192</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>298.486402</td>\n      <td>0.621144</td>\n      <td>0.117977</td>\n      <td>0.017865</td>\n      <td>0.015379</td>\n      <td>balanced</td>\n      <td>0.000033</td>\n      <td>optimal</td>\n      <td>squared_error</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.01537948446580078, 'model__...</td>\n      <td>0.602855</td>\n      <td>0.603559</td>\n      <td>0.586773</td>\n      <td>0.593342</td>\n      <td>0.601164</td>\n      <td>0.597539</td>\n      <td>0.006499</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>286.520971</td>\n      <td>1.246275</td>\n      <td>0.095616</td>\n      <td>0.015227</td>\n      <td>0.000069</td>\n      <td>None</td>\n      <td>0.038085</td>\n      <td>adaptive</td>\n      <td>squared_epsilon_insensitive</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 6.937084058445544e-05, 'model...</td>\n      <td>0.602704</td>\n      <td>0.613147</td>\n      <td>0.577065</td>\n      <td>0.603865</td>\n      <td>0.589174</td>\n      <td>0.597191</td>\n      <td>0.012640</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>278.651748</td>\n      <td>1.067038</td>\n      <td>0.089523</td>\n      <td>0.017071</td>\n      <td>0.1</td>\n      <td>None</td>\n      <td>0.000051</td>\n      <td>optimal</td>\n      <td>squared_error</td>\n      <td>l1</td>\n      <td>{'model__alpha': 0.1, 'model__class_weight': N...</td>\n      <td>0.597503</td>\n      <td>0.595771</td>\n      <td>0.586406</td>\n      <td>0.581483</td>\n      <td>0.601205</td>\n      <td>0.592474</td>\n      <td>0.007349</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>3.907871</td>\n      <td>0.764192</td>\n      <td>0.106823</td>\n      <td>0.023423</td>\n      <td>0.00001</td>\n      <td>None</td>\n      <td>0.1</td>\n      <td>constant</td>\n      <td>squared_epsilon_insensitive</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 9.560509917296386e-06, 'model...</td>\n      <td>0.599617</td>\n      <td>0.584659</td>\n      <td>0.589793</td>\n      <td>0.556685</td>\n      <td>0.575613</td>\n      <td>0.581274</td>\n      <td>0.014541</td>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgdc_grid_search_dataframe = pd.DataFrame(\n",
    "    np.load(\"Dataset_Files/Baseline_Models/Classification/optimised_sgdc_cv_results.npy\", allow_pickle=True).tolist())\n",
    "sgdc_grid_search_dataframe.sort_values(by=[\"rank_test_score\"], inplace=True)\n",
    "sgdc_grid_search_dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 500\n",
      "--------------------------------------------------------\n",
      "Median Recall: 0.86 with a 95% confidence interval of [0.83,0.90]\n",
      "Median Precision: 0.77 with a 95% confidence interval of [0.73,0.81]\n",
      "Median F1: 0.81 with a 95% confidence interval of [0.78,0.84]\n",
      "Median Accuracy: 0.73 with a 95% confidence interval of [0.69,0.77]\n",
      "Median MCC: 0.32 with a 95% confidence interval of [0.23,0.42]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_sgdc, X_test, y_test, 500, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AlphaFold Project Environment",
   "language": "python",
   "name": "alphafold_dataset_drug_binding_prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
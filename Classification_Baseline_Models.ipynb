{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# General Imports\n",
    "from models_utils import *\n",
    "\n",
    "# Classification Models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "feature_selection_columns = load_from_pickle(\"Training_Test_Sets/Classification/X_train_feature_selection\").loc[:,\n",
    "                            \"MolecularWeight\":].columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = load_from_pickle(\"Training_Test_Sets/Classification/X_train_feature_selection\")\n",
    "X_train.drop(columns=[\"Drug_CID\", \"Protein_Accession\"], inplace=True)\n",
    "X_train = X_train.to_numpy()\n",
    "\n",
    "y_train = load_from_pickle(\"Training_Test_Sets/Classification/y_train\")\n",
    "y_train = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_test = load_from_pickle(\"Training_Test_Sets/Classification/X_test_feature_selection\")\n",
    "X_test.drop(columns=[\"Drug_CID\", \"Protein_Accession\"], inplace=True)\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "y_test = load_from_pickle(\"Training_Test_Sets/Classification/y_test\")\n",
    "y_test = y_test.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (99705, 388)\n",
      "y_train shape: 99705 (Binding Count: 73498, Non-Binding Count: 26207)\n",
      "X_test shape: (816, 388)\n",
      "y_test shape: 816 (Binding Count: 563, Non-Binding Count: 253)\n"
     ]
    }
   ],
   "source": [
    "# Useful Information & Sanity Checks\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape[0]} \", end=\"\")\n",
    "print(f\"(Binding Count: {y_train[y_train == 1].shape[0]}, \", end=\"\")\n",
    "print(f\"Non-Binding Count: {y_train[y_train == 0].shape[0]})\")\n",
    "\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape[0]} \", end=\"\")\n",
    "print(f\"(Binding Count: {y_test[y_test == 1].shape[0]}, \", end=\"\")\n",
    "print(f\"Non-Binding Count: {y_test[y_test == 0].shape[0]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training & Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def on_step(optim_result):\n",
    "    global index\n",
    "    print(f\"Iteration Completed: {index}\")\n",
    "    index += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dummy Classifier (DC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model', DummyClassifier(random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': DummyClassifier(random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__constant': None,\n 'model__random_state': 42,\n 'model__strategy': 'prior'}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_classifier = Pipeline(\n",
    "    [\n",
    "        ('scale', StandardScaler()),\n",
    "        ('model', DummyClassifier(random_state=42))\n",
    "    ]\n",
    ")\n",
    "dummy_classifier.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dummy_classifier.fit(X_train, y_train)\n",
    "#\n",
    "# y_train_pred = dummy_classifier.predict(X_train)\n",
    "# calculate_metrics_classification(y_train, y_train_pred)\n",
    "#\n",
    "# # Save Model\n",
    "# dump(dummy_classifier, 'Dataset_Files/Baseline_Models/Classification/dc.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Load Model\n",
    "dummy_classifier = load('Dataset_Files/Baseline_Models/Classification/dc.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 1000\n",
      "--------------------------------------------------------\n",
      "Median Recall: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median Precision: 0.74 with a 95% confidence interval of [0.71,0.76]\n",
      "Median F1: 0.85 with a 95% confidence interval of [0.83,0.87]\n",
      "Median Accuracy: 0.74 with a 95% confidence interval of [0.71,0.76]\n",
      "Median MCC: 0.00 with a 95% confidence interval of [0.00,0.00]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(dummy_classifier, X_train, y_train, 1000, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 500\n",
      "--------------------------------------------------------\n",
      "Median Recall: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median Precision: 0.69 with a 95% confidence interval of [0.65,0.73]\n",
      "Median F1: 0.82 with a 95% confidence interval of [0.79,0.84]\n",
      "Median Accuracy: 0.69 with a 95% confidence interval of [0.65,0.73]\n",
      "Median MCC: 0.00 with a 95% confidence interval of [0.00,0.00]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(dummy_classifier, X_test, y_test, 500, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Logistic Regression (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model', LogisticRegression(random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': LogisticRegression(random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__C': 1.0,\n 'model__class_weight': None,\n 'model__dual': False,\n 'model__fit_intercept': True,\n 'model__intercept_scaling': 1,\n 'model__l1_ratio': None,\n 'model__max_iter': 100,\n 'model__multi_class': 'auto',\n 'model__n_jobs': None,\n 'model__penalty': 'l2',\n 'model__random_state': 42,\n 'model__solver': 'lbfgs',\n 'model__tol': 0.0001,\n 'model__verbose': 0,\n 'model__warm_start': False}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scale', StandardScaler()),\n",
    "        ('model', LogisticRegression(random_state=42))\n",
    "    ]\n",
    ")\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = BayesSearchCV(estimator=pipe,\n",
    "                      search_spaces=[\n",
    "                          {'model__C': Real(1e-6, 1e+2, prior='log-uniform'),\n",
    "                           'model__solver': Categorical(['newton-cg', 'lbfgs', 'sag']),\n",
    "                           'model__penalty': Categorical(['none', 'l2']),\n",
    "                           'model__max_iter': Integer(50, 5000),\n",
    "                           'model__class_weight': Categorical([None, \"balanced\"])},\n",
    "                          {'model__C': Real(1e-6, 1e+2, prior='log-uniform'),\n",
    "                           'model__solver': Categorical(['liblinear']),\n",
    "                           'model__penalty': Categorical(['l2', 'l1']),\n",
    "                           'model__max_iter': Integer(50, 5000),\n",
    "                           'model__class_weight': Categorical([None, \"balanced\"])},\n",
    "                          {'model__C': Real(1e-6, 1e+2, prior='log-uniform'),\n",
    "                           'model__l1_ratio': Real(0, 1),\n",
    "                           'model__solver': Categorical(['saga']),\n",
    "                           'model__penalty': Categorical(['none', 'l2', 'l1', 'elasticnet']),\n",
    "                           'model__max_iter': Integer(50, 5000),\n",
    "                           'model__class_weight': Categorical([None, \"balanced\"])},\n",
    "                      ],\n",
    "                      scoring='f1',\n",
    "                      cv=5,\n",
    "                      error_score=np.nan,\n",
    "                      n_jobs=-1,\n",
    "                      pre_dispatch='2*n_jobs',\n",
    "                      random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# index = 1\n",
    "# model.fit(X_train, y_train, callback=on_step)\n",
    "#\n",
    "# optimised_lr = model.best_estimator_\n",
    "#\n",
    "# y_train_pred = optimised_lr.predict(X_train)\n",
    "# calculate_metrics_classification(y_train, y_train_pred)\n",
    "#\n",
    "# # Save Model & CV Results\n",
    "# dump(optimised_lr, 'Dataset_Files/Baseline_Models/Classification/optimised_lr.joblib')\n",
    "# np.save(\"Dataset_Files/Baseline_Models/Classification/optimised_lr_cv_results\", model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Load Model\n",
    "optimised_lr = load('Dataset_Files/Baseline_Models/Classification/optimised_lr.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 1000\n",
      "--------------------------------------------------------\n",
      "Median Recall: 0.93 with a 95% confidence interval of [0.91,0.95]\n",
      "Median Precision: 0.84 with a 95% confidence interval of [0.81,0.86]\n",
      "Median F1: 0.88 with a 95% confidence interval of [0.86,0.90]\n",
      "Median Accuracy: 0.82 with a 95% confidence interval of [0.79,0.84]\n",
      "Median MCC: 0.49 with a 95% confidence interval of [0.42,0.55]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_lr, X_train, y_train, 1000, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model',\n   LogisticRegression(C=0.08691067180260512, max_iter=4439, random_state=42,\n                      solver='liblinear'))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': LogisticRegression(C=0.08691067180260512, max_iter=4439, random_state=42,\n                    solver='liblinear'),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__C': 0.08691067180260512,\n 'model__class_weight': None,\n 'model__dual': False,\n 'model__fit_intercept': True,\n 'model__intercept_scaling': 1,\n 'model__l1_ratio': None,\n 'model__max_iter': 4439,\n 'model__multi_class': 'auto',\n 'model__n_jobs': None,\n 'model__penalty': 'l2',\n 'model__random_state': 42,\n 'model__solver': 'liblinear',\n 'model__tol': 0.0001,\n 'model__verbose': 0,\n 'model__warm_start': False}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimised_lr.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n66       55.793100      2.523845         0.132408        0.043119   \n26     2815.406966      2.884060         0.092576        0.014220   \n110      99.473659     44.479059         0.077112        0.012028   \n70      249.368894     19.934678         0.112724        0.023588   \n148      27.944436      0.060402         0.090997        0.005039   \n..             ...           ...              ...             ...   \n50        5.015475      0.039212         0.204767        0.003667   \n67        3.546709      0.147501         0.118602        0.020674   \n101       2.940660      0.183646         0.072081        0.006645   \n86        2.425969      0.030663         0.182416        0.004853   \n87        2.239574      0.043833         0.172363        0.009425   \n\n    param_model__C param_model__class_weight param_model__max_iter  \\\n66        0.086911                      None                  4439   \n26        0.172047                      None                  5000   \n110       0.458579                      None                  3710   \n70        0.276555                      None                    50   \n148       2.752098                      None                    50   \n..             ...                       ...                   ...   \n50        0.000002                      None                  1273   \n67        0.000001                  balanced                  1764   \n101       0.000016                  balanced                  4596   \n86        0.000009                  balanced                  4473   \n87        0.000001                      None                  2972   \n\n    param_model__penalty param_model__solver param_model__l1_ratio  \\\n66                    l2           liblinear                   NaN   \n26                    l2                 sag                   NaN   \n110                   l1                saga              0.709831   \n70                    l1           liblinear                   NaN   \n148                   l2                saga                   0.0   \n..                   ...                 ...                   ...   \n50                    l2           liblinear                   NaN   \n67                    l2           liblinear                   NaN   \n101                   l1                saga              0.473675   \n86                    l1           liblinear                   NaN   \n87                    l1           liblinear                   NaN   \n\n                                                params  split0_test_score  \\\n66   {'model__C': 0.08691067180260512, 'model__clas...           0.881027   \n26   {'model__C': 0.17204723798386953, 'model__clas...           0.881012   \n110  {'model__C': 0.4585792720221234, 'model__class...           0.880919   \n70   {'model__C': 0.2765547591820871, 'model__class...           0.880999   \n148  {'model__C': 2.7520978985242417, 'model__class...           0.880781   \n..                                                 ...                ...   \n50   {'model__C': 2.195551082864074e-06, 'model__cl...           0.738634   \n67   {'model__C': 1e-06, 'model__class_weight': 'ba...           0.693792   \n101  {'model__C': 1.6285217534593228e-05, 'model__c...           0.000000   \n86   {'model__C': 9.132486222789627e-06, 'model__cl...           0.000000   \n87   {'model__C': 1e-06, 'model__class_weight': Non...           0.000000   \n\n     split1_test_score  split2_test_score  split3_test_score  \\\n66            0.879426           0.882736           0.881267   \n26            0.879418           0.882679           0.881265   \n110           0.879570           0.882601           0.881239   \n70            0.879606           0.882495           0.881154   \n148           0.879539           0.882721           0.881100   \n..                 ...                ...                ...   \n50            0.740038           0.748189           0.743261   \n67            0.693219           0.703228           0.698660   \n101           0.848705           0.848705           0.848672   \n86            0.000000           0.000000           0.000000   \n87            0.000000           0.000000           0.000000   \n\n     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n66            0.880858         0.881063        0.001055                1  \n26            0.880830         0.881041        0.001040                2  \n110           0.880801         0.881026        0.000970                3  \n70            0.880868         0.881024        0.000918                4  \n148           0.880907         0.881010        0.001016                5  \n..                 ...              ...             ...              ...  \n50            0.738875         0.741799        0.003595              146  \n67            0.692990         0.696378        0.004007              147  \n101           0.000000         0.509217        0.415774              148  \n86            0.000000         0.000000        0.000000              149  \n87            0.000000         0.000000        0.000000              149  \n\n[150 rows x 19 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_model__C</th>\n      <th>param_model__class_weight</th>\n      <th>param_model__max_iter</th>\n      <th>param_model__penalty</th>\n      <th>param_model__solver</th>\n      <th>param_model__l1_ratio</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>66</th>\n      <td>55.793100</td>\n      <td>2.523845</td>\n      <td>0.132408</td>\n      <td>0.043119</td>\n      <td>0.086911</td>\n      <td>None</td>\n      <td>4439</td>\n      <td>l2</td>\n      <td>liblinear</td>\n      <td>NaN</td>\n      <td>{'model__C': 0.08691067180260512, 'model__clas...</td>\n      <td>0.881027</td>\n      <td>0.879426</td>\n      <td>0.882736</td>\n      <td>0.881267</td>\n      <td>0.880858</td>\n      <td>0.881063</td>\n      <td>0.001055</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>2815.406966</td>\n      <td>2.884060</td>\n      <td>0.092576</td>\n      <td>0.014220</td>\n      <td>0.172047</td>\n      <td>None</td>\n      <td>5000</td>\n      <td>l2</td>\n      <td>sag</td>\n      <td>NaN</td>\n      <td>{'model__C': 0.17204723798386953, 'model__clas...</td>\n      <td>0.881012</td>\n      <td>0.879418</td>\n      <td>0.882679</td>\n      <td>0.881265</td>\n      <td>0.880830</td>\n      <td>0.881041</td>\n      <td>0.001040</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>110</th>\n      <td>99.473659</td>\n      <td>44.479059</td>\n      <td>0.077112</td>\n      <td>0.012028</td>\n      <td>0.458579</td>\n      <td>None</td>\n      <td>3710</td>\n      <td>l1</td>\n      <td>saga</td>\n      <td>0.709831</td>\n      <td>{'model__C': 0.4585792720221234, 'model__class...</td>\n      <td>0.880919</td>\n      <td>0.879570</td>\n      <td>0.882601</td>\n      <td>0.881239</td>\n      <td>0.880801</td>\n      <td>0.881026</td>\n      <td>0.000970</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>249.368894</td>\n      <td>19.934678</td>\n      <td>0.112724</td>\n      <td>0.023588</td>\n      <td>0.276555</td>\n      <td>None</td>\n      <td>50</td>\n      <td>l1</td>\n      <td>liblinear</td>\n      <td>NaN</td>\n      <td>{'model__C': 0.2765547591820871, 'model__class...</td>\n      <td>0.880999</td>\n      <td>0.879606</td>\n      <td>0.882495</td>\n      <td>0.881154</td>\n      <td>0.880868</td>\n      <td>0.881024</td>\n      <td>0.000918</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>27.944436</td>\n      <td>0.060402</td>\n      <td>0.090997</td>\n      <td>0.005039</td>\n      <td>2.752098</td>\n      <td>None</td>\n      <td>50</td>\n      <td>l2</td>\n      <td>saga</td>\n      <td>0.0</td>\n      <td>{'model__C': 2.7520978985242417, 'model__class...</td>\n      <td>0.880781</td>\n      <td>0.879539</td>\n      <td>0.882721</td>\n      <td>0.881100</td>\n      <td>0.880907</td>\n      <td>0.881010</td>\n      <td>0.001016</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>5.015475</td>\n      <td>0.039212</td>\n      <td>0.204767</td>\n      <td>0.003667</td>\n      <td>0.000002</td>\n      <td>None</td>\n      <td>1273</td>\n      <td>l2</td>\n      <td>liblinear</td>\n      <td>NaN</td>\n      <td>{'model__C': 2.195551082864074e-06, 'model__cl...</td>\n      <td>0.738634</td>\n      <td>0.740038</td>\n      <td>0.748189</td>\n      <td>0.743261</td>\n      <td>0.738875</td>\n      <td>0.741799</td>\n      <td>0.003595</td>\n      <td>146</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>3.546709</td>\n      <td>0.147501</td>\n      <td>0.118602</td>\n      <td>0.020674</td>\n      <td>0.000001</td>\n      <td>balanced</td>\n      <td>1764</td>\n      <td>l2</td>\n      <td>liblinear</td>\n      <td>NaN</td>\n      <td>{'model__C': 1e-06, 'model__class_weight': 'ba...</td>\n      <td>0.693792</td>\n      <td>0.693219</td>\n      <td>0.703228</td>\n      <td>0.698660</td>\n      <td>0.692990</td>\n      <td>0.696378</td>\n      <td>0.004007</td>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>2.940660</td>\n      <td>0.183646</td>\n      <td>0.072081</td>\n      <td>0.006645</td>\n      <td>0.000016</td>\n      <td>balanced</td>\n      <td>4596</td>\n      <td>l1</td>\n      <td>saga</td>\n      <td>0.473675</td>\n      <td>{'model__C': 1.6285217534593228e-05, 'model__c...</td>\n      <td>0.000000</td>\n      <td>0.848705</td>\n      <td>0.848705</td>\n      <td>0.848672</td>\n      <td>0.000000</td>\n      <td>0.509217</td>\n      <td>0.415774</td>\n      <td>148</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>2.425969</td>\n      <td>0.030663</td>\n      <td>0.182416</td>\n      <td>0.004853</td>\n      <td>0.000009</td>\n      <td>balanced</td>\n      <td>4473</td>\n      <td>l1</td>\n      <td>liblinear</td>\n      <td>NaN</td>\n      <td>{'model__C': 9.132486222789627e-06, 'model__cl...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>149</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>2.239574</td>\n      <td>0.043833</td>\n      <td>0.172363</td>\n      <td>0.009425</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>2972</td>\n      <td>l1</td>\n      <td>liblinear</td>\n      <td>NaN</td>\n      <td>{'model__C': 1e-06, 'model__class_weight': Non...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>149</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows × 19 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_grid_search_dataframe = pd.DataFrame(\n",
    "    np.load(\"Dataset_Files/Baseline_Models/Classification/optimised_lr_cv_results.npy\", allow_pickle=True).tolist())\n",
    "logistic_regression_grid_search_dataframe.sort_values(by=[\"rank_test_score\"], inplace=True)\n",
    "logistic_regression_grid_search_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 500\n",
      "--------------------------------------------------------\n",
      "Median Recall: 0.86 with a 95% confidence interval of [0.83,0.90]\n",
      "Median Precision: 0.77 with a 95% confidence interval of [0.73,0.81]\n",
      "Median F1: 0.82 with a 95% confidence interval of [0.78,0.85]\n",
      "Median Accuracy: 0.73 with a 95% confidence interval of [0.69,0.77]\n",
      "Median MCC: 0.32 with a 95% confidence interval of [0.23,0.42]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_lr, X_test, y_test, 500, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear Support Vector Classification (LSVC)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()), ('model', LinearSVC(random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': LinearSVC(random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__C': 1.0,\n 'model__class_weight': None,\n 'model__dual': True,\n 'model__fit_intercept': True,\n 'model__intercept_scaling': 1,\n 'model__loss': 'squared_hinge',\n 'model__max_iter': 1000,\n 'model__multi_class': 'ovr',\n 'model__penalty': 'l2',\n 'model__random_state': 42,\n 'model__tol': 0.0001,\n 'model__verbose': 0}"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scale', StandardScaler()),\n",
    "        ('model', LinearSVC(random_state=42, penalty='l2'))\n",
    "    ]\n",
    ")\n",
    "pipe.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "model = BayesSearchCV(estimator=pipe,\n",
    "                      search_spaces={'model__loss': Categorical(['hinge', 'squared_hinge']),\n",
    "                                     'model__C': Real(1e-6, 1e+2, prior='log-uniform'),\n",
    "                                     'model__class_weight': Categorical([None, \"balanced\"]),\n",
    "                                     'model__max_iter': Integer(500, 5000)},\n",
    "                      scoring='f1',\n",
    "                      cv=5,\n",
    "                      error_score=np.nan,\n",
    "                      n_jobs=-1,\n",
    "                      pre_dispatch='2*n_jobs',\n",
    "                      random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# index = 1\n",
    "# model.fit(X_train, y_train, callback=on_step)\n",
    "#\n",
    "# optimised_lsvc = model.best_estimator_\n",
    "#\n",
    "# y_train_pred = optimised_lsvc.predict(X_train)\n",
    "# calculate_metrics_classification(y_train, y_train_pred)\n",
    "#\n",
    "# # Save Model & CV Results\n",
    "# dump(optimised_lsvc, 'Dataset_Files/Baseline_Models/Classification/optimised_lsvc.joblib')\n",
    "# np.save(\"Dataset_Files/Baseline_Models/Classification/optimised_lsvc_cv_results.npy\", model.cv_results_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Load Model\n",
    "optimised_lsvc = load('Dataset_Files/Baseline_Models/Classification/optimised_lsvc.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 1000\n",
      "--------------------------------------------------------\n",
      "Median Recall: 0.94 with a 95% confidence interval of [0.92,0.95]\n",
      "Median Precision: 0.84 with a 95% confidence interval of [0.81,0.86]\n",
      "Median F1: 0.88 with a 95% confidence interval of [0.87,0.90]\n",
      "Median Accuracy: 0.82 with a 95% confidence interval of [0.79,0.84]\n",
      "Median MCC: 0.49 with a 95% confidence interval of [0.43,0.55]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_lsvc, X_train, y_train, 1000, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model',\n   LinearSVC(C=0.1380447014995764, loss='hinge', max_iter=3709, random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': LinearSVC(C=0.1380447014995764, loss='hinge', max_iter=3709, random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__C': 0.1380447014995764,\n 'model__class_weight': None,\n 'model__dual': True,\n 'model__fit_intercept': True,\n 'model__intercept_scaling': 1,\n 'model__loss': 'hinge',\n 'model__max_iter': 3709,\n 'model__multi_class': 'ovr',\n 'model__penalty': 'l2',\n 'model__random_state': 42,\n 'model__tol': 0.0001,\n 'model__verbose': 0}"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimised_lsvc.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n36     118.052291      1.109156         0.267848        0.035558   \n27      68.849699      0.879660         0.278061        0.048183   \n47      26.869208      0.263102         0.110933        0.018699   \n35     141.892981      1.392536         0.277655        0.025748   \n37      42.512370      0.342727         0.353301        0.097358   \n44     169.831090      1.389224         0.118468        0.020090   \n11     296.117881      2.094355         0.175879        0.038099   \n14      28.360347      0.292943         0.187140        0.035945   \n28      25.389982      0.158025         0.332762        0.015867   \n15      13.524660      0.224726         0.160166        0.035083   \n13      15.010084      0.233330         0.205424        0.030478   \n39       7.842014      0.063153         0.139061        0.015650   \n45       5.020756      0.054922         0.186843        0.017749   \n25     149.880685      0.310445         0.274437        0.049648   \n48     611.437613     58.544506         0.121409        0.013648   \n20     771.935747      1.368396         0.131113        0.029190   \n21     412.567679      0.981906         0.128559        0.027845   \n26     911.965336      1.507382         0.276249        0.058067   \n33     116.090260     20.056046         0.242836        0.041755   \n23    1023.824014      2.290465         0.286916        0.022857   \n49      85.043209      0.366886         0.121957        0.006294   \n31      22.760233      1.005423         0.236901        0.028053   \n29      14.790688      0.743672         0.251940        0.032489   \n24      13.984725      0.847896         0.249698        0.042019   \n32       9.707024      0.196035         0.281170        0.026580   \n4      590.877874      1.166030         0.123632        0.020106   \n30       7.781186      0.148114         0.270777        0.005686   \n10     100.775869      0.137673         0.206002        0.011858   \n22       6.377747      0.508341         0.106082        0.028090   \n40       3.790051      0.071753         0.182783        0.007246   \n16       4.376968      0.038433         0.198150        0.015893   \n3      694.955791      0.528573         0.108702        0.015464   \n43       3.817455      0.060822         0.195877        0.016906   \n18       5.016402      0.218525         0.169953        0.026093   \n46       3.744259      0.037101         0.160122        0.011777   \n34       5.948197      1.055979         0.246611        0.051239   \n38    1044.583379      0.509100         0.117302        0.028650   \n6       63.761827      0.336938         0.124023        0.025984   \n7       22.498485      0.208984         0.120853        0.016997   \n5      189.953322      1.027424         0.140368        0.023502   \n2       11.072094      0.187763         0.155932        0.020495   \n1      699.235452      1.017112         0.173472        0.031814   \n41     681.326954      1.056109         0.108217        0.016551   \n0       25.624570      1.357725         0.103357        0.013794   \n19     131.597474      0.374998         0.133420        0.012072   \n17     804.989544      0.529906         0.135393        0.018506   \n42       4.285828      0.423871         0.137486        0.013661   \n8      464.071592      0.305549         0.126450        0.022532   \n9        5.212596      0.096365         0.201239        0.028343   \n12       4.057702      0.046689         0.288904        0.033302   \n\n   param_model__C param_model__class_weight param_model__loss  \\\n36       0.138045                      None             hinge   \n27        0.07581                      None             hinge   \n47       0.045751                      None             hinge   \n35       0.172145                      None             hinge   \n37       0.052407                      None             hinge   \n44       0.538708                      None             hinge   \n11       0.743033                      None             hinge   \n14       0.032194                      None             hinge   \n28       0.014692                      None             hinge   \n15       0.013968                      None             hinge   \n13       0.005555                      None             hinge   \n39       0.004797                      None             hinge   \n45       0.003031                      None             hinge   \n25       0.039382                      None     squared_hinge   \n48       0.052175                      None     squared_hinge   \n20       0.264474                      None     squared_hinge   \n21       0.081255                      None     squared_hinge   \n26       0.458997                      None     squared_hinge   \n33       0.006776                      None     squared_hinge   \n23       1.131329                      None     squared_hinge   \n49       0.116385                      None     squared_hinge   \n31       0.001056                      None     squared_hinge   \n29       0.000592                      None     squared_hinge   \n24       0.001381                      None             hinge   \n32       0.000214                      None     squared_hinge   \n4        2.491309                      None     squared_hinge   \n30       0.000097                      None     squared_hinge   \n10       0.350239                      None     squared_hinge   \n22       0.000619                      None             hinge   \n40       0.000062                      None     squared_hinge   \n16       0.000488                      None             hinge   \n3        3.156225                      None     squared_hinge   \n43       0.000037                      None     squared_hinge   \n18       0.000076                      None             hinge   \n46       0.000008                      None     squared_hinge   \n34       0.000032                      None             hinge   \n38      19.190776                      None     squared_hinge   \n6        0.086424                  balanced             hinge   \n7        0.022245                  balanced             hinge   \n5        0.745116                  balanced             hinge   \n2         0.00362                  balanced             hinge   \n1        5.001576                  balanced             hinge   \n41       0.150803                  balanced     squared_hinge   \n0        0.001909                  balanced     squared_hinge   \n19       2.576424                      None             hinge   \n17      99.334634                      None             hinge   \n42       0.000084                  balanced             hinge   \n8       44.037625                  balanced     squared_hinge   \n9        0.000001                  balanced     squared_hinge   \n12       0.000001                      None             hinge   \n\n   param_model__max_iter                                             params  \\\n36                  3709  {'model__C': 0.1380447014995764, 'model__class...   \n27                  2099  {'model__C': 0.07580988177176091, 'model__clas...   \n47                  3711  {'model__C': 0.045751052954376946, 'model__cla...   \n35                  4946  {'model__C': 0.1721453720296977, 'model__class...   \n37                   500  {'model__C': 0.052407004122209624, 'model__cla...   \n44                  5000  {'model__C': 0.5387084648932836, 'model__class...   \n11                  4770  {'model__C': 0.7430332959877312, 'model__class...   \n14                  5000  {'model__C': 0.03219377091560028, 'model__clas...   \n28                  2867  {'model__C': 0.01469227089101338, 'model__clas...   \n15                   513  {'model__C': 0.013967868241974836, 'model__cla...   \n13                  4936  {'model__C': 0.00555534437946428, 'model__clas...   \n39                  1614  {'model__C': 0.004797305476167124, 'model__cla...   \n45                   500  {'model__C': 0.0030308919904399726, 'model__cl...   \n25                   500  {'model__C': 0.03938209697001779, 'model__clas...   \n48                  5000  {'model__C': 0.05217478142578604, 'model__clas...   \n20                  5000  {'model__C': 0.2644743677880158, 'model__class...   \n21                  2521  {'model__C': 0.08125487389127094, 'model__clas...   \n26                  3060  {'model__C': 0.4589969036051254, 'model__class...   \n33                  5000  {'model__C': 0.006776175185943892, 'model__cla...   \n23                  5000  {'model__C': 1.1313292661182266, 'model__class...   \n49                   500  {'model__C': 0.11638526459687938, 'model__clas...   \n31                   500  {'model__C': 0.0010556527784712365, 'model__cl...   \n29                  5000  {'model__C': 0.0005921590488276713, 'model__cl...   \n24                  2703  {'model__C': 0.001380765290289825, 'model__cla...   \n32                  2735  {'model__C': 0.00021382241224399877, 'model__c...   \n4                   3721  {'model__C': 2.491308632420524, 'model__class_...   \n30                   500  {'model__C': 9.657669098785221e-05, 'model__cl...   \n10                   500  {'model__C': 0.3502393891414413, 'model__class...   \n22                  5000  {'model__C': 0.0006187840005129989, 'model__cl...   \n40                  5000  {'model__C': 6.213259856244187e-05, 'model__cl...   \n16                   500  {'model__C': 0.00048761423845638266, 'model__c...   \n3                   4112  {'model__C': 3.1562246465541888, 'model__class...   \n43                  2685  {'model__C': 3.6685285478109704e-05, 'model__c...   \n18                  4856  {'model__C': 7.605225223648453e-05, 'model__cl...   \n46                   519  {'model__C': 8.435601353254293e-06, 'model__cl...   \n34                   500  {'model__C': 3.1953755780018515e-05, 'model__c...   \n38                  4991  {'model__C': 19.190776178531312, 'model__class...   \n6                   4434  {'model__C': 0.08642410048155082, 'model__clas...   \n7                   4269  {'model__C': 0.022244596968016832, 'model__cla...   \n5                   1348  {'model__C': 0.7451164370027008, 'model__class...   \n2                   2450  {'model__C': 0.003619595990038508, 'model__cla...   \n1                   4781  {'model__C': 5.001575677983704, 'model__class_...   \n41                  4246  {'model__C': 0.15080272165641095, 'model__clas...   \n0                   1921  {'model__C': 0.0019091131576909443, 'model__cl...   \n19                   513  {'model__C': 2.576423799733396, 'model__class_...   \n17                  4103  {'model__C': 99.33463392847965, 'model__class_...   \n42                   571  {'model__C': 8.405612361362026e-05, 'model__cl...   \n8                   2371  {'model__C': 44.037625157309144, 'model__class...   \n9                   1645  {'model__C': 1.0691593986059968e-06, 'model__c...   \n12                  4849  {'model__C': 1e-06, 'model__class_weight': Non...   \n\n    split0_test_score  split1_test_score  split2_test_score  \\\n36           0.881801           0.882608           0.882870   \n27           0.882007           0.882444           0.882729   \n47           0.882002           0.882623           0.882730   \n35           0.881786           0.882472           0.882821   \n37           0.881790           0.882557           0.882779   \n44           0.881716           0.882493           0.882793   \n11           0.881729           0.882506           0.882689   \n14           0.881711           0.882211           0.882432   \n28           0.881939           0.882255           0.882100   \n15           0.881718           0.882234           0.882013   \n13           0.881632           0.881261           0.881776   \n39           0.881427           0.880790           0.881694   \n45           0.880872           0.880126           0.881705   \n25           0.879051           0.880041           0.881728   \n48           0.879023           0.880005           0.881636   \n20           0.879046           0.880013           0.881628   \n21           0.878938           0.880005           0.881636   \n26           0.879023           0.879985           0.881620   \n33           0.879418           0.879749           0.881596   \n23           0.878925           0.879879           0.881598   \n49           0.879050           0.879956           0.881494   \n31           0.879447           0.879621           0.881020   \n29           0.879857           0.879317           0.880737   \n24           0.879288           0.878618           0.880529   \n32           0.878524           0.878848           0.880143   \n4            0.879086           0.877277           0.878736   \n30           0.876841           0.877268           0.878548   \n10           0.877201           0.878223           0.876580   \n22           0.875837           0.876274           0.878091   \n40           0.876036           0.876538           0.877747   \n16           0.874725           0.874901           0.877304   \n3            0.875531           0.873759           0.875420   \n43           0.872764           0.874067           0.876078   \n18           0.861732           0.861345           0.864796   \n46           0.860740           0.861583           0.865152   \n34           0.855093           0.854795           0.858568   \n38           0.825028           0.838569           0.827313   \n6            0.831175           0.832855           0.831931   \n7            0.831413           0.832437           0.832425   \n5            0.831197           0.830718           0.832438   \n2            0.830317           0.831122           0.832127   \n1            0.827334           0.830760           0.829129   \n41           0.825051           0.827224           0.828343   \n0            0.825322           0.827007           0.827450   \n19           0.831415           0.818033           0.822409   \n17           0.812772           0.812948           0.806522   \n42           0.802268           0.801766           0.803975   \n8            0.792139           0.763830           0.814554   \n9            0.723185           0.724696           0.731959   \n12           0.712968           0.711833           0.723109   \n\n    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n36           0.882889           0.883740         0.882782        0.000621   \n27           0.882889           0.883684         0.882750        0.000554   \n47           0.882790           0.883463         0.882722        0.000465   \n35           0.882866           0.883576         0.882704        0.000583   \n37           0.882911           0.883441         0.882696        0.000538   \n44           0.882941           0.883478         0.882684        0.000580   \n11           0.882601           0.883685         0.882642        0.000623   \n14           0.882820           0.883478         0.882531        0.000594   \n28           0.882593           0.883252         0.882428        0.000465   \n15           0.882680           0.883210         0.882371        0.000524   \n13           0.882463           0.883121         0.882051        0.000662   \n39           0.882300           0.882908         0.881824        0.000728   \n45           0.882056           0.881743         0.881300        0.000706   \n25           0.880627           0.881239         0.880537        0.000935   \n48           0.880627           0.881231         0.880504        0.000924   \n20           0.880612           0.881187         0.880497        0.000906   \n21           0.880591           0.881231         0.880480        0.000950   \n26           0.880311           0.881216         0.880431        0.000919   \n33           0.880429           0.880928         0.880424        0.000787   \n23           0.880355           0.880854         0.880322        0.000901   \n49           0.880370           0.880630         0.880300        0.000802   \n31           0.880116           0.880540         0.880149        0.000580   \n29           0.879695           0.880200         0.879961        0.000481   \n24           0.880923           0.879353         0.879742        0.000853   \n32           0.878466           0.878882         0.878972        0.000609   \n4            0.877208           0.878434         0.878148        0.000768   \n30           0.877579           0.877966         0.877640        0.000585   \n10           0.878403           0.875174         0.877116        0.001179   \n22           0.877464           0.877598         0.877053        0.000852   \n40           0.876619           0.877756         0.876939        0.000693   \n16           0.877044           0.877003         0.876195        0.001135   \n3            0.876503           0.875322         0.875307        0.000882   \n43           0.874636           0.875807         0.874670        0.001206   \n18           0.863012           0.862944         0.862766        0.001208   \n46           0.861862           0.864009         0.862669        0.001644   \n34           0.855336           0.856430         0.856044        0.001377   \n38           0.839358           0.834100         0.832874        0.005805   \n6            0.830593           0.831549         0.831621        0.000759   \n7            0.830435           0.830939         0.831530        0.000798   \n5            0.829093           0.830200         0.830729        0.001104   \n2            0.829261           0.829518         0.830469        0.001055   \n1            0.827239           0.828813         0.828655        0.001299   \n41           0.823516           0.823768         0.825581        0.001906   \n0            0.823443           0.823646         0.825374        0.001655   \n19           0.816078           0.825342         0.822655        0.005452   \n17           0.804379           0.801151         0.807554        0.004658   \n42           0.800688           0.797680         0.801275        0.002087   \n8            0.756638           0.809883         0.787409        0.023525   \n9            0.725389           0.721253         0.725296        0.003621   \n12           0.718041           0.713101         0.715810        0.004231   \n\n    rank_test_score  \n36                1  \n27                2  \n47                3  \n35                4  \n37                5  \n44                6  \n11                7  \n14                8  \n28                9  \n15               10  \n13               11  \n39               12  \n45               13  \n25               14  \n48               15  \n20               16  \n21               17  \n26               18  \n33               19  \n23               20  \n49               21  \n31               22  \n29               23  \n24               24  \n32               25  \n4                26  \n30               27  \n10               28  \n22               29  \n40               30  \n16               31  \n3                32  \n43               33  \n18               34  \n46               35  \n34               36  \n38               37  \n6                38  \n7                39  \n5                40  \n2                41  \n1                42  \n41               43  \n0                44  \n19               45  \n17               46  \n42               47  \n8                48  \n9                49  \n12               50  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_model__C</th>\n      <th>param_model__class_weight</th>\n      <th>param_model__loss</th>\n      <th>param_model__max_iter</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>36</th>\n      <td>118.052291</td>\n      <td>1.109156</td>\n      <td>0.267848</td>\n      <td>0.035558</td>\n      <td>0.138045</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>3709</td>\n      <td>{'model__C': 0.1380447014995764, 'model__class...</td>\n      <td>0.881801</td>\n      <td>0.882608</td>\n      <td>0.882870</td>\n      <td>0.882889</td>\n      <td>0.883740</td>\n      <td>0.882782</td>\n      <td>0.000621</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>68.849699</td>\n      <td>0.879660</td>\n      <td>0.278061</td>\n      <td>0.048183</td>\n      <td>0.07581</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>2099</td>\n      <td>{'model__C': 0.07580988177176091, 'model__clas...</td>\n      <td>0.882007</td>\n      <td>0.882444</td>\n      <td>0.882729</td>\n      <td>0.882889</td>\n      <td>0.883684</td>\n      <td>0.882750</td>\n      <td>0.000554</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>26.869208</td>\n      <td>0.263102</td>\n      <td>0.110933</td>\n      <td>0.018699</td>\n      <td>0.045751</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>3711</td>\n      <td>{'model__C': 0.045751052954376946, 'model__cla...</td>\n      <td>0.882002</td>\n      <td>0.882623</td>\n      <td>0.882730</td>\n      <td>0.882790</td>\n      <td>0.883463</td>\n      <td>0.882722</td>\n      <td>0.000465</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>141.892981</td>\n      <td>1.392536</td>\n      <td>0.277655</td>\n      <td>0.025748</td>\n      <td>0.172145</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>4946</td>\n      <td>{'model__C': 0.1721453720296977, 'model__class...</td>\n      <td>0.881786</td>\n      <td>0.882472</td>\n      <td>0.882821</td>\n      <td>0.882866</td>\n      <td>0.883576</td>\n      <td>0.882704</td>\n      <td>0.000583</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>42.512370</td>\n      <td>0.342727</td>\n      <td>0.353301</td>\n      <td>0.097358</td>\n      <td>0.052407</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>500</td>\n      <td>{'model__C': 0.052407004122209624, 'model__cla...</td>\n      <td>0.881790</td>\n      <td>0.882557</td>\n      <td>0.882779</td>\n      <td>0.882911</td>\n      <td>0.883441</td>\n      <td>0.882696</td>\n      <td>0.000538</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>169.831090</td>\n      <td>1.389224</td>\n      <td>0.118468</td>\n      <td>0.020090</td>\n      <td>0.538708</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 0.5387084648932836, 'model__class...</td>\n      <td>0.881716</td>\n      <td>0.882493</td>\n      <td>0.882793</td>\n      <td>0.882941</td>\n      <td>0.883478</td>\n      <td>0.882684</td>\n      <td>0.000580</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>296.117881</td>\n      <td>2.094355</td>\n      <td>0.175879</td>\n      <td>0.038099</td>\n      <td>0.743033</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>4770</td>\n      <td>{'model__C': 0.7430332959877312, 'model__class...</td>\n      <td>0.881729</td>\n      <td>0.882506</td>\n      <td>0.882689</td>\n      <td>0.882601</td>\n      <td>0.883685</td>\n      <td>0.882642</td>\n      <td>0.000623</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>28.360347</td>\n      <td>0.292943</td>\n      <td>0.187140</td>\n      <td>0.035945</td>\n      <td>0.032194</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 0.03219377091560028, 'model__clas...</td>\n      <td>0.881711</td>\n      <td>0.882211</td>\n      <td>0.882432</td>\n      <td>0.882820</td>\n      <td>0.883478</td>\n      <td>0.882531</td>\n      <td>0.000594</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>25.389982</td>\n      <td>0.158025</td>\n      <td>0.332762</td>\n      <td>0.015867</td>\n      <td>0.014692</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>2867</td>\n      <td>{'model__C': 0.01469227089101338, 'model__clas...</td>\n      <td>0.881939</td>\n      <td>0.882255</td>\n      <td>0.882100</td>\n      <td>0.882593</td>\n      <td>0.883252</td>\n      <td>0.882428</td>\n      <td>0.000465</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>13.524660</td>\n      <td>0.224726</td>\n      <td>0.160166</td>\n      <td>0.035083</td>\n      <td>0.013968</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>513</td>\n      <td>{'model__C': 0.013967868241974836, 'model__cla...</td>\n      <td>0.881718</td>\n      <td>0.882234</td>\n      <td>0.882013</td>\n      <td>0.882680</td>\n      <td>0.883210</td>\n      <td>0.882371</td>\n      <td>0.000524</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>15.010084</td>\n      <td>0.233330</td>\n      <td>0.205424</td>\n      <td>0.030478</td>\n      <td>0.005555</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>4936</td>\n      <td>{'model__C': 0.00555534437946428, 'model__clas...</td>\n      <td>0.881632</td>\n      <td>0.881261</td>\n      <td>0.881776</td>\n      <td>0.882463</td>\n      <td>0.883121</td>\n      <td>0.882051</td>\n      <td>0.000662</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>7.842014</td>\n      <td>0.063153</td>\n      <td>0.139061</td>\n      <td>0.015650</td>\n      <td>0.004797</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>1614</td>\n      <td>{'model__C': 0.004797305476167124, 'model__cla...</td>\n      <td>0.881427</td>\n      <td>0.880790</td>\n      <td>0.881694</td>\n      <td>0.882300</td>\n      <td>0.882908</td>\n      <td>0.881824</td>\n      <td>0.000728</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>5.020756</td>\n      <td>0.054922</td>\n      <td>0.186843</td>\n      <td>0.017749</td>\n      <td>0.003031</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>500</td>\n      <td>{'model__C': 0.0030308919904399726, 'model__cl...</td>\n      <td>0.880872</td>\n      <td>0.880126</td>\n      <td>0.881705</td>\n      <td>0.882056</td>\n      <td>0.881743</td>\n      <td>0.881300</td>\n      <td>0.000706</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>149.880685</td>\n      <td>0.310445</td>\n      <td>0.274437</td>\n      <td>0.049648</td>\n      <td>0.039382</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>500</td>\n      <td>{'model__C': 0.03938209697001779, 'model__clas...</td>\n      <td>0.879051</td>\n      <td>0.880041</td>\n      <td>0.881728</td>\n      <td>0.880627</td>\n      <td>0.881239</td>\n      <td>0.880537</td>\n      <td>0.000935</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>611.437613</td>\n      <td>58.544506</td>\n      <td>0.121409</td>\n      <td>0.013648</td>\n      <td>0.052175</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 0.05217478142578604, 'model__clas...</td>\n      <td>0.879023</td>\n      <td>0.880005</td>\n      <td>0.881636</td>\n      <td>0.880627</td>\n      <td>0.881231</td>\n      <td>0.880504</td>\n      <td>0.000924</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>771.935747</td>\n      <td>1.368396</td>\n      <td>0.131113</td>\n      <td>0.029190</td>\n      <td>0.264474</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 0.2644743677880158, 'model__class...</td>\n      <td>0.879046</td>\n      <td>0.880013</td>\n      <td>0.881628</td>\n      <td>0.880612</td>\n      <td>0.881187</td>\n      <td>0.880497</td>\n      <td>0.000906</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>412.567679</td>\n      <td>0.981906</td>\n      <td>0.128559</td>\n      <td>0.027845</td>\n      <td>0.081255</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>2521</td>\n      <td>{'model__C': 0.08125487389127094, 'model__clas...</td>\n      <td>0.878938</td>\n      <td>0.880005</td>\n      <td>0.881636</td>\n      <td>0.880591</td>\n      <td>0.881231</td>\n      <td>0.880480</td>\n      <td>0.000950</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>911.965336</td>\n      <td>1.507382</td>\n      <td>0.276249</td>\n      <td>0.058067</td>\n      <td>0.458997</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>3060</td>\n      <td>{'model__C': 0.4589969036051254, 'model__class...</td>\n      <td>0.879023</td>\n      <td>0.879985</td>\n      <td>0.881620</td>\n      <td>0.880311</td>\n      <td>0.881216</td>\n      <td>0.880431</td>\n      <td>0.000919</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>116.090260</td>\n      <td>20.056046</td>\n      <td>0.242836</td>\n      <td>0.041755</td>\n      <td>0.006776</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 0.006776175185943892, 'model__cla...</td>\n      <td>0.879418</td>\n      <td>0.879749</td>\n      <td>0.881596</td>\n      <td>0.880429</td>\n      <td>0.880928</td>\n      <td>0.880424</td>\n      <td>0.000787</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>1023.824014</td>\n      <td>2.290465</td>\n      <td>0.286916</td>\n      <td>0.022857</td>\n      <td>1.131329</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 1.1313292661182266, 'model__class...</td>\n      <td>0.878925</td>\n      <td>0.879879</td>\n      <td>0.881598</td>\n      <td>0.880355</td>\n      <td>0.880854</td>\n      <td>0.880322</td>\n      <td>0.000901</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>85.043209</td>\n      <td>0.366886</td>\n      <td>0.121957</td>\n      <td>0.006294</td>\n      <td>0.116385</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>500</td>\n      <td>{'model__C': 0.11638526459687938, 'model__clas...</td>\n      <td>0.879050</td>\n      <td>0.879956</td>\n      <td>0.881494</td>\n      <td>0.880370</td>\n      <td>0.880630</td>\n      <td>0.880300</td>\n      <td>0.000802</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>22.760233</td>\n      <td>1.005423</td>\n      <td>0.236901</td>\n      <td>0.028053</td>\n      <td>0.001056</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>500</td>\n      <td>{'model__C': 0.0010556527784712365, 'model__cl...</td>\n      <td>0.879447</td>\n      <td>0.879621</td>\n      <td>0.881020</td>\n      <td>0.880116</td>\n      <td>0.880540</td>\n      <td>0.880149</td>\n      <td>0.000580</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>14.790688</td>\n      <td>0.743672</td>\n      <td>0.251940</td>\n      <td>0.032489</td>\n      <td>0.000592</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 0.0005921590488276713, 'model__cl...</td>\n      <td>0.879857</td>\n      <td>0.879317</td>\n      <td>0.880737</td>\n      <td>0.879695</td>\n      <td>0.880200</td>\n      <td>0.879961</td>\n      <td>0.000481</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>13.984725</td>\n      <td>0.847896</td>\n      <td>0.249698</td>\n      <td>0.042019</td>\n      <td>0.001381</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>2703</td>\n      <td>{'model__C': 0.001380765290289825, 'model__cla...</td>\n      <td>0.879288</td>\n      <td>0.878618</td>\n      <td>0.880529</td>\n      <td>0.880923</td>\n      <td>0.879353</td>\n      <td>0.879742</td>\n      <td>0.000853</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>9.707024</td>\n      <td>0.196035</td>\n      <td>0.281170</td>\n      <td>0.026580</td>\n      <td>0.000214</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>2735</td>\n      <td>{'model__C': 0.00021382241224399877, 'model__c...</td>\n      <td>0.878524</td>\n      <td>0.878848</td>\n      <td>0.880143</td>\n      <td>0.878466</td>\n      <td>0.878882</td>\n      <td>0.878972</td>\n      <td>0.000609</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>590.877874</td>\n      <td>1.166030</td>\n      <td>0.123632</td>\n      <td>0.020106</td>\n      <td>2.491309</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>3721</td>\n      <td>{'model__C': 2.491308632420524, 'model__class_...</td>\n      <td>0.879086</td>\n      <td>0.877277</td>\n      <td>0.878736</td>\n      <td>0.877208</td>\n      <td>0.878434</td>\n      <td>0.878148</td>\n      <td>0.000768</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>7.781186</td>\n      <td>0.148114</td>\n      <td>0.270777</td>\n      <td>0.005686</td>\n      <td>0.000097</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>500</td>\n      <td>{'model__C': 9.657669098785221e-05, 'model__cl...</td>\n      <td>0.876841</td>\n      <td>0.877268</td>\n      <td>0.878548</td>\n      <td>0.877579</td>\n      <td>0.877966</td>\n      <td>0.877640</td>\n      <td>0.000585</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>100.775869</td>\n      <td>0.137673</td>\n      <td>0.206002</td>\n      <td>0.011858</td>\n      <td>0.350239</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>500</td>\n      <td>{'model__C': 0.3502393891414413, 'model__class...</td>\n      <td>0.877201</td>\n      <td>0.878223</td>\n      <td>0.876580</td>\n      <td>0.878403</td>\n      <td>0.875174</td>\n      <td>0.877116</td>\n      <td>0.001179</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>6.377747</td>\n      <td>0.508341</td>\n      <td>0.106082</td>\n      <td>0.028090</td>\n      <td>0.000619</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 0.0006187840005129989, 'model__cl...</td>\n      <td>0.875837</td>\n      <td>0.876274</td>\n      <td>0.878091</td>\n      <td>0.877464</td>\n      <td>0.877598</td>\n      <td>0.877053</td>\n      <td>0.000852</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>3.790051</td>\n      <td>0.071753</td>\n      <td>0.182783</td>\n      <td>0.007246</td>\n      <td>0.000062</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>5000</td>\n      <td>{'model__C': 6.213259856244187e-05, 'model__cl...</td>\n      <td>0.876036</td>\n      <td>0.876538</td>\n      <td>0.877747</td>\n      <td>0.876619</td>\n      <td>0.877756</td>\n      <td>0.876939</td>\n      <td>0.000693</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>4.376968</td>\n      <td>0.038433</td>\n      <td>0.198150</td>\n      <td>0.015893</td>\n      <td>0.000488</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>500</td>\n      <td>{'model__C': 0.00048761423845638266, 'model__c...</td>\n      <td>0.874725</td>\n      <td>0.874901</td>\n      <td>0.877304</td>\n      <td>0.877044</td>\n      <td>0.877003</td>\n      <td>0.876195</td>\n      <td>0.001135</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>694.955791</td>\n      <td>0.528573</td>\n      <td>0.108702</td>\n      <td>0.015464</td>\n      <td>3.156225</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>4112</td>\n      <td>{'model__C': 3.1562246465541888, 'model__class...</td>\n      <td>0.875531</td>\n      <td>0.873759</td>\n      <td>0.875420</td>\n      <td>0.876503</td>\n      <td>0.875322</td>\n      <td>0.875307</td>\n      <td>0.000882</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>3.817455</td>\n      <td>0.060822</td>\n      <td>0.195877</td>\n      <td>0.016906</td>\n      <td>0.000037</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>2685</td>\n      <td>{'model__C': 3.6685285478109704e-05, 'model__c...</td>\n      <td>0.872764</td>\n      <td>0.874067</td>\n      <td>0.876078</td>\n      <td>0.874636</td>\n      <td>0.875807</td>\n      <td>0.874670</td>\n      <td>0.001206</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>5.016402</td>\n      <td>0.218525</td>\n      <td>0.169953</td>\n      <td>0.026093</td>\n      <td>0.000076</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>4856</td>\n      <td>{'model__C': 7.605225223648453e-05, 'model__cl...</td>\n      <td>0.861732</td>\n      <td>0.861345</td>\n      <td>0.864796</td>\n      <td>0.863012</td>\n      <td>0.862944</td>\n      <td>0.862766</td>\n      <td>0.001208</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>3.744259</td>\n      <td>0.037101</td>\n      <td>0.160122</td>\n      <td>0.011777</td>\n      <td>0.000008</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>519</td>\n      <td>{'model__C': 8.435601353254293e-06, 'model__cl...</td>\n      <td>0.860740</td>\n      <td>0.861583</td>\n      <td>0.865152</td>\n      <td>0.861862</td>\n      <td>0.864009</td>\n      <td>0.862669</td>\n      <td>0.001644</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>5.948197</td>\n      <td>1.055979</td>\n      <td>0.246611</td>\n      <td>0.051239</td>\n      <td>0.000032</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>500</td>\n      <td>{'model__C': 3.1953755780018515e-05, 'model__c...</td>\n      <td>0.855093</td>\n      <td>0.854795</td>\n      <td>0.858568</td>\n      <td>0.855336</td>\n      <td>0.856430</td>\n      <td>0.856044</td>\n      <td>0.001377</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>1044.583379</td>\n      <td>0.509100</td>\n      <td>0.117302</td>\n      <td>0.028650</td>\n      <td>19.190776</td>\n      <td>None</td>\n      <td>squared_hinge</td>\n      <td>4991</td>\n      <td>{'model__C': 19.190776178531312, 'model__class...</td>\n      <td>0.825028</td>\n      <td>0.838569</td>\n      <td>0.827313</td>\n      <td>0.839358</td>\n      <td>0.834100</td>\n      <td>0.832874</td>\n      <td>0.005805</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>63.761827</td>\n      <td>0.336938</td>\n      <td>0.124023</td>\n      <td>0.025984</td>\n      <td>0.086424</td>\n      <td>balanced</td>\n      <td>hinge</td>\n      <td>4434</td>\n      <td>{'model__C': 0.08642410048155082, 'model__clas...</td>\n      <td>0.831175</td>\n      <td>0.832855</td>\n      <td>0.831931</td>\n      <td>0.830593</td>\n      <td>0.831549</td>\n      <td>0.831621</td>\n      <td>0.000759</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>22.498485</td>\n      <td>0.208984</td>\n      <td>0.120853</td>\n      <td>0.016997</td>\n      <td>0.022245</td>\n      <td>balanced</td>\n      <td>hinge</td>\n      <td>4269</td>\n      <td>{'model__C': 0.022244596968016832, 'model__cla...</td>\n      <td>0.831413</td>\n      <td>0.832437</td>\n      <td>0.832425</td>\n      <td>0.830435</td>\n      <td>0.830939</td>\n      <td>0.831530</td>\n      <td>0.000798</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>189.953322</td>\n      <td>1.027424</td>\n      <td>0.140368</td>\n      <td>0.023502</td>\n      <td>0.745116</td>\n      <td>balanced</td>\n      <td>hinge</td>\n      <td>1348</td>\n      <td>{'model__C': 0.7451164370027008, 'model__class...</td>\n      <td>0.831197</td>\n      <td>0.830718</td>\n      <td>0.832438</td>\n      <td>0.829093</td>\n      <td>0.830200</td>\n      <td>0.830729</td>\n      <td>0.001104</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11.072094</td>\n      <td>0.187763</td>\n      <td>0.155932</td>\n      <td>0.020495</td>\n      <td>0.00362</td>\n      <td>balanced</td>\n      <td>hinge</td>\n      <td>2450</td>\n      <td>{'model__C': 0.003619595990038508, 'model__cla...</td>\n      <td>0.830317</td>\n      <td>0.831122</td>\n      <td>0.832127</td>\n      <td>0.829261</td>\n      <td>0.829518</td>\n      <td>0.830469</td>\n      <td>0.001055</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>699.235452</td>\n      <td>1.017112</td>\n      <td>0.173472</td>\n      <td>0.031814</td>\n      <td>5.001576</td>\n      <td>balanced</td>\n      <td>hinge</td>\n      <td>4781</td>\n      <td>{'model__C': 5.001575677983704, 'model__class_...</td>\n      <td>0.827334</td>\n      <td>0.830760</td>\n      <td>0.829129</td>\n      <td>0.827239</td>\n      <td>0.828813</td>\n      <td>0.828655</td>\n      <td>0.001299</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>681.326954</td>\n      <td>1.056109</td>\n      <td>0.108217</td>\n      <td>0.016551</td>\n      <td>0.150803</td>\n      <td>balanced</td>\n      <td>squared_hinge</td>\n      <td>4246</td>\n      <td>{'model__C': 0.15080272165641095, 'model__clas...</td>\n      <td>0.825051</td>\n      <td>0.827224</td>\n      <td>0.828343</td>\n      <td>0.823516</td>\n      <td>0.823768</td>\n      <td>0.825581</td>\n      <td>0.001906</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>25.624570</td>\n      <td>1.357725</td>\n      <td>0.103357</td>\n      <td>0.013794</td>\n      <td>0.001909</td>\n      <td>balanced</td>\n      <td>squared_hinge</td>\n      <td>1921</td>\n      <td>{'model__C': 0.0019091131576909443, 'model__cl...</td>\n      <td>0.825322</td>\n      <td>0.827007</td>\n      <td>0.827450</td>\n      <td>0.823443</td>\n      <td>0.823646</td>\n      <td>0.825374</td>\n      <td>0.001655</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>131.597474</td>\n      <td>0.374998</td>\n      <td>0.133420</td>\n      <td>0.012072</td>\n      <td>2.576424</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>513</td>\n      <td>{'model__C': 2.576423799733396, 'model__class_...</td>\n      <td>0.831415</td>\n      <td>0.818033</td>\n      <td>0.822409</td>\n      <td>0.816078</td>\n      <td>0.825342</td>\n      <td>0.822655</td>\n      <td>0.005452</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>804.989544</td>\n      <td>0.529906</td>\n      <td>0.135393</td>\n      <td>0.018506</td>\n      <td>99.334634</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>4103</td>\n      <td>{'model__C': 99.33463392847965, 'model__class_...</td>\n      <td>0.812772</td>\n      <td>0.812948</td>\n      <td>0.806522</td>\n      <td>0.804379</td>\n      <td>0.801151</td>\n      <td>0.807554</td>\n      <td>0.004658</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>4.285828</td>\n      <td>0.423871</td>\n      <td>0.137486</td>\n      <td>0.013661</td>\n      <td>0.000084</td>\n      <td>balanced</td>\n      <td>hinge</td>\n      <td>571</td>\n      <td>{'model__C': 8.405612361362026e-05, 'model__cl...</td>\n      <td>0.802268</td>\n      <td>0.801766</td>\n      <td>0.803975</td>\n      <td>0.800688</td>\n      <td>0.797680</td>\n      <td>0.801275</td>\n      <td>0.002087</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>464.071592</td>\n      <td>0.305549</td>\n      <td>0.126450</td>\n      <td>0.022532</td>\n      <td>44.037625</td>\n      <td>balanced</td>\n      <td>squared_hinge</td>\n      <td>2371</td>\n      <td>{'model__C': 44.037625157309144, 'model__class...</td>\n      <td>0.792139</td>\n      <td>0.763830</td>\n      <td>0.814554</td>\n      <td>0.756638</td>\n      <td>0.809883</td>\n      <td>0.787409</td>\n      <td>0.023525</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>5.212596</td>\n      <td>0.096365</td>\n      <td>0.201239</td>\n      <td>0.028343</td>\n      <td>0.000001</td>\n      <td>balanced</td>\n      <td>squared_hinge</td>\n      <td>1645</td>\n      <td>{'model__C': 1.0691593986059968e-06, 'model__c...</td>\n      <td>0.723185</td>\n      <td>0.724696</td>\n      <td>0.731959</td>\n      <td>0.725389</td>\n      <td>0.721253</td>\n      <td>0.725296</td>\n      <td>0.003621</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>4.057702</td>\n      <td>0.046689</td>\n      <td>0.288904</td>\n      <td>0.033302</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>hinge</td>\n      <td>4849</td>\n      <td>{'model__C': 1e-06, 'model__class_weight': Non...</td>\n      <td>0.712968</td>\n      <td>0.711833</td>\n      <td>0.723109</td>\n      <td>0.718041</td>\n      <td>0.713101</td>\n      <td>0.715810</td>\n      <td>0.004231</td>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_grid_search_dataframe = pd.DataFrame(\n",
    "    np.load(\"Dataset_Files/Baseline_Models/Classification/optimised_lsvc_cv_results.npy\", allow_pickle=True).tolist())\n",
    "lsvc_grid_search_dataframe.sort_values(by=[\"rank_test_score\"], inplace=True)\n",
    "lsvc_grid_search_dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 500\n",
      "--------------------------------------------------------\n",
      "Median Recall: 0.87 with a 95% confidence interval of [0.84,0.91]\n",
      "Median Precision: 0.77 with a 95% confidence interval of [0.73,0.81]\n",
      "Median F1: 0.82 with a 95% confidence interval of [0.79,0.85]\n",
      "Median Accuracy: 0.73 with a 95% confidence interval of [0.70,0.77]\n",
      "Median MCC: 0.33 with a 95% confidence interval of [0.24,0.42]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_lsvc, X_test, y_test, 500, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K-Nearest Neighbors Classifier (KNNC)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()), ('model', KNeighborsClassifier())],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': KNeighborsClassifier(),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__algorithm': 'auto',\n 'model__leaf_size': 30,\n 'model__metric': 'minkowski',\n 'model__metric_params': None,\n 'model__n_jobs': None,\n 'model__n_neighbors': 5,\n 'model__p': 2,\n 'model__weights': 'uniform'}"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scale', StandardScaler()),\n",
    "        ('model', KNeighborsClassifier())\n",
    "    ]\n",
    ")\n",
    "pipe.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "model = BayesSearchCV(estimator=pipe,\n",
    "                      search_spaces=\n",
    "                      {'model__n_neighbors': Integer(4, 20),\n",
    "                       'model__weights': Categorical(['uniform', 'distance']),\n",
    "                       'model__algorithm': Categorical(['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "                       },\n",
    "                      scoring='f1',\n",
    "                      cv=5,\n",
    "                      error_score=np.nan,\n",
    "                      n_jobs=-1,\n",
    "                      pre_dispatch='2*n_jobs',\n",
    "                      random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# index = 1\n",
    "# model.fit(X_train, y_train, callback=on_step)\n",
    "#\n",
    "# optimised_knnc = model.best_estimator_\n",
    "#\n",
    "# y_train_pred = optimised_knnc.predict(X_train)\n",
    "# calculate_metrics_classification(y_train, y_train_pred)\n",
    "#\n",
    "# # Save Model & CV Results\n",
    "# dump(optimised_knnc, 'Dataset_Files/Baseline_Models/Classification/optimised_knnc.joblib')\n",
    "# np.save(\"Dataset_Files/Baseline_Models/Classification/optimised_knnc_cv_results.npy\", model.cv_results_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Load Model\n",
    "optimised_knnc = load('Dataset_Files/Baseline_Models/Classification/optimised_knnc.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 1000\n",
      "--------------------------------------------------------\n",
      "Median Recall: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median Precision: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median F1: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median Accuracy: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median MCC: 1.00 with a 95% confidence interval of [1.00,1.00]\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"Dataset_Files/Baseline_Models/Classification/optimised_knnc_train_metrics.txt\"):\n",
    "    with open(\"Dataset_Files/Baseline_Models/Classification/optimised_knnc_train_metrics.txt\", \"r\") as file:\n",
    "        print(file.read())\n",
    "else:\n",
    "    get_confidence_intervals(optimised_knnc, X_train, y_train, 1000, \"Classification\", print_iterator=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model',\n   KNeighborsClassifier(algorithm='kd_tree', n_neighbors=6, weights='distance'))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': KNeighborsClassifier(algorithm='kd_tree', n_neighbors=6, weights='distance'),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__algorithm': 'kd_tree',\n 'model__leaf_size': 30,\n 'model__metric': 'minkowski',\n 'model__metric_params': None,\n 'model__n_jobs': None,\n 'model__n_neighbors': 6,\n 'model__p': 2,\n 'model__weights': 'distance'}"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimised_knnc.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n49      13.633698      0.141628      1182.344960        9.960524   \n15      12.282033      0.163549      1002.542356        9.767320   \n43      22.050243      0.193560      1119.140156        9.118300   \n45      14.069371      0.095460      1210.372202       13.322948   \n44       1.731142      0.010747       128.236136        2.612396   \n31       1.451200      0.009786       122.137484        1.565822   \n33       3.836397      0.079219       276.719662        3.997535   \n35      28.715279      0.242853      2172.784967       22.308000   \n47       1.568193      0.007192       129.001900        1.864633   \n36       3.547066      0.060361       253.647092        3.554642   \n20      12.467864      0.094568       879.274201       10.315965   \n12       1.410587      0.006248       103.993256        1.480152   \n13      11.939139      0.161890       883.272332        9.123843   \n16      10.592306      0.106060      1468.007120        1.928264   \n30      12.745729      0.170139      1061.168437       10.446218   \n48       1.110310      0.060513       120.543100        1.521186   \n14       1.523911      0.033683       103.645632        1.673347   \n22      12.427316      0.142909      1167.199646        9.671298   \n29      12.789531      0.195517      1129.421846        9.209997   \n37       2.319242      0.019540       229.797554        3.452442   \n11      11.559892      0.183064      1242.038463        7.615021   \n23       1.417207      0.015903       102.768099        1.693798   \n25       1.110864      0.041205       102.519864        1.469421   \n27      11.913418      0.124610       943.528255        9.587321   \n39       2.247518      0.024675       241.102124        3.363891   \n6        1.202527      0.031855       105.360753        1.660302   \n21      12.355561      0.178958       882.567757        8.977212   \n10       1.083356      0.015456       105.598004        1.397503   \n26       1.046725      0.029948       103.488808        1.836739   \n3        1.664987      0.019373       107.672155        1.464451   \n38       2.751194      0.016043       235.642281        3.299760   \n41       2.138876      0.010298       221.075354        3.719896   \n1       30.271943      0.153900      2912.979437       13.237353   \n40       2.880847      0.015945       223.305763        2.822534   \n2       25.679029      0.239313      1660.398176        0.879954   \n7        1.245393      0.018753       105.746313        1.754549   \n5        1.005173      0.031830       106.850213        1.543455   \n28      12.325799      0.159261      1407.690522        6.518909   \n24       1.080017      0.013982       102.321437        1.002827   \n42       2.584706      0.014557       220.808146        2.829504   \n19       9.965368      0.112155      1491.819639        1.857336   \n4        1.239053      0.018300       106.306700        1.312471   \n32      13.110906      0.239192      1620.739931       23.200740   \n46       2.030376      0.058700       130.328410        1.883344   \n18       1.541150      0.007654       104.128398        1.502392   \n8       12.106159      0.218784      1331.408807        9.130672   \n0       15.136697      0.043895      2813.086722        1.972424   \n9        1.473508      0.015309       104.973381        1.502207   \n34       2.725652      0.032220       237.524849        2.808966   \n17      12.409100      0.203703      1412.635878        6.244366   \n\n   param_model__algorithm param_model__n_neighbors param_model__weights  \\\n49                kd_tree                        6             distance   \n15                kd_tree                        6             distance   \n43                kd_tree                        6             distance   \n45                kd_tree                        6             distance   \n44                   auto                        6             distance   \n31                   auto                        6             distance   \n33                   auto                        6             distance   \n35                kd_tree                        6             distance   \n47                   auto                        6             distance   \n36                   auto                        6             distance   \n20                kd_tree                        4             distance   \n12                   auto                        4             distance   \n13                kd_tree                        4             distance   \n16              ball_tree                        5             distance   \n30                kd_tree                        7             distance   \n48                   auto                        8             distance   \n14                   auto                        8             distance   \n22                kd_tree                       10             distance   \n29                kd_tree                        9             distance   \n37                   auto                       11             distance   \n11                kd_tree                       12             distance   \n23                   auto                       13             distance   \n25                  brute                       14             distance   \n27                kd_tree                        5              uniform   \n39                   auto                       15             distance   \n6                   brute                       16             distance   \n21                kd_tree                        4              uniform   \n10                   auto                        4              uniform   \n26                   auto                        7              uniform   \n3                   brute                        7              uniform   \n38                   auto                        6              uniform   \n41                   auto                       17             distance   \n1                 kd_tree                       18             distance   \n40                   auto                        8              uniform   \n2               ball_tree                       19             distance   \n7                   brute                       19             distance   \n5                   brute                       19             distance   \n28                kd_tree                       20             distance   \n24                  brute                        9              uniform   \n42                   auto                       10              uniform   \n19              ball_tree                       11              uniform   \n4                   brute                       11              uniform   \n32                kd_tree                       12              uniform   \n46                   auto                       13              uniform   \n18                  brute                       14              uniform   \n8                 kd_tree                       15              uniform   \n0               ball_tree                       16              uniform   \n9                    auto                       17              uniform   \n34                   auto                       19              uniform   \n17                kd_tree                       20              uniform   \n\n                                               params  split0_test_score  \\\n49  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.939270   \n15  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.939270   \n43  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.939270   \n45  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.939270   \n44  {'model__algorithm': 'auto', 'model__n_neighbo...           0.939270   \n31  {'model__algorithm': 'auto', 'model__n_neighbo...           0.939270   \n33  {'model__algorithm': 'auto', 'model__n_neighbo...           0.939270   \n35  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.939270   \n47  {'model__algorithm': 'auto', 'model__n_neighbo...           0.939270   \n36  {'model__algorithm': 'auto', 'model__n_neighbo...           0.939270   \n20  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.939290   \n12  {'model__algorithm': 'auto', 'model__n_neighbo...           0.939290   \n13  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.939290   \n16  {'model__algorithm': 'ball_tree', 'model__n_ne...           0.939725   \n30  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.939067   \n48  {'model__algorithm': 'auto', 'model__n_neighbo...           0.939777   \n14  {'model__algorithm': 'auto', 'model__n_neighbo...           0.939777   \n22  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.938953   \n29  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.938413   \n37  {'model__algorithm': 'auto', 'model__n_neighbo...           0.937851   \n11  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.937903   \n23  {'model__algorithm': 'auto', 'model__n_neighbo...           0.936606   \n25  {'model__algorithm': 'brute', 'model__n_neighb...           0.936412   \n27  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.935727   \n39  {'model__algorithm': 'auto', 'model__n_neighbo...           0.935189   \n6   {'model__algorithm': 'brute', 'model__n_neighb...           0.935441   \n21  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.932611   \n10  {'model__algorithm': 'auto', 'model__n_neighbo...           0.932611   \n26  {'model__algorithm': 'auto', 'model__n_neighbo...           0.934451   \n3   {'model__algorithm': 'brute', 'model__n_neighb...           0.934451   \n38  {'model__algorithm': 'auto', 'model__n_neighbo...           0.933766   \n41  {'model__algorithm': 'auto', 'model__n_neighbo...           0.933735   \n1   {'model__algorithm': 'kd_tree', 'model__n_neig...           0.934009   \n40  {'model__algorithm': 'auto', 'model__n_neighbo...           0.932670   \n2   {'model__algorithm': 'ball_tree', 'model__n_ne...           0.932945   \n7   {'model__algorithm': 'brute', 'model__n_neighb...           0.932945   \n5   {'model__algorithm': 'brute', 'model__n_neighb...           0.932945   \n28  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.932782   \n24  {'model__algorithm': 'brute', 'model__n_neighb...           0.932130   \n42  {'model__algorithm': 'auto', 'model__n_neighbo...           0.931119   \n19  {'model__algorithm': 'ball_tree', 'model__n_ne...           0.931177   \n4   {'model__algorithm': 'brute', 'model__n_neighb...           0.931177   \n32  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.930004   \n46  {'model__algorithm': 'auto', 'model__n_neighbo...           0.928975   \n18  {'model__algorithm': 'brute', 'model__n_neighb...           0.928376   \n8   {'model__algorithm': 'kd_tree', 'model__n_neig...           0.927294   \n0   {'model__algorithm': 'ball_tree', 'model__n_ne...           0.924548   \n9   {'model__algorithm': 'auto', 'model__n_neighbo...           0.923769   \n34  {'model__algorithm': 'auto', 'model__n_neighbo...           0.921270   \n17  {'model__algorithm': 'kd_tree', 'model__n_neig...           0.920265   \n\n    split1_test_score  split2_test_score  split3_test_score  \\\n49           0.935738           0.938946           0.939656   \n15           0.935738           0.938946           0.939656   \n43           0.935738           0.938946           0.939656   \n45           0.935738           0.938946           0.939656   \n44           0.935738           0.938946           0.939656   \n31           0.935738           0.938946           0.939656   \n33           0.935738           0.938946           0.939656   \n35           0.935738           0.938946           0.939656   \n47           0.935738           0.938946           0.939656   \n36           0.935738           0.938946           0.939656   \n20           0.936396           0.938866           0.939069   \n12           0.936396           0.938866           0.939069   \n13           0.936396           0.938866           0.939069   \n16           0.935901           0.937638           0.938979   \n30           0.935222           0.937983           0.940183   \n48           0.935052           0.937849           0.939784   \n14           0.935052           0.937849           0.939784   \n22           0.933740           0.936559           0.939320   \n29           0.933878           0.936567           0.939295   \n37           0.933360           0.935617           0.937552   \n11           0.933227           0.935678           0.937527   \n23           0.932340           0.934465           0.935872   \n25           0.932234           0.933921           0.935885   \n27           0.932425           0.934061           0.935727   \n39           0.931671           0.933051           0.935074   \n6            0.931569           0.932897           0.934311   \n21           0.932297           0.932753           0.934665   \n10           0.932297           0.932753           0.934628   \n26           0.930706           0.933125           0.935406   \n3            0.930706           0.933125           0.935406   \n38           0.930913           0.933414           0.934320   \n41           0.930760           0.932152           0.933555   \n1            0.930437           0.931954           0.933218   \n40           0.929363           0.932189           0.933253   \n2            0.929893           0.931334           0.932458   \n7            0.929893           0.931334           0.932458   \n5            0.929893           0.931334           0.932458   \n28           0.929844           0.931585           0.931998   \n24           0.928460           0.930870           0.933896   \n42           0.927041           0.929792           0.931881   \n19           0.927483           0.928900           0.931682   \n4            0.927483           0.928900           0.931682   \n32           0.925757           0.927993           0.929044   \n46           0.925605           0.926860           0.928159   \n18           0.924034           0.926037           0.926186   \n8            0.923748           0.924235           0.926395   \n0            0.920714           0.922550           0.923910   \n9            0.920643           0.921457           0.923798   \n34           0.917670           0.918865           0.922024   \n17           0.917406           0.918084           0.920437   \n\n    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n49           0.938927         0.938507        0.001410                1  \n15           0.938927         0.938507        0.001410                1  \n43           0.938927         0.938507        0.001410                1  \n45           0.938927         0.938507        0.001410                1  \n44           0.938927         0.938507        0.001410                1  \n31           0.938927         0.938507        0.001410                1  \n33           0.938927         0.938507        0.001410                1  \n35           0.938927         0.938507        0.001410                1  \n47           0.938927         0.938507        0.001410                1  \n36           0.938927         0.938507        0.001410                1  \n20           0.938829         0.938490        0.001060               11  \n12           0.938829         0.938490        0.001060               11  \n13           0.938829         0.938490        0.001060               11  \n16           0.938336         0.938116        0.001305               14  \n30           0.937214         0.937934        0.001686               15  \n48           0.937020         0.937896        0.001787               16  \n14           0.937020         0.937896        0.001787               16  \n22           0.936705         0.937056        0.002005               18  \n29           0.936335         0.936897        0.001876               19  \n37           0.934912         0.935858        0.001675               20  \n11           0.934853         0.935838        0.001728               21  \n23           0.934162         0.934689        0.001478               22  \n25           0.933887         0.934468        0.001511               23  \n27           0.934326         0.934453        0.001227               24  \n39           0.933462         0.933689        0.001319               25  \n6            0.932807         0.933405        0.001338               26  \n21           0.933424         0.933150        0.000842               27  \n10           0.933424         0.933143        0.000829               28  \n26           0.931961         0.933130        0.001683               29  \n3            0.931961         0.933130        0.001683               29  \n38           0.931923         0.932867        0.001259               31  \n41           0.932630         0.932567        0.001075               32  \n1            0.931880         0.932300        0.001227               33  \n40           0.931222         0.931740        0.001362               34  \n2            0.931646         0.931655        0.001050               35  \n7            0.931646         0.931655        0.001050               35  \n5            0.931646         0.931655        0.001050               35  \n28           0.931451         0.931532        0.000963               38  \n24           0.931344         0.931340        0.001770               39  \n42           0.929050         0.929777        0.001688               40  \n19           0.928818         0.929612        0.001575               41  \n4            0.928818         0.929612        0.001575               41  \n32           0.927540         0.928068        0.001437               43  \n46           0.927057         0.927331        0.001155               44  \n18           0.925522         0.926031        0.001398               45  \n8            0.925289         0.925392        0.001317               46  \n0            0.923097         0.922964        0.001316               47  \n9            0.922358         0.922405        0.001249               48  \n34           0.919485         0.919863        0.001587               49  \n17           0.918710         0.918980        0.001194               50  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_model__algorithm</th>\n      <th>param_model__n_neighbors</th>\n      <th>param_model__weights</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>49</th>\n      <td>13.633698</td>\n      <td>0.141628</td>\n      <td>1182.344960</td>\n      <td>9.960524</td>\n      <td>kd_tree</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>12.282033</td>\n      <td>0.163549</td>\n      <td>1002.542356</td>\n      <td>9.767320</td>\n      <td>kd_tree</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>22.050243</td>\n      <td>0.193560</td>\n      <td>1119.140156</td>\n      <td>9.118300</td>\n      <td>kd_tree</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>14.069371</td>\n      <td>0.095460</td>\n      <td>1210.372202</td>\n      <td>13.322948</td>\n      <td>kd_tree</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>1.731142</td>\n      <td>0.010747</td>\n      <td>128.236136</td>\n      <td>2.612396</td>\n      <td>auto</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>1.451200</td>\n      <td>0.009786</td>\n      <td>122.137484</td>\n      <td>1.565822</td>\n      <td>auto</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>3.836397</td>\n      <td>0.079219</td>\n      <td>276.719662</td>\n      <td>3.997535</td>\n      <td>auto</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>28.715279</td>\n      <td>0.242853</td>\n      <td>2172.784967</td>\n      <td>22.308000</td>\n      <td>kd_tree</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>1.568193</td>\n      <td>0.007192</td>\n      <td>129.001900</td>\n      <td>1.864633</td>\n      <td>auto</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>3.547066</td>\n      <td>0.060361</td>\n      <td>253.647092</td>\n      <td>3.554642</td>\n      <td>auto</td>\n      <td>6</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.939270</td>\n      <td>0.935738</td>\n      <td>0.938946</td>\n      <td>0.939656</td>\n      <td>0.938927</td>\n      <td>0.938507</td>\n      <td>0.001410</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>12.467864</td>\n      <td>0.094568</td>\n      <td>879.274201</td>\n      <td>10.315965</td>\n      <td>kd_tree</td>\n      <td>4</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.939290</td>\n      <td>0.936396</td>\n      <td>0.938866</td>\n      <td>0.939069</td>\n      <td>0.938829</td>\n      <td>0.938490</td>\n      <td>0.001060</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.410587</td>\n      <td>0.006248</td>\n      <td>103.993256</td>\n      <td>1.480152</td>\n      <td>auto</td>\n      <td>4</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.939290</td>\n      <td>0.936396</td>\n      <td>0.938866</td>\n      <td>0.939069</td>\n      <td>0.938829</td>\n      <td>0.938490</td>\n      <td>0.001060</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>11.939139</td>\n      <td>0.161890</td>\n      <td>883.272332</td>\n      <td>9.123843</td>\n      <td>kd_tree</td>\n      <td>4</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.939290</td>\n      <td>0.936396</td>\n      <td>0.938866</td>\n      <td>0.939069</td>\n      <td>0.938829</td>\n      <td>0.938490</td>\n      <td>0.001060</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>10.592306</td>\n      <td>0.106060</td>\n      <td>1468.007120</td>\n      <td>1.928264</td>\n      <td>ball_tree</td>\n      <td>5</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'ball_tree', 'model__n_ne...</td>\n      <td>0.939725</td>\n      <td>0.935901</td>\n      <td>0.937638</td>\n      <td>0.938979</td>\n      <td>0.938336</td>\n      <td>0.938116</td>\n      <td>0.001305</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>12.745729</td>\n      <td>0.170139</td>\n      <td>1061.168437</td>\n      <td>10.446218</td>\n      <td>kd_tree</td>\n      <td>7</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.939067</td>\n      <td>0.935222</td>\n      <td>0.937983</td>\n      <td>0.940183</td>\n      <td>0.937214</td>\n      <td>0.937934</td>\n      <td>0.001686</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>1.110310</td>\n      <td>0.060513</td>\n      <td>120.543100</td>\n      <td>1.521186</td>\n      <td>auto</td>\n      <td>8</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.939777</td>\n      <td>0.935052</td>\n      <td>0.937849</td>\n      <td>0.939784</td>\n      <td>0.937020</td>\n      <td>0.937896</td>\n      <td>0.001787</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1.523911</td>\n      <td>0.033683</td>\n      <td>103.645632</td>\n      <td>1.673347</td>\n      <td>auto</td>\n      <td>8</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.939777</td>\n      <td>0.935052</td>\n      <td>0.937849</td>\n      <td>0.939784</td>\n      <td>0.937020</td>\n      <td>0.937896</td>\n      <td>0.001787</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>12.427316</td>\n      <td>0.142909</td>\n      <td>1167.199646</td>\n      <td>9.671298</td>\n      <td>kd_tree</td>\n      <td>10</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.938953</td>\n      <td>0.933740</td>\n      <td>0.936559</td>\n      <td>0.939320</td>\n      <td>0.936705</td>\n      <td>0.937056</td>\n      <td>0.002005</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>12.789531</td>\n      <td>0.195517</td>\n      <td>1129.421846</td>\n      <td>9.209997</td>\n      <td>kd_tree</td>\n      <td>9</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.938413</td>\n      <td>0.933878</td>\n      <td>0.936567</td>\n      <td>0.939295</td>\n      <td>0.936335</td>\n      <td>0.936897</td>\n      <td>0.001876</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>2.319242</td>\n      <td>0.019540</td>\n      <td>229.797554</td>\n      <td>3.452442</td>\n      <td>auto</td>\n      <td>11</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.937851</td>\n      <td>0.933360</td>\n      <td>0.935617</td>\n      <td>0.937552</td>\n      <td>0.934912</td>\n      <td>0.935858</td>\n      <td>0.001675</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11.559892</td>\n      <td>0.183064</td>\n      <td>1242.038463</td>\n      <td>7.615021</td>\n      <td>kd_tree</td>\n      <td>12</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.937903</td>\n      <td>0.933227</td>\n      <td>0.935678</td>\n      <td>0.937527</td>\n      <td>0.934853</td>\n      <td>0.935838</td>\n      <td>0.001728</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>1.417207</td>\n      <td>0.015903</td>\n      <td>102.768099</td>\n      <td>1.693798</td>\n      <td>auto</td>\n      <td>13</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.936606</td>\n      <td>0.932340</td>\n      <td>0.934465</td>\n      <td>0.935872</td>\n      <td>0.934162</td>\n      <td>0.934689</td>\n      <td>0.001478</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>1.110864</td>\n      <td>0.041205</td>\n      <td>102.519864</td>\n      <td>1.469421</td>\n      <td>brute</td>\n      <td>14</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'brute', 'model__n_neighb...</td>\n      <td>0.936412</td>\n      <td>0.932234</td>\n      <td>0.933921</td>\n      <td>0.935885</td>\n      <td>0.933887</td>\n      <td>0.934468</td>\n      <td>0.001511</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>11.913418</td>\n      <td>0.124610</td>\n      <td>943.528255</td>\n      <td>9.587321</td>\n      <td>kd_tree</td>\n      <td>5</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.935727</td>\n      <td>0.932425</td>\n      <td>0.934061</td>\n      <td>0.935727</td>\n      <td>0.934326</td>\n      <td>0.934453</td>\n      <td>0.001227</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>2.247518</td>\n      <td>0.024675</td>\n      <td>241.102124</td>\n      <td>3.363891</td>\n      <td>auto</td>\n      <td>15</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.935189</td>\n      <td>0.931671</td>\n      <td>0.933051</td>\n      <td>0.935074</td>\n      <td>0.933462</td>\n      <td>0.933689</td>\n      <td>0.001319</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.202527</td>\n      <td>0.031855</td>\n      <td>105.360753</td>\n      <td>1.660302</td>\n      <td>brute</td>\n      <td>16</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'brute', 'model__n_neighb...</td>\n      <td>0.935441</td>\n      <td>0.931569</td>\n      <td>0.932897</td>\n      <td>0.934311</td>\n      <td>0.932807</td>\n      <td>0.933405</td>\n      <td>0.001338</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>12.355561</td>\n      <td>0.178958</td>\n      <td>882.567757</td>\n      <td>8.977212</td>\n      <td>kd_tree</td>\n      <td>4</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.932611</td>\n      <td>0.932297</td>\n      <td>0.932753</td>\n      <td>0.934665</td>\n      <td>0.933424</td>\n      <td>0.933150</td>\n      <td>0.000842</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.083356</td>\n      <td>0.015456</td>\n      <td>105.598004</td>\n      <td>1.397503</td>\n      <td>auto</td>\n      <td>4</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.932611</td>\n      <td>0.932297</td>\n      <td>0.932753</td>\n      <td>0.934628</td>\n      <td>0.933424</td>\n      <td>0.933143</td>\n      <td>0.000829</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>1.046725</td>\n      <td>0.029948</td>\n      <td>103.488808</td>\n      <td>1.836739</td>\n      <td>auto</td>\n      <td>7</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.934451</td>\n      <td>0.930706</td>\n      <td>0.933125</td>\n      <td>0.935406</td>\n      <td>0.931961</td>\n      <td>0.933130</td>\n      <td>0.001683</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.664987</td>\n      <td>0.019373</td>\n      <td>107.672155</td>\n      <td>1.464451</td>\n      <td>brute</td>\n      <td>7</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'brute', 'model__n_neighb...</td>\n      <td>0.934451</td>\n      <td>0.930706</td>\n      <td>0.933125</td>\n      <td>0.935406</td>\n      <td>0.931961</td>\n      <td>0.933130</td>\n      <td>0.001683</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>2.751194</td>\n      <td>0.016043</td>\n      <td>235.642281</td>\n      <td>3.299760</td>\n      <td>auto</td>\n      <td>6</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.933766</td>\n      <td>0.930913</td>\n      <td>0.933414</td>\n      <td>0.934320</td>\n      <td>0.931923</td>\n      <td>0.932867</td>\n      <td>0.001259</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>2.138876</td>\n      <td>0.010298</td>\n      <td>221.075354</td>\n      <td>3.719896</td>\n      <td>auto</td>\n      <td>17</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.933735</td>\n      <td>0.930760</td>\n      <td>0.932152</td>\n      <td>0.933555</td>\n      <td>0.932630</td>\n      <td>0.932567</td>\n      <td>0.001075</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30.271943</td>\n      <td>0.153900</td>\n      <td>2912.979437</td>\n      <td>13.237353</td>\n      <td>kd_tree</td>\n      <td>18</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.934009</td>\n      <td>0.930437</td>\n      <td>0.931954</td>\n      <td>0.933218</td>\n      <td>0.931880</td>\n      <td>0.932300</td>\n      <td>0.001227</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>2.880847</td>\n      <td>0.015945</td>\n      <td>223.305763</td>\n      <td>2.822534</td>\n      <td>auto</td>\n      <td>8</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.932670</td>\n      <td>0.929363</td>\n      <td>0.932189</td>\n      <td>0.933253</td>\n      <td>0.931222</td>\n      <td>0.931740</td>\n      <td>0.001362</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25.679029</td>\n      <td>0.239313</td>\n      <td>1660.398176</td>\n      <td>0.879954</td>\n      <td>ball_tree</td>\n      <td>19</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'ball_tree', 'model__n_ne...</td>\n      <td>0.932945</td>\n      <td>0.929893</td>\n      <td>0.931334</td>\n      <td>0.932458</td>\n      <td>0.931646</td>\n      <td>0.931655</td>\n      <td>0.001050</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.245393</td>\n      <td>0.018753</td>\n      <td>105.746313</td>\n      <td>1.754549</td>\n      <td>brute</td>\n      <td>19</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'brute', 'model__n_neighb...</td>\n      <td>0.932945</td>\n      <td>0.929893</td>\n      <td>0.931334</td>\n      <td>0.932458</td>\n      <td>0.931646</td>\n      <td>0.931655</td>\n      <td>0.001050</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.005173</td>\n      <td>0.031830</td>\n      <td>106.850213</td>\n      <td>1.543455</td>\n      <td>brute</td>\n      <td>19</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'brute', 'model__n_neighb...</td>\n      <td>0.932945</td>\n      <td>0.929893</td>\n      <td>0.931334</td>\n      <td>0.932458</td>\n      <td>0.931646</td>\n      <td>0.931655</td>\n      <td>0.001050</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>12.325799</td>\n      <td>0.159261</td>\n      <td>1407.690522</td>\n      <td>6.518909</td>\n      <td>kd_tree</td>\n      <td>20</td>\n      <td>distance</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.932782</td>\n      <td>0.929844</td>\n      <td>0.931585</td>\n      <td>0.931998</td>\n      <td>0.931451</td>\n      <td>0.931532</td>\n      <td>0.000963</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>1.080017</td>\n      <td>0.013982</td>\n      <td>102.321437</td>\n      <td>1.002827</td>\n      <td>brute</td>\n      <td>9</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'brute', 'model__n_neighb...</td>\n      <td>0.932130</td>\n      <td>0.928460</td>\n      <td>0.930870</td>\n      <td>0.933896</td>\n      <td>0.931344</td>\n      <td>0.931340</td>\n      <td>0.001770</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>2.584706</td>\n      <td>0.014557</td>\n      <td>220.808146</td>\n      <td>2.829504</td>\n      <td>auto</td>\n      <td>10</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.931119</td>\n      <td>0.927041</td>\n      <td>0.929792</td>\n      <td>0.931881</td>\n      <td>0.929050</td>\n      <td>0.929777</td>\n      <td>0.001688</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>9.965368</td>\n      <td>0.112155</td>\n      <td>1491.819639</td>\n      <td>1.857336</td>\n      <td>ball_tree</td>\n      <td>11</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'ball_tree', 'model__n_ne...</td>\n      <td>0.931177</td>\n      <td>0.927483</td>\n      <td>0.928900</td>\n      <td>0.931682</td>\n      <td>0.928818</td>\n      <td>0.929612</td>\n      <td>0.001575</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.239053</td>\n      <td>0.018300</td>\n      <td>106.306700</td>\n      <td>1.312471</td>\n      <td>brute</td>\n      <td>11</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'brute', 'model__n_neighb...</td>\n      <td>0.931177</td>\n      <td>0.927483</td>\n      <td>0.928900</td>\n      <td>0.931682</td>\n      <td>0.928818</td>\n      <td>0.929612</td>\n      <td>0.001575</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>13.110906</td>\n      <td>0.239192</td>\n      <td>1620.739931</td>\n      <td>23.200740</td>\n      <td>kd_tree</td>\n      <td>12</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.930004</td>\n      <td>0.925757</td>\n      <td>0.927993</td>\n      <td>0.929044</td>\n      <td>0.927540</td>\n      <td>0.928068</td>\n      <td>0.001437</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>2.030376</td>\n      <td>0.058700</td>\n      <td>130.328410</td>\n      <td>1.883344</td>\n      <td>auto</td>\n      <td>13</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.928975</td>\n      <td>0.925605</td>\n      <td>0.926860</td>\n      <td>0.928159</td>\n      <td>0.927057</td>\n      <td>0.927331</td>\n      <td>0.001155</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1.541150</td>\n      <td>0.007654</td>\n      <td>104.128398</td>\n      <td>1.502392</td>\n      <td>brute</td>\n      <td>14</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'brute', 'model__n_neighb...</td>\n      <td>0.928376</td>\n      <td>0.924034</td>\n      <td>0.926037</td>\n      <td>0.926186</td>\n      <td>0.925522</td>\n      <td>0.926031</td>\n      <td>0.001398</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>12.106159</td>\n      <td>0.218784</td>\n      <td>1331.408807</td>\n      <td>9.130672</td>\n      <td>kd_tree</td>\n      <td>15</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.927294</td>\n      <td>0.923748</td>\n      <td>0.924235</td>\n      <td>0.926395</td>\n      <td>0.925289</td>\n      <td>0.925392</td>\n      <td>0.001317</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>15.136697</td>\n      <td>0.043895</td>\n      <td>2813.086722</td>\n      <td>1.972424</td>\n      <td>ball_tree</td>\n      <td>16</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'ball_tree', 'model__n_ne...</td>\n      <td>0.924548</td>\n      <td>0.920714</td>\n      <td>0.922550</td>\n      <td>0.923910</td>\n      <td>0.923097</td>\n      <td>0.922964</td>\n      <td>0.001316</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.473508</td>\n      <td>0.015309</td>\n      <td>104.973381</td>\n      <td>1.502207</td>\n      <td>auto</td>\n      <td>17</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.923769</td>\n      <td>0.920643</td>\n      <td>0.921457</td>\n      <td>0.923798</td>\n      <td>0.922358</td>\n      <td>0.922405</td>\n      <td>0.001249</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>2.725652</td>\n      <td>0.032220</td>\n      <td>237.524849</td>\n      <td>2.808966</td>\n      <td>auto</td>\n      <td>19</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n      <td>0.921270</td>\n      <td>0.917670</td>\n      <td>0.918865</td>\n      <td>0.922024</td>\n      <td>0.919485</td>\n      <td>0.919863</td>\n      <td>0.001587</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>12.409100</td>\n      <td>0.203703</td>\n      <td>1412.635878</td>\n      <td>6.244366</td>\n      <td>kd_tree</td>\n      <td>20</td>\n      <td>uniform</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__n_neig...</td>\n      <td>0.920265</td>\n      <td>0.917406</td>\n      <td>0.918084</td>\n      <td>0.920437</td>\n      <td>0.918710</td>\n      <td>0.918980</td>\n      <td>0.001194</td>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnc_grid_search_dataframe = pd.DataFrame(\n",
    "    np.load(\"Dataset_Files/Baseline_Models/Classification/optimised_knnc_cv_results.npy\", allow_pickle=True).tolist())\n",
    "knnc_grid_search_dataframe.sort_values(by=[\"rank_test_score\"], inplace=True)\n",
    "knnc_grid_search_dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 500\n",
      "--------------------------------------------------------\n",
      "Median Recall: 0.83 with a 95% confidence interval of [0.79,0.87]\n",
      "Median Precision: 0.82 with a 95% confidence interval of [0.77,0.85]\n",
      "Median F1: 0.82 with a 95% confidence interval of [0.79,0.85]\n",
      "Median Accuracy: 0.75 with a 95% confidence interval of [0.71,0.79]\n",
      "Median MCC: 0.42 with a 95% confidence interval of [0.33,0.50]\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"Dataset_Files/Baseline_Models/Classification/optimised_knnc_test_metrics.txt\"):\n",
    "    with open(\"Dataset_Files/Baseline_Models/Classification/optimised_knnc_test_metrics.txt\", \"r\") as file:\n",
    "        print(file.read())\n",
    "else:\n",
    "    get_confidence_intervals(optimised_knnc, X_test, y_test, 500, \"Classification\", print_iterator=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree Classifier (DTC)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model', DecisionTreeClassifier(random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': DecisionTreeClassifier(random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__ccp_alpha': 0.0,\n 'model__class_weight': None,\n 'model__criterion': 'gini',\n 'model__max_depth': None,\n 'model__max_features': None,\n 'model__max_leaf_nodes': None,\n 'model__min_impurity_decrease': 0.0,\n 'model__min_samples_leaf': 1,\n 'model__min_samples_split': 2,\n 'model__min_weight_fraction_leaf': 0.0,\n 'model__random_state': 42,\n 'model__splitter': 'best'}"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scale', StandardScaler()),\n",
    "        ('model', DecisionTreeClassifier(random_state=42))\n",
    "    ]\n",
    ")\n",
    "pipe.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "model = BayesSearchCV(estimator=pipe,\n",
    "                      search_spaces=\n",
    "                      {'model__criterion': Categorical(['gini', 'entropy']),\n",
    "                       'model__splitter': Categorical(['best', 'random']),\n",
    "                       'model__max_features': Categorical([None, 'sqrt', 'log2']),\n",
    "                       'model__class_weight': Categorical([None, 'balanced'])\n",
    "                       },\n",
    "                      scoring='f1',\n",
    "                      cv=5,\n",
    "                      error_score=np.nan,\n",
    "                      n_jobs=-1,\n",
    "                      pre_dispatch='2*n_jobs',\n",
    "                      random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# index = 1\n",
    "# model.fit(X_train, y_train, callback=on_step)\n",
    "#\n",
    "# optimised_dtc = model.best_estimator_\n",
    "#\n",
    "# y_train_pred = optimised_dtc.predict(X_train)\n",
    "# calculate_metrics_classification(y_train, y_train_pred)\n",
    "#\n",
    "# # Save Model & CV Results\n",
    "# dump(optimised_dtc, 'Dataset_Files/Baseline_Models/Classification/optimised_dtc.joblib')\n",
    "# np.save(\"Dataset_Files/Baseline_Models/Classification/optimised_dtc_cv_results.npy\", model.cv_results_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Load Model\n",
    "optimised_dtc = load('Dataset_Files/Baseline_Models/Classification/optimised_dtc.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# visualise_decision_tree(optimised_dtc['model'], feature_selection_columns, [\"Inactive\", \"Active\"],\n",
    "#                         \"Dataset_Files/Baseline_Models/Classification/optimised_dtc.dot\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 1000\n",
      "--------------------------------------------------------\n",
      "Median Recall: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median Precision: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median F1: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median Accuracy: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median MCC: 1.00 with a 95% confidence interval of [1.00,1.00]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_dtc, X_train, y_train, 1000, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model',\n   DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n                          random_state=42, splitter='random'))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n                        random_state=42, splitter='random'),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__ccp_alpha': 0.0,\n 'model__class_weight': 'balanced',\n 'model__criterion': 'entropy',\n 'model__max_depth': None,\n 'model__max_features': None,\n 'model__max_leaf_nodes': None,\n 'model__min_impurity_decrease': 0.0,\n 'model__min_samples_leaf': 1,\n 'model__min_samples_split': 2,\n 'model__min_weight_fraction_leaf': 0.0,\n 'model__random_state': 42,\n 'model__splitter': 'random'}"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimised_dtc.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n49      13.174896      0.330564         0.083181        0.013300   \n23      13.090956      0.333569         0.078187        0.019857   \n48      13.090186      0.241431         0.079286        0.011067   \n11      13.126391      0.323209         0.074224        0.011057   \n27      13.251386      0.259169         0.072245        0.012244   \n31      13.038817      0.345910         0.078129        0.009886   \n19      13.154575      0.344138         0.082861        0.011696   \n33      13.309156      0.329549         0.084524        0.015882   \n36      13.511728      0.310206         0.079706        0.015926   \n37      12.940933      0.296501         0.077887        0.010588   \n39      13.288205      0.294810         0.074122        0.011010   \n44      13.045502      0.332964         0.076809        0.012575   \n45      13.116223      0.256961         0.084969        0.015720   \n47      13.405283      0.281470         0.076693        0.015935   \n34      13.378143      0.323774         0.082232        0.015154   \n16      13.161747      0.291926         0.081252        0.011796   \n12      14.746081      0.616043         0.071601        0.006906   \n24      18.487709      0.333083         0.081248        0.011695   \n15      12.811288      0.187718         0.077357        0.013163   \n1        1.654041      0.068141         0.087184        0.012292   \n6        1.834078      0.044856         0.080104        0.003490   \n7        1.775065      0.050833         0.087548        0.007682   \n13       2.451630      0.083617         0.087509        0.012492   \n14      27.542007      0.433331         0.080630        0.010789   \n5       32.430072      1.499737         0.080160        0.020595   \n26      26.613685      0.291141         0.071952        0.007728   \n38       2.027398      0.049281         0.100591        0.011510   \n28       1.966272      0.052782         0.081618        0.004628   \n43       1.859982      0.045420         0.088466        0.006745   \n42       2.327800      0.057561         0.084380        0.007647   \n21       2.503849      0.028811         0.071870        0.007655   \n18       1.701962      0.046839         0.093766        0.009871   \n46       1.569760      0.021181         0.131273        0.012500   \n29       1.874212      0.027817         0.092419        0.003337   \n3        1.695048      0.035076         0.071870        0.007653   \n35       1.836015      0.037503         0.087522        0.012491   \n4        2.024992      0.042389         0.093755        0.013989   \n32       2.692785      0.095013         0.093336        0.013960   \n9        2.756969      0.073684         0.096116        0.013414   \n20       1.833678      0.055816         0.100000        0.027247   \n25       2.226726      0.072383         0.081283        0.011707   \n2       47.578724      4.711592         0.074520        0.010506   \n0        1.590742      0.073559         0.084385        0.012493   \n40       1.717093      0.045715         0.087596        0.007598   \n8        1.751587      0.083179         0.115016        0.025277   \n22       1.429637      0.042620         0.084388        0.012489   \n10       1.669425      0.021381         0.104163        0.008792   \n30       1.378603      0.023124         0.091270        0.011837   \n41       1.547312      0.026558         0.087502        0.007653   \n17       1.408097      0.024658         0.093708        0.000016   \n\n   param_model__class_weight param_model__criterion param_model__max_features  \\\n49                  balanced                entropy                      None   \n23                  balanced                entropy                      None   \n48                  balanced                entropy                      None   \n11                  balanced                entropy                      None   \n27                  balanced                entropy                      None   \n31                  balanced                entropy                      None   \n19                  balanced                entropy                      None   \n33                  balanced                entropy                      None   \n36                  balanced                entropy                      None   \n37                  balanced                entropy                      None   \n39                  balanced                entropy                      None   \n44                  balanced                entropy                      None   \n45                  balanced                entropy                      None   \n47                  balanced                entropy                      None   \n34                  balanced                entropy                      None   \n16                  balanced                entropy                      None   \n12                  balanced                   gini                      None   \n24                      None                   gini                      None   \n15                      None                entropy                      None   \n1                   balanced                   gini                      sqrt   \n6                   balanced                   gini                      sqrt   \n7                   balanced                   gini                      sqrt   \n13                  balanced                entropy                      sqrt   \n14                  balanced                entropy                      None   \n5                   balanced                   gini                      None   \n26                      None                entropy                      None   \n38                      None                entropy                      sqrt   \n28                      None                entropy                      sqrt   \n43                      None                entropy                      sqrt   \n42                  balanced                   gini                      sqrt   \n21                  balanced                   gini                      sqrt   \n18                      None                   gini                      sqrt   \n46                  balanced                entropy                      log2   \n29                  balanced                entropy                      log2   \n3                   balanced                entropy                      sqrt   \n35                  balanced                entropy                      sqrt   \n4                   balanced                entropy                      sqrt   \n32                      None                   gini                      sqrt   \n9                       None                   gini                      sqrt   \n20                      None                entropy                      log2   \n25                      None                entropy                      sqrt   \n2                       None                   gini                      None   \n0                       None                   gini                      log2   \n40                  balanced                   gini                      log2   \n8                   balanced                   gini                      log2   \n22                  balanced                entropy                      log2   \n10                  balanced                   gini                      log2   \n30                      None                   gini                      log2   \n41                      None                   gini                      log2   \n17                      None                entropy                      log2   \n\n   param_model__splitter                                             params  \\\n49                random  {'model__class_weight': 'balanced', 'model__cr...   \n23                random  {'model__class_weight': 'balanced', 'model__cr...   \n48                random  {'model__class_weight': 'balanced', 'model__cr...   \n11                random  {'model__class_weight': 'balanced', 'model__cr...   \n27                random  {'model__class_weight': 'balanced', 'model__cr...   \n31                random  {'model__class_weight': 'balanced', 'model__cr...   \n19                random  {'model__class_weight': 'balanced', 'model__cr...   \n33                random  {'model__class_weight': 'balanced', 'model__cr...   \n36                random  {'model__class_weight': 'balanced', 'model__cr...   \n37                random  {'model__class_weight': 'balanced', 'model__cr...   \n39                random  {'model__class_weight': 'balanced', 'model__cr...   \n44                random  {'model__class_weight': 'balanced', 'model__cr...   \n45                random  {'model__class_weight': 'balanced', 'model__cr...   \n47                random  {'model__class_weight': 'balanced', 'model__cr...   \n34                random  {'model__class_weight': 'balanced', 'model__cr...   \n16                random  {'model__class_weight': 'balanced', 'model__cr...   \n12                random  {'model__class_weight': 'balanced', 'model__cr...   \n24                random  {'model__class_weight': None, 'model__criterio...   \n15                random  {'model__class_weight': None, 'model__criterio...   \n1                 random  {'model__class_weight': 'balanced', 'model__cr...   \n6                 random  {'model__class_weight': 'balanced', 'model__cr...   \n7                 random  {'model__class_weight': 'balanced', 'model__cr...   \n13                  best  {'model__class_weight': 'balanced', 'model__cr...   \n14                  best  {'model__class_weight': 'balanced', 'model__cr...   \n5                   best  {'model__class_weight': 'balanced', 'model__cr...   \n26                  best  {'model__class_weight': None, 'model__criterio...   \n38                random  {'model__class_weight': None, 'model__criterio...   \n28                random  {'model__class_weight': None, 'model__criterio...   \n43                random  {'model__class_weight': None, 'model__criterio...   \n42                  best  {'model__class_weight': 'balanced', 'model__cr...   \n21                  best  {'model__class_weight': 'balanced', 'model__cr...   \n18                random  {'model__class_weight': None, 'model__criterio...   \n46                  best  {'model__class_weight': 'balanced', 'model__cr...   \n29                  best  {'model__class_weight': 'balanced', 'model__cr...   \n3                 random  {'model__class_weight': 'balanced', 'model__cr...   \n35                random  {'model__class_weight': 'balanced', 'model__cr...   \n4                 random  {'model__class_weight': 'balanced', 'model__cr...   \n32                  best  {'model__class_weight': None, 'model__criterio...   \n9                   best  {'model__class_weight': None, 'model__criterio...   \n20                  best  {'model__class_weight': None, 'model__criterio...   \n25                  best  {'model__class_weight': None, 'model__criterio...   \n2                   best  {'model__class_weight': None, 'model__criterio...   \n0                   best  {'model__class_weight': None, 'model__criterio...   \n40                  best  {'model__class_weight': 'balanced', 'model__cr...   \n8                   best  {'model__class_weight': 'balanced', 'model__cr...   \n22                random  {'model__class_weight': 'balanced', 'model__cr...   \n10                random  {'model__class_weight': 'balanced', 'model__cr...   \n30                random  {'model__class_weight': None, 'model__criterio...   \n41                random  {'model__class_weight': None, 'model__criterio...   \n17                random  {'model__class_weight': None, 'model__criterio...   \n\n    split0_test_score  split1_test_score  split2_test_score  \\\n49           0.921640           0.920335           0.923301   \n23           0.921640           0.920335           0.923301   \n48           0.921640           0.920335           0.923301   \n11           0.921640           0.920335           0.923301   \n27           0.921640           0.920335           0.923301   \n31           0.921640           0.920335           0.923301   \n19           0.921640           0.920335           0.923301   \n33           0.921640           0.920335           0.923301   \n36           0.921640           0.920335           0.923301   \n37           0.921640           0.920335           0.923301   \n39           0.921640           0.920335           0.923301   \n44           0.921640           0.920335           0.923301   \n45           0.921640           0.920335           0.923301   \n47           0.921640           0.920335           0.923301   \n34           0.921640           0.920335           0.923301   \n16           0.921640           0.920335           0.923301   \n12           0.923660           0.919801           0.920203   \n24           0.922634           0.919121           0.921826   \n15           0.921292           0.921110           0.921053   \n1            0.922020           0.916447           0.918884   \n6            0.922020           0.916447           0.918884   \n7            0.922020           0.916447           0.918884   \n13           0.919897           0.918304           0.919394   \n14           0.917068           0.919193           0.919025   \n5            0.917934           0.917204           0.920893   \n26           0.918913           0.916596           0.919045   \n38           0.920312           0.916054           0.918227   \n28           0.920312           0.916054           0.918227   \n43           0.920312           0.916054           0.918227   \n42           0.916890           0.917979           0.917700   \n21           0.916890           0.917979           0.917700   \n18           0.920538           0.915398           0.917283   \n46           0.919209           0.917630           0.917716   \n29           0.919209           0.917630           0.917716   \n3            0.917337           0.917360           0.920061   \n35           0.917337           0.917360           0.920061   \n4            0.917337           0.917360           0.920061   \n32           0.919536           0.915692           0.918304   \n9            0.919536           0.915692           0.918304   \n20           0.918279           0.916726           0.914402   \n25           0.917956           0.916734           0.918159   \n2            0.915449           0.915814           0.917675   \n0            0.918609           0.916059           0.916138   \n40           0.915772           0.915482           0.917644   \n8            0.915772           0.915482           0.917644   \n22           0.914456           0.915331           0.911781   \n10           0.912816           0.910685           0.911686   \n30           0.911983           0.907660           0.913700   \n41           0.911983           0.907660           0.913700   \n17           0.910545           0.908601           0.910647   \n\n    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n49           0.921825           0.922775         0.921975        0.001022   \n23           0.921825           0.922775         0.921975        0.001022   \n48           0.921825           0.922775         0.921975        0.001022   \n11           0.921825           0.922775         0.921975        0.001022   \n27           0.921825           0.922775         0.921975        0.001022   \n31           0.921825           0.922775         0.921975        0.001022   \n19           0.921825           0.922775         0.921975        0.001022   \n33           0.921825           0.922775         0.921975        0.001022   \n36           0.921825           0.922775         0.921975        0.001022   \n37           0.921825           0.922775         0.921975        0.001022   \n39           0.921825           0.922775         0.921975        0.001022   \n44           0.921825           0.922775         0.921975        0.001022   \n45           0.921825           0.922775         0.921975        0.001022   \n47           0.921825           0.922775         0.921975        0.001022   \n34           0.921825           0.922775         0.921975        0.001022   \n16           0.921825           0.922775         0.921975        0.001022   \n12           0.920596           0.920739         0.921000        0.001370   \n24           0.920049           0.919495         0.920625        0.001367   \n15           0.920177           0.918437         0.920414        0.001061   \n1            0.921035           0.920265         0.919730        0.001935   \n6            0.921035           0.920265         0.919730        0.001935   \n7            0.921035           0.920265         0.919730        0.001935   \n13           0.919244           0.918228         0.919013        0.000648   \n14           0.919311           0.919448         0.918809        0.000882   \n5            0.919621           0.917341         0.918599        0.001434   \n26           0.920020           0.918135         0.918542        0.001143   \n38           0.918374           0.918255         0.918244        0.001348   \n28           0.918374           0.918255         0.918244        0.001348   \n43           0.918374           0.918255         0.918244        0.001348   \n42           0.918868           0.919644         0.918216        0.000954   \n21           0.918868           0.919644         0.918216        0.000954   \n18           0.918307           0.919254         0.918156        0.001748   \n46           0.918299           0.917478         0.918066        0.000635   \n29           0.918299           0.917478         0.918066        0.000635   \n3            0.917298           0.917075         0.917826        0.001122   \n35           0.917298           0.917075         0.917826        0.001122   \n4            0.917298           0.917075         0.917826        0.001122   \n32           0.919768           0.915791         0.917818        0.001767   \n9            0.919768           0.915791         0.917818        0.001767   \n20           0.919466           0.919188         0.917612        0.001869   \n25           0.916819           0.917447         0.917423        0.000577   \n2            0.920324           0.917419         0.917336        0.001728   \n0            0.919158           0.916238         0.917240        0.001354   \n40           0.917200           0.916008         0.916421        0.000846   \n8            0.917200           0.916008         0.916421        0.000846   \n22           0.918421           0.912047         0.914407        0.002426   \n10           0.916633           0.912178         0.912800        0.002039   \n30           0.913307           0.911735         0.911677        0.002144   \n41           0.913307           0.911735         0.911677        0.002144   \n17           0.911585           0.914793         0.911234        0.002027   \n\n    rank_test_score  \n49                1  \n23                1  \n48                1  \n11                1  \n27                1  \n31                1  \n19                1  \n33                1  \n36                1  \n37                1  \n39                1  \n44                1  \n45                1  \n47                1  \n34                1  \n16                1  \n12               17  \n24               18  \n15               19  \n1                20  \n6                20  \n7                20  \n13               23  \n14               24  \n5                25  \n26               26  \n38               27  \n28               27  \n43               27  \n42               30  \n21               30  \n18               32  \n46               33  \n29               33  \n3                35  \n35               35  \n4                35  \n32               38  \n9                38  \n20               40  \n25               41  \n2                42  \n0                43  \n40               44  \n8                44  \n22               46  \n10               47  \n30               48  \n41               48  \n17               50  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_model__class_weight</th>\n      <th>param_model__criterion</th>\n      <th>param_model__max_features</th>\n      <th>param_model__splitter</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>49</th>\n      <td>13.174896</td>\n      <td>0.330564</td>\n      <td>0.083181</td>\n      <td>0.013300</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>13.090956</td>\n      <td>0.333569</td>\n      <td>0.078187</td>\n      <td>0.019857</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>13.090186</td>\n      <td>0.241431</td>\n      <td>0.079286</td>\n      <td>0.011067</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>13.126391</td>\n      <td>0.323209</td>\n      <td>0.074224</td>\n      <td>0.011057</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>13.251386</td>\n      <td>0.259169</td>\n      <td>0.072245</td>\n      <td>0.012244</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>13.038817</td>\n      <td>0.345910</td>\n      <td>0.078129</td>\n      <td>0.009886</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>13.154575</td>\n      <td>0.344138</td>\n      <td>0.082861</td>\n      <td>0.011696</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>13.309156</td>\n      <td>0.329549</td>\n      <td>0.084524</td>\n      <td>0.015882</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>13.511728</td>\n      <td>0.310206</td>\n      <td>0.079706</td>\n      <td>0.015926</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>12.940933</td>\n      <td>0.296501</td>\n      <td>0.077887</td>\n      <td>0.010588</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>13.288205</td>\n      <td>0.294810</td>\n      <td>0.074122</td>\n      <td>0.011010</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>13.045502</td>\n      <td>0.332964</td>\n      <td>0.076809</td>\n      <td>0.012575</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>13.116223</td>\n      <td>0.256961</td>\n      <td>0.084969</td>\n      <td>0.015720</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>13.405283</td>\n      <td>0.281470</td>\n      <td>0.076693</td>\n      <td>0.015935</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>13.378143</td>\n      <td>0.323774</td>\n      <td>0.082232</td>\n      <td>0.015154</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>13.161747</td>\n      <td>0.291926</td>\n      <td>0.081252</td>\n      <td>0.011796</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.921640</td>\n      <td>0.920335</td>\n      <td>0.923301</td>\n      <td>0.921825</td>\n      <td>0.922775</td>\n      <td>0.921975</td>\n      <td>0.001022</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>14.746081</td>\n      <td>0.616043</td>\n      <td>0.071601</td>\n      <td>0.006906</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.923660</td>\n      <td>0.919801</td>\n      <td>0.920203</td>\n      <td>0.920596</td>\n      <td>0.920739</td>\n      <td>0.921000</td>\n      <td>0.001370</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>18.487709</td>\n      <td>0.333083</td>\n      <td>0.081248</td>\n      <td>0.011695</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.922634</td>\n      <td>0.919121</td>\n      <td>0.921826</td>\n      <td>0.920049</td>\n      <td>0.919495</td>\n      <td>0.920625</td>\n      <td>0.001367</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>12.811288</td>\n      <td>0.187718</td>\n      <td>0.077357</td>\n      <td>0.013163</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>random</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.921292</td>\n      <td>0.921110</td>\n      <td>0.921053</td>\n      <td>0.920177</td>\n      <td>0.918437</td>\n      <td>0.920414</td>\n      <td>0.001061</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.654041</td>\n      <td>0.068141</td>\n      <td>0.087184</td>\n      <td>0.012292</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.922020</td>\n      <td>0.916447</td>\n      <td>0.918884</td>\n      <td>0.921035</td>\n      <td>0.920265</td>\n      <td>0.919730</td>\n      <td>0.001935</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.834078</td>\n      <td>0.044856</td>\n      <td>0.080104</td>\n      <td>0.003490</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.922020</td>\n      <td>0.916447</td>\n      <td>0.918884</td>\n      <td>0.921035</td>\n      <td>0.920265</td>\n      <td>0.919730</td>\n      <td>0.001935</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.775065</td>\n      <td>0.050833</td>\n      <td>0.087548</td>\n      <td>0.007682</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.922020</td>\n      <td>0.916447</td>\n      <td>0.918884</td>\n      <td>0.921035</td>\n      <td>0.920265</td>\n      <td>0.919730</td>\n      <td>0.001935</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2.451630</td>\n      <td>0.083617</td>\n      <td>0.087509</td>\n      <td>0.012492</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>best</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.919897</td>\n      <td>0.918304</td>\n      <td>0.919394</td>\n      <td>0.919244</td>\n      <td>0.918228</td>\n      <td>0.919013</td>\n      <td>0.000648</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>27.542007</td>\n      <td>0.433331</td>\n      <td>0.080630</td>\n      <td>0.010789</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>best</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.917068</td>\n      <td>0.919193</td>\n      <td>0.919025</td>\n      <td>0.919311</td>\n      <td>0.919448</td>\n      <td>0.918809</td>\n      <td>0.000882</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>32.430072</td>\n      <td>1.499737</td>\n      <td>0.080160</td>\n      <td>0.020595</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>None</td>\n      <td>best</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.917934</td>\n      <td>0.917204</td>\n      <td>0.920893</td>\n      <td>0.919621</td>\n      <td>0.917341</td>\n      <td>0.918599</td>\n      <td>0.001434</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>26.613685</td>\n      <td>0.291141</td>\n      <td>0.071952</td>\n      <td>0.007728</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>best</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.918913</td>\n      <td>0.916596</td>\n      <td>0.919045</td>\n      <td>0.920020</td>\n      <td>0.918135</td>\n      <td>0.918542</td>\n      <td>0.001143</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>2.027398</td>\n      <td>0.049281</td>\n      <td>0.100591</td>\n      <td>0.011510</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.920312</td>\n      <td>0.916054</td>\n      <td>0.918227</td>\n      <td>0.918374</td>\n      <td>0.918255</td>\n      <td>0.918244</td>\n      <td>0.001348</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>1.966272</td>\n      <td>0.052782</td>\n      <td>0.081618</td>\n      <td>0.004628</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.920312</td>\n      <td>0.916054</td>\n      <td>0.918227</td>\n      <td>0.918374</td>\n      <td>0.918255</td>\n      <td>0.918244</td>\n      <td>0.001348</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>1.859982</td>\n      <td>0.045420</td>\n      <td>0.088466</td>\n      <td>0.006745</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.920312</td>\n      <td>0.916054</td>\n      <td>0.918227</td>\n      <td>0.918374</td>\n      <td>0.918255</td>\n      <td>0.918244</td>\n      <td>0.001348</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>2.327800</td>\n      <td>0.057561</td>\n      <td>0.084380</td>\n      <td>0.007647</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>best</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.916890</td>\n      <td>0.917979</td>\n      <td>0.917700</td>\n      <td>0.918868</td>\n      <td>0.919644</td>\n      <td>0.918216</td>\n      <td>0.000954</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2.503849</td>\n      <td>0.028811</td>\n      <td>0.071870</td>\n      <td>0.007655</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>best</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.916890</td>\n      <td>0.917979</td>\n      <td>0.917700</td>\n      <td>0.918868</td>\n      <td>0.919644</td>\n      <td>0.918216</td>\n      <td>0.000954</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1.701962</td>\n      <td>0.046839</td>\n      <td>0.093766</td>\n      <td>0.009871</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.920538</td>\n      <td>0.915398</td>\n      <td>0.917283</td>\n      <td>0.918307</td>\n      <td>0.919254</td>\n      <td>0.918156</td>\n      <td>0.001748</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>1.569760</td>\n      <td>0.021181</td>\n      <td>0.131273</td>\n      <td>0.012500</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>log2</td>\n      <td>best</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.919209</td>\n      <td>0.917630</td>\n      <td>0.917716</td>\n      <td>0.918299</td>\n      <td>0.917478</td>\n      <td>0.918066</td>\n      <td>0.000635</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>1.874212</td>\n      <td>0.027817</td>\n      <td>0.092419</td>\n      <td>0.003337</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>log2</td>\n      <td>best</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.919209</td>\n      <td>0.917630</td>\n      <td>0.917716</td>\n      <td>0.918299</td>\n      <td>0.917478</td>\n      <td>0.918066</td>\n      <td>0.000635</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.695048</td>\n      <td>0.035076</td>\n      <td>0.071870</td>\n      <td>0.007653</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.917337</td>\n      <td>0.917360</td>\n      <td>0.920061</td>\n      <td>0.917298</td>\n      <td>0.917075</td>\n      <td>0.917826</td>\n      <td>0.001122</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>1.836015</td>\n      <td>0.037503</td>\n      <td>0.087522</td>\n      <td>0.012491</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.917337</td>\n      <td>0.917360</td>\n      <td>0.920061</td>\n      <td>0.917298</td>\n      <td>0.917075</td>\n      <td>0.917826</td>\n      <td>0.001122</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.024992</td>\n      <td>0.042389</td>\n      <td>0.093755</td>\n      <td>0.013989</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.917337</td>\n      <td>0.917360</td>\n      <td>0.920061</td>\n      <td>0.917298</td>\n      <td>0.917075</td>\n      <td>0.917826</td>\n      <td>0.001122</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>2.692785</td>\n      <td>0.095013</td>\n      <td>0.093336</td>\n      <td>0.013960</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>best</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.919536</td>\n      <td>0.915692</td>\n      <td>0.918304</td>\n      <td>0.919768</td>\n      <td>0.915791</td>\n      <td>0.917818</td>\n      <td>0.001767</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2.756969</td>\n      <td>0.073684</td>\n      <td>0.096116</td>\n      <td>0.013414</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>best</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.919536</td>\n      <td>0.915692</td>\n      <td>0.918304</td>\n      <td>0.919768</td>\n      <td>0.915791</td>\n      <td>0.917818</td>\n      <td>0.001767</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1.833678</td>\n      <td>0.055816</td>\n      <td>0.100000</td>\n      <td>0.027247</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>log2</td>\n      <td>best</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.918279</td>\n      <td>0.916726</td>\n      <td>0.914402</td>\n      <td>0.919466</td>\n      <td>0.919188</td>\n      <td>0.917612</td>\n      <td>0.001869</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2.226726</td>\n      <td>0.072383</td>\n      <td>0.081283</td>\n      <td>0.011707</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>best</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.917956</td>\n      <td>0.916734</td>\n      <td>0.918159</td>\n      <td>0.916819</td>\n      <td>0.917447</td>\n      <td>0.917423</td>\n      <td>0.000577</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47.578724</td>\n      <td>4.711592</td>\n      <td>0.074520</td>\n      <td>0.010506</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>None</td>\n      <td>best</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.915449</td>\n      <td>0.915814</td>\n      <td>0.917675</td>\n      <td>0.920324</td>\n      <td>0.917419</td>\n      <td>0.917336</td>\n      <td>0.001728</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1.590742</td>\n      <td>0.073559</td>\n      <td>0.084385</td>\n      <td>0.012493</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>best</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.918609</td>\n      <td>0.916059</td>\n      <td>0.916138</td>\n      <td>0.919158</td>\n      <td>0.916238</td>\n      <td>0.917240</td>\n      <td>0.001354</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>1.717093</td>\n      <td>0.045715</td>\n      <td>0.087596</td>\n      <td>0.007598</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>best</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.915772</td>\n      <td>0.915482</td>\n      <td>0.917644</td>\n      <td>0.917200</td>\n      <td>0.916008</td>\n      <td>0.916421</td>\n      <td>0.000846</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.751587</td>\n      <td>0.083179</td>\n      <td>0.115016</td>\n      <td>0.025277</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>best</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.915772</td>\n      <td>0.915482</td>\n      <td>0.917644</td>\n      <td>0.917200</td>\n      <td>0.916008</td>\n      <td>0.916421</td>\n      <td>0.000846</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1.429637</td>\n      <td>0.042620</td>\n      <td>0.084388</td>\n      <td>0.012489</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>log2</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.914456</td>\n      <td>0.915331</td>\n      <td>0.911781</td>\n      <td>0.918421</td>\n      <td>0.912047</td>\n      <td>0.914407</td>\n      <td>0.002426</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.669425</td>\n      <td>0.021381</td>\n      <td>0.104163</td>\n      <td>0.008792</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>random</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.912816</td>\n      <td>0.910685</td>\n      <td>0.911686</td>\n      <td>0.916633</td>\n      <td>0.912178</td>\n      <td>0.912800</td>\n      <td>0.002039</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>1.378603</td>\n      <td>0.023124</td>\n      <td>0.091270</td>\n      <td>0.011837</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>random</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.911983</td>\n      <td>0.907660</td>\n      <td>0.913700</td>\n      <td>0.913307</td>\n      <td>0.911735</td>\n      <td>0.911677</td>\n      <td>0.002144</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>1.547312</td>\n      <td>0.026558</td>\n      <td>0.087502</td>\n      <td>0.007653</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>random</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.911983</td>\n      <td>0.907660</td>\n      <td>0.913700</td>\n      <td>0.913307</td>\n      <td>0.911735</td>\n      <td>0.911677</td>\n      <td>0.002144</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1.408097</td>\n      <td>0.024658</td>\n      <td>0.093708</td>\n      <td>0.000016</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>log2</td>\n      <td>random</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.910545</td>\n      <td>0.908601</td>\n      <td>0.910647</td>\n      <td>0.911585</td>\n      <td>0.914793</td>\n      <td>0.911234</td>\n      <td>0.002027</td>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_grid_search_dataframe = pd.DataFrame(\n",
    "    np.load(\"Dataset_Files/Baseline_Models/Classification/optimised_dtc_cv_results.npy\", allow_pickle=True).tolist())\n",
    "dtc_grid_search_dataframe.sort_values(by=[\"rank_test_score\"], inplace=True)\n",
    "dtc_grid_search_dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 500\n",
      "--------------------------------------------------------\n",
      "Median Recall: 0.71 with a 95% confidence interval of [0.67,0.76]\n",
      "Median Precision: 0.75 with a 95% confidence interval of [0.71,0.80]\n",
      "Median F1: 0.73 with a 95% confidence interval of [0.69,0.77]\n",
      "Median Accuracy: 0.64 with a 95% confidence interval of [0.60,0.68]\n",
      "Median MCC: 0.18 with a 95% confidence interval of [0.09,0.27]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_dtc, X_test, y_test, 500, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest Classifier (RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model', RandomForestClassifier(random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': RandomForestClassifier(random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__bootstrap': True,\n 'model__ccp_alpha': 0.0,\n 'model__class_weight': None,\n 'model__criterion': 'gini',\n 'model__max_depth': None,\n 'model__max_features': 'sqrt',\n 'model__max_leaf_nodes': None,\n 'model__max_samples': None,\n 'model__min_impurity_decrease': 0.0,\n 'model__min_samples_leaf': 1,\n 'model__min_samples_split': 2,\n 'model__min_weight_fraction_leaf': 0.0,\n 'model__n_estimators': 100,\n 'model__n_jobs': None,\n 'model__oob_score': False,\n 'model__random_state': 42,\n 'model__verbose': 0,\n 'model__warm_start': False}"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scale', StandardScaler()),\n",
    "        ('model', RandomForestClassifier(random_state=42))\n",
    "    ]\n",
    ")\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = BayesSearchCV(estimator=pipe,\n",
    "                      search_spaces=\n",
    "                      {'model__n_estimators': Integer(100, 800),\n",
    "                       'model__criterion': Categorical(['gini', 'entropy', 'log_loss']),\n",
    "                       'model__max_features': Categorical([None, 'sqrt', 'log2']),\n",
    "                       'model__class_weight': Categorical([None, 'balanced', 'balanced_subsample'])\n",
    "                       },\n",
    "                      scoring='f1',\n",
    "                      cv=5,\n",
    "                      error_score=np.nan,\n",
    "                      n_jobs=-1,\n",
    "                      pre_dispatch='2*n_jobs',\n",
    "                      random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# index = 1\n",
    "# model.fit(X_train, y_train, callback=on_step)\n",
    "#\n",
    "# optimised_rfc = model.best_estimator_\n",
    "#\n",
    "# y_train_pred = optimised_rfc.predict(X_train)\n",
    "# calculate_metrics_classification(y_train, y_train_pred)\n",
    "#\n",
    "# # Save Model\n",
    "# dump(optimised_rfc, 'Dataset_Files/Baseline_Models/Classification/optimised_rfc.joblib')\n",
    "# np.save(\"Dataset_Files/Baseline_Models/Classification/optimised_rfc_cv_results.npy\", model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# Load Model\n",
    "optimised_rfc = load('Dataset_Files/Baseline_Models/Classification/optimised_rfc.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 1000\n",
      "--------------------------------------------------------\n",
      "Median Recall: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median Precision: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median F1: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median Accuracy: 1.00 with a 95% confidence interval of [1.00,1.00]\n",
      "Median MCC: 1.00 with a 95% confidence interval of [1.00,1.00]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_rfc, X_train, y_train, 1000, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model',\n   RandomForestClassifier(criterion='entropy', max_features=None, n_estimators=799,\n                          random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': RandomForestClassifier(criterion='entropy', max_features=None, n_estimators=799,\n                        random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__bootstrap': True,\n 'model__ccp_alpha': 0.0,\n 'model__class_weight': None,\n 'model__criterion': 'entropy',\n 'model__max_depth': None,\n 'model__max_features': None,\n 'model__max_leaf_nodes': None,\n 'model__max_samples': None,\n 'model__min_impurity_decrease': 0.0,\n 'model__min_samples_leaf': 1,\n 'model__min_samples_split': 2,\n 'model__min_weight_fraction_leaf': 0.0,\n 'model__n_estimators': 799,\n 'model__n_jobs': None,\n 'model__oob_score': False,\n 'model__random_state': 42,\n 'model__verbose': 0,\n 'model__warm_start': False}"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimised_rfc.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n13   16898.942848     81.928433         5.966139        0.794394   \n49   14031.461306     49.547133         5.234502        0.618534   \n19   15946.972400    127.733869        12.078268        2.661393   \n44   13844.117221     59.094871         5.841689        0.715712   \n23   20453.466873     62.563594         6.860888        1.153252   \n16   14270.508583     58.413429         5.247010        0.617883   \n48   18277.824007     73.331706         6.267198        1.122905   \n39   13702.078298     73.717344         5.111344        0.622625   \n45   15396.591052     58.853851         6.315138        1.347216   \n31   13564.366297     52.906671         5.246218        0.801017   \n33   13673.874352     67.747572         6.382504        1.143049   \n34   16286.235630    132.743527        14.257385        1.639299   \n36   21435.536257     54.316198         6.345252        0.897030   \n37   13755.462110     54.690405         5.195492        0.715487   \n47   18692.215819    166.424583        15.316086        2.619209   \n27   12519.818798     43.121996         4.924381        0.494517   \n5     3902.399420      9.505767         1.449567        0.182472   \n2     6779.073320     19.975554         2.667546        0.355795   \n29    3363.060958     13.134122         1.348213        0.173339   \n14    1681.524561     10.144290         0.692009        0.100879   \n11    1816.098255     10.035743         0.703744        0.076370   \n12   30224.931937     81.703363         7.349922        1.118624   \n20   17310.744819     49.825324         4.598238        0.691819   \n28    3173.285284     41.831978         0.856841        0.115916   \n17   10308.864132     50.149852         3.805250        0.485125   \n7      619.600894      1.622474         6.037332        0.169792   \n6      643.287335      1.649804         6.263818        0.297116   \n35    1563.058823      2.624444        13.733911        0.603931   \n9      259.104246      0.421726         2.479930        0.058403   \n32     385.026346      0.877611         3.628836        0.218351   \n1      709.582681      1.743284         7.169362        0.387766   \n38     402.694624      1.220985         4.029641        0.371186   \n43     796.965170      1.816679         6.889778        0.200154   \n3      614.072000      0.484783         6.173640        0.024593   \n18     718.325676      5.286180         6.807955        0.961451   \n4      561.586023      2.118599         6.337098        0.660861   \n15      93.416879      0.269706         0.913513        0.035017   \n25      88.450746      0.346537         0.828431        0.065010   \n42     132.709218      0.691395         1.323703        0.147575   \n26     323.662767      0.964103         7.703709        0.409996   \n10     347.579725      0.705520         8.431970        0.101914   \n0      136.200675      0.549271         3.504577        0.185863   \n21     126.770246      0.532006         3.177777        0.079588   \n41     206.629923      0.568967         5.097892        0.108359   \n22      52.680727      0.421691         1.027410        0.062114   \n46      55.131252      0.278878         1.538894        0.106783   \n8      170.014446      0.209937         4.381587        0.018258   \n24      44.626302      0.567197         0.961206        0.131189   \n40      49.180252      0.490156         1.249152        0.156566   \n30      42.894490      0.280651         1.069137        0.032160   \n\n   param_model__class_weight param_model__criterion param_model__max_features  \\\n13                      None                entropy                      None   \n49                      None               log_loss                      None   \n19                      None               log_loss                      None   \n44                      None               log_loss                      None   \n23                      None               log_loss                      None   \n16                      None               log_loss                      None   \n48                      None                entropy                      None   \n39                      None                entropy                      None   \n45                      None                entropy                      None   \n31                      None                entropy                      None   \n33                      None                entropy                      None   \n34                      None                entropy                      None   \n36                      None                entropy                      None   \n37                      None                entropy                      None   \n47                      None               log_loss                      None   \n27        balanced_subsample                entropy                      None   \n5                   balanced               log_loss                      None   \n2                   balanced               log_loss                      None   \n29        balanced_subsample               log_loss                      None   \n14        balanced_subsample                entropy                      None   \n11                      None                entropy                      None   \n12        balanced_subsample                   gini                      None   \n20        balanced_subsample                   gini                      None   \n28                      None                   gini                      None   \n17                  balanced                   gini                      None   \n7                   balanced               log_loss                      sqrt   \n6                   balanced               log_loss                      sqrt   \n35                  balanced                entropy                      sqrt   \n9                       None               log_loss                      sqrt   \n32                      None               log_loss                      sqrt   \n1         balanced_subsample               log_loss                      sqrt   \n38                      None                entropy                      sqrt   \n43                      None                   gini                      sqrt   \n3         balanced_subsample                entropy                      sqrt   \n18                  balanced                   gini                      sqrt   \n4         balanced_subsample                   gini                      sqrt   \n15        balanced_subsample                   gini                      sqrt   \n25                      None                entropy                      sqrt   \n42                  balanced                   gini                      sqrt   \n26                      None               log_loss                      log2   \n10                      None                entropy                      log2   \n0                   balanced                   gini                      log2   \n21                  balanced                   gini                      log2   \n41                      None               log_loss                      log2   \n22        balanced_subsample               log_loss                      log2   \n46                  balanced                entropy                      log2   \n8         balanced_subsample                   gini                      log2   \n24        balanced_subsample                entropy                      log2   \n40                  balanced                   gini                      log2   \n30                  balanced                   gini                      log2   \n\n   param_model__n_estimators  \\\n13                       799   \n49                       800   \n19                       800   \n44                       800   \n23                       800   \n16                       800   \n48                       800   \n39                       800   \n45                       800   \n31                       800   \n33                       800   \n34                       800   \n36                       800   \n37                       800   \n47                       800   \n27                       800   \n5                        232   \n2                        403   \n29                       215   \n14                       102   \n11                       100   \n12                       798   \n20                       519   \n28                       100   \n17                       498   \n7                        686   \n6                        712   \n35                       713   \n9                        278   \n32                       442   \n1                        766   \n38                       460   \n43                       753   \n3                        662   \n18                       800   \n4                        601   \n15                       101   \n25                       101   \n42                       153   \n26                       799   \n10                       800   \n0                        321   \n21                       271   \n41                       504   \n22                       101   \n46                       106   \n8                        391   \n24                       103   \n40                       124   \n30                       109   \n\n                                               params  split0_test_score  \\\n13  {'model__class_weight': None, 'model__criterio...           0.949162   \n49  {'model__class_weight': None, 'model__criterio...           0.949127   \n19  {'model__class_weight': None, 'model__criterio...           0.949127   \n44  {'model__class_weight': None, 'model__criterio...           0.949127   \n23  {'model__class_weight': None, 'model__criterio...           0.949127   \n16  {'model__class_weight': None, 'model__criterio...           0.949127   \n48  {'model__class_weight': None, 'model__criterio...           0.949127   \n39  {'model__class_weight': None, 'model__criterio...           0.949127   \n45  {'model__class_weight': None, 'model__criterio...           0.949127   \n31  {'model__class_weight': None, 'model__criterio...           0.949127   \n33  {'model__class_weight': None, 'model__criterio...           0.949127   \n34  {'model__class_weight': None, 'model__criterio...           0.949127   \n36  {'model__class_weight': None, 'model__criterio...           0.949127   \n37  {'model__class_weight': None, 'model__criterio...           0.949127   \n47  {'model__class_weight': None, 'model__criterio...           0.949127   \n27  {'model__class_weight': 'balanced_subsample', ...           0.949397   \n5   {'model__class_weight': 'balanced', 'model__cr...           0.949241   \n2   {'model__class_weight': 'balanced', 'model__cr...           0.948833   \n29  {'model__class_weight': 'balanced_subsample', ...           0.949071   \n14  {'model__class_weight': 'balanced_subsample', ...           0.949395   \n11  {'model__class_weight': None, 'model__criterio...           0.947934   \n12  {'model__class_weight': 'balanced_subsample', ...           0.948487   \n20  {'model__class_weight': 'balanced_subsample', ...           0.948227   \n28  {'model__class_weight': None, 'model__criterio...           0.947316   \n17  {'model__class_weight': 'balanced', 'model__cr...           0.948227   \n7   {'model__class_weight': 'balanced', 'model__cr...           0.946813   \n6   {'model__class_weight': 'balanced', 'model__cr...           0.946820   \n35  {'model__class_weight': 'balanced', 'model__cr...           0.946725   \n9   {'model__class_weight': None, 'model__criterio...           0.946323   \n32  {'model__class_weight': None, 'model__criterio...           0.946530   \n1   {'model__class_weight': 'balanced_subsample', ...           0.945691   \n38  {'model__class_weight': None, 'model__criterio...           0.946498   \n43  {'model__class_weight': None, 'model__criterio...           0.946558   \n3   {'model__class_weight': 'balanced_subsample', ...           0.945621   \n18  {'model__class_weight': 'balanced', 'model__cr...           0.945762   \n4   {'model__class_weight': 'balanced_subsample', ...           0.945959   \n15  {'model__class_weight': 'balanced_subsample', ...           0.944743   \n25  {'model__class_weight': None, 'model__criterio...           0.945498   \n42  {'model__class_weight': 'balanced', 'model__cr...           0.945493   \n26  {'model__class_weight': None, 'model__criterio...           0.944019   \n10  {'model__class_weight': None, 'model__criterio...           0.944114   \n0   {'model__class_weight': 'balanced', 'model__cr...           0.944597   \n21  {'model__class_weight': 'balanced', 'model__cr...           0.944463   \n41  {'model__class_weight': None, 'model__criterio...           0.944143   \n22  {'model__class_weight': 'balanced_subsample', ...           0.944920   \n46  {'model__class_weight': 'balanced', 'model__cr...           0.943942   \n8   {'model__class_weight': 'balanced_subsample', ...           0.944175   \n24  {'model__class_weight': 'balanced_subsample', ...           0.945090   \n40  {'model__class_weight': 'balanced', 'model__cr...           0.944249   \n30  {'model__class_weight': 'balanced', 'model__cr...           0.944234   \n\n    split1_test_score  split2_test_score  split3_test_score  \\\n13           0.946310           0.948151           0.949253   \n49           0.946170           0.948214           0.949250   \n19           0.946170           0.948214           0.949250   \n44           0.946170           0.948214           0.949250   \n23           0.946170           0.948214           0.949250   \n16           0.946170           0.948214           0.949250   \n48           0.946170           0.948214           0.949250   \n39           0.946170           0.948214           0.949250   \n45           0.946170           0.948214           0.949250   \n31           0.946170           0.948214           0.949250   \n33           0.946170           0.948214           0.949250   \n34           0.946170           0.948214           0.949250   \n36           0.946170           0.948214           0.949250   \n37           0.946170           0.948214           0.949250   \n47           0.946170           0.948214           0.949250   \n27           0.945974           0.947936           0.949473   \n5            0.945542           0.947558           0.948993   \n2            0.945442           0.947715           0.949094   \n29           0.945647           0.947186           0.949041   \n14           0.945236           0.947277           0.948531   \n11           0.945330           0.947523           0.948414   \n12           0.945433           0.947130           0.948018   \n20           0.945486           0.946934           0.948046   \n28           0.944715           0.947309           0.947763   \n17           0.945068           0.946906           0.947941   \n7            0.943120           0.944452           0.946052   \n6            0.943026           0.944487           0.945950   \n35           0.942963           0.944459           0.945894   \n9            0.943225           0.944210           0.945700   \n32           0.943016           0.944166           0.945457   \n1            0.942955           0.944767           0.945650   \n38           0.942907           0.943986           0.945386   \n43           0.943269           0.944305           0.945160   \n3            0.942968           0.944528           0.945520   \n18           0.942684           0.944257           0.945175   \n4            0.942356           0.944320           0.945217   \n15           0.943386           0.944053           0.944909   \n25           0.942691           0.943915           0.945180   \n42           0.942512           0.944365           0.944576   \n26           0.941471           0.943716           0.944670   \n10           0.941396           0.943744           0.944698   \n0            0.941679           0.943693           0.944245   \n21           0.941757           0.943425           0.944277   \n41           0.941510           0.943680           0.943972   \n22           0.940855           0.942360           0.944201   \n46           0.941483           0.943218           0.943796   \n8            0.941416           0.942808           0.944091   \n24           0.940788           0.942065           0.944003   \n40           0.940917           0.942503           0.944055   \n30           0.940419           0.942486           0.944033   \n\n    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n13           0.947203         0.948016        0.001134                1  \n49           0.947126         0.947977        0.001182                2  \n19           0.947126         0.947977        0.001182                2  \n44           0.947126         0.947977        0.001182                2  \n23           0.947126         0.947977        0.001182                2  \n16           0.947126         0.947977        0.001182                2  \n48           0.947126         0.947977        0.001182                2  \n39           0.947126         0.947977        0.001182                2  \n45           0.947126         0.947977        0.001182                2  \n31           0.947126         0.947977        0.001182                2  \n33           0.947126         0.947977        0.001182                2  \n34           0.947126         0.947977        0.001182                2  \n36           0.947126         0.947977        0.001182                2  \n37           0.947126         0.947977        0.001182                2  \n47           0.947126         0.947977        0.001182                2  \n27           0.946874         0.947931        0.001377               16  \n5            0.946667         0.947600        0.001396               17  \n2            0.946573         0.947531        0.001375               18  \n29           0.946512         0.947491        0.001367               19  \n14           0.946659         0.947420        0.001450               20  \n11           0.946373         0.947115        0.001119               21  \n12           0.946135         0.947041        0.001137               22  \n20           0.945626         0.946864        0.001157               23  \n28           0.946777         0.946776        0.001077               24  \n17           0.945560         0.946741        0.001255               25  \n7            0.943973         0.944882        0.001357               26  \n6            0.944032         0.944863        0.001358               27  \n35           0.944040         0.944816        0.001339               28  \n9            0.943951         0.944682        0.001150               29  \n32           0.944193         0.944673        0.001208               30  \n1            0.943750         0.944563        0.001072               31  \n38           0.943953         0.944546        0.001255               32  \n43           0.943353         0.944529        0.001228               33  \n3            0.943553         0.944438        0.001051               34  \n18           0.943850         0.944346        0.001068               35  \n4            0.943496         0.944270        0.001266               36  \n15           0.943308         0.944080        0.000664               37  \n25           0.943083         0.944074        0.001111               38  \n42           0.943104         0.944010        0.001069               39  \n26           0.943363         0.943448        0.001078               40  \n10           0.943257         0.943442        0.001126               41  \n0            0.942168         0.943276        0.001152               42  \n21           0.942412         0.943267        0.001047               43  \n41           0.942883         0.943238        0.000966               44  \n22           0.942810         0.943029        0.001426               45  \n46           0.942655         0.943019        0.000893               46  \n8            0.942452         0.942988        0.001041               47  \n24           0.942976         0.942984        0.001492               48  \n40           0.942838         0.942912        0.001204               49  \n30           0.942755         0.942786        0.001367               50  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_model__class_weight</th>\n      <th>param_model__criterion</th>\n      <th>param_model__max_features</th>\n      <th>param_model__n_estimators</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>13</th>\n      <td>16898.942848</td>\n      <td>81.928433</td>\n      <td>5.966139</td>\n      <td>0.794394</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>799</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949162</td>\n      <td>0.946310</td>\n      <td>0.948151</td>\n      <td>0.949253</td>\n      <td>0.947203</td>\n      <td>0.948016</td>\n      <td>0.001134</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>14031.461306</td>\n      <td>49.547133</td>\n      <td>5.234502</td>\n      <td>0.618534</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>800</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949127</td>\n      <td>0.946170</td>\n      <td>0.948214</td>\n      <td>0.949250</td>\n      <td>0.947126</td>\n      <td>0.947977</td>\n      <td>0.001182</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>15946.972400</td>\n      <td>127.733869</td>\n      <td>12.078268</td>\n      <td>2.661393</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>800</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949127</td>\n      <td>0.946170</td>\n      <td>0.948214</td>\n      <td>0.949250</td>\n      <td>0.947126</td>\n      <td>0.947977</td>\n      <td>0.001182</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>13844.117221</td>\n      <td>59.094871</td>\n      <td>5.841689</td>\n      <td>0.715712</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>800</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949127</td>\n      <td>0.946170</td>\n      <td>0.948214</td>\n      <td>0.949250</td>\n      <td>0.947126</td>\n      <td>0.947977</td>\n      <td>0.001182</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>20453.466873</td>\n      <td>62.563594</td>\n      <td>6.860888</td>\n      <td>1.153252</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>800</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949127</td>\n      <td>0.946170</td>\n      <td>0.948214</td>\n      <td>0.949250</td>\n      <td>0.947126</td>\n      <td>0.947977</td>\n      <td>0.001182</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>14270.508583</td>\n      <td>58.413429</td>\n      <td>5.247010</td>\n      <td>0.617883</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>800</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949127</td>\n      <td>0.946170</td>\n      <td>0.948214</td>\n      <td>0.949250</td>\n      <td>0.947126</td>\n      <td>0.947977</td>\n      <td>0.001182</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>18277.824007</td>\n      <td>73.331706</td>\n      <td>6.267198</td>\n      <td>1.122905</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>800</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949127</td>\n      <td>0.946170</td>\n      <td>0.948214</td>\n      <td>0.949250</td>\n      <td>0.947126</td>\n      <td>0.947977</td>\n      <td>0.001182</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>13702.078298</td>\n      <td>73.717344</td>\n      <td>5.111344</td>\n      <td>0.622625</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>800</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949127</td>\n      <td>0.946170</td>\n      <td>0.948214</td>\n      <td>0.949250</td>\n      <td>0.947126</td>\n      <td>0.947977</td>\n      <td>0.001182</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>15396.591052</td>\n      <td>58.853851</td>\n      <td>6.315138</td>\n      <td>1.347216</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>800</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949127</td>\n      <td>0.946170</td>\n      <td>0.948214</td>\n      <td>0.949250</td>\n      <td>0.947126</td>\n      <td>0.947977</td>\n      <td>0.001182</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>13564.366297</td>\n      <td>52.906671</td>\n      <td>5.246218</td>\n      <td>0.801017</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>800</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949127</td>\n      <td>0.946170</td>\n      <td>0.948214</td>\n      <td>0.949250</td>\n      <td>0.947126</td>\n      <td>0.947977</td>\n      <td>0.001182</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>13673.874352</td>\n      <td>67.747572</td>\n      <td>6.382504</td>\n      <td>1.143049</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>800</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949127</td>\n      <td>0.946170</td>\n      <td>0.948214</td>\n      <td>0.949250</td>\n      <td>0.947126</td>\n      <td>0.947977</td>\n      <td>0.001182</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>16286.235630</td>\n      <td>132.743527</td>\n      <td>14.257385</td>\n      <td>1.639299</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>800</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949127</td>\n      <td>0.946170</td>\n      <td>0.948214</td>\n      <td>0.949250</td>\n      <td>0.947126</td>\n      <td>0.947977</td>\n      <td>0.001182</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>21435.536257</td>\n      <td>54.316198</td>\n      <td>6.345252</td>\n      <td>0.897030</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>800</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949127</td>\n      <td>0.946170</td>\n      <td>0.948214</td>\n      <td>0.949250</td>\n      <td>0.947126</td>\n      <td>0.947977</td>\n      <td>0.001182</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>13755.462110</td>\n      <td>54.690405</td>\n      <td>5.195492</td>\n      <td>0.715487</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>800</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949127</td>\n      <td>0.946170</td>\n      <td>0.948214</td>\n      <td>0.949250</td>\n      <td>0.947126</td>\n      <td>0.947977</td>\n      <td>0.001182</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>18692.215819</td>\n      <td>166.424583</td>\n      <td>15.316086</td>\n      <td>2.619209</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>800</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.949127</td>\n      <td>0.946170</td>\n      <td>0.948214</td>\n      <td>0.949250</td>\n      <td>0.947126</td>\n      <td>0.947977</td>\n      <td>0.001182</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>12519.818798</td>\n      <td>43.121996</td>\n      <td>4.924381</td>\n      <td>0.494517</td>\n      <td>balanced_subsample</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>800</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.949397</td>\n      <td>0.945974</td>\n      <td>0.947936</td>\n      <td>0.949473</td>\n      <td>0.946874</td>\n      <td>0.947931</td>\n      <td>0.001377</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3902.399420</td>\n      <td>9.505767</td>\n      <td>1.449567</td>\n      <td>0.182472</td>\n      <td>balanced</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>232</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.949241</td>\n      <td>0.945542</td>\n      <td>0.947558</td>\n      <td>0.948993</td>\n      <td>0.946667</td>\n      <td>0.947600</td>\n      <td>0.001396</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6779.073320</td>\n      <td>19.975554</td>\n      <td>2.667546</td>\n      <td>0.355795</td>\n      <td>balanced</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>403</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.948833</td>\n      <td>0.945442</td>\n      <td>0.947715</td>\n      <td>0.949094</td>\n      <td>0.946573</td>\n      <td>0.947531</td>\n      <td>0.001375</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>3363.060958</td>\n      <td>13.134122</td>\n      <td>1.348213</td>\n      <td>0.173339</td>\n      <td>balanced_subsample</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>215</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.949071</td>\n      <td>0.945647</td>\n      <td>0.947186</td>\n      <td>0.949041</td>\n      <td>0.946512</td>\n      <td>0.947491</td>\n      <td>0.001367</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1681.524561</td>\n      <td>10.144290</td>\n      <td>0.692009</td>\n      <td>0.100879</td>\n      <td>balanced_subsample</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>102</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.949395</td>\n      <td>0.945236</td>\n      <td>0.947277</td>\n      <td>0.948531</td>\n      <td>0.946659</td>\n      <td>0.947420</td>\n      <td>0.001450</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1816.098255</td>\n      <td>10.035743</td>\n      <td>0.703744</td>\n      <td>0.076370</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>None</td>\n      <td>100</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.947934</td>\n      <td>0.945330</td>\n      <td>0.947523</td>\n      <td>0.948414</td>\n      <td>0.946373</td>\n      <td>0.947115</td>\n      <td>0.001119</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>30224.931937</td>\n      <td>81.703363</td>\n      <td>7.349922</td>\n      <td>1.118624</td>\n      <td>balanced_subsample</td>\n      <td>gini</td>\n      <td>None</td>\n      <td>798</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.948487</td>\n      <td>0.945433</td>\n      <td>0.947130</td>\n      <td>0.948018</td>\n      <td>0.946135</td>\n      <td>0.947041</td>\n      <td>0.001137</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>17310.744819</td>\n      <td>49.825324</td>\n      <td>4.598238</td>\n      <td>0.691819</td>\n      <td>balanced_subsample</td>\n      <td>gini</td>\n      <td>None</td>\n      <td>519</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.948227</td>\n      <td>0.945486</td>\n      <td>0.946934</td>\n      <td>0.948046</td>\n      <td>0.945626</td>\n      <td>0.946864</td>\n      <td>0.001157</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>3173.285284</td>\n      <td>41.831978</td>\n      <td>0.856841</td>\n      <td>0.115916</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>None</td>\n      <td>100</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.947316</td>\n      <td>0.944715</td>\n      <td>0.947309</td>\n      <td>0.947763</td>\n      <td>0.946777</td>\n      <td>0.946776</td>\n      <td>0.001077</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>10308.864132</td>\n      <td>50.149852</td>\n      <td>3.805250</td>\n      <td>0.485125</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>None</td>\n      <td>498</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.948227</td>\n      <td>0.945068</td>\n      <td>0.946906</td>\n      <td>0.947941</td>\n      <td>0.945560</td>\n      <td>0.946741</td>\n      <td>0.001255</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>619.600894</td>\n      <td>1.622474</td>\n      <td>6.037332</td>\n      <td>0.169792</td>\n      <td>balanced</td>\n      <td>log_loss</td>\n      <td>sqrt</td>\n      <td>686</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.946813</td>\n      <td>0.943120</td>\n      <td>0.944452</td>\n      <td>0.946052</td>\n      <td>0.943973</td>\n      <td>0.944882</td>\n      <td>0.001357</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>643.287335</td>\n      <td>1.649804</td>\n      <td>6.263818</td>\n      <td>0.297116</td>\n      <td>balanced</td>\n      <td>log_loss</td>\n      <td>sqrt</td>\n      <td>712</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.946820</td>\n      <td>0.943026</td>\n      <td>0.944487</td>\n      <td>0.945950</td>\n      <td>0.944032</td>\n      <td>0.944863</td>\n      <td>0.001358</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>1563.058823</td>\n      <td>2.624444</td>\n      <td>13.733911</td>\n      <td>0.603931</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>713</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.946725</td>\n      <td>0.942963</td>\n      <td>0.944459</td>\n      <td>0.945894</td>\n      <td>0.944040</td>\n      <td>0.944816</td>\n      <td>0.001339</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>259.104246</td>\n      <td>0.421726</td>\n      <td>2.479930</td>\n      <td>0.058403</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>sqrt</td>\n      <td>278</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.946323</td>\n      <td>0.943225</td>\n      <td>0.944210</td>\n      <td>0.945700</td>\n      <td>0.943951</td>\n      <td>0.944682</td>\n      <td>0.001150</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>385.026346</td>\n      <td>0.877611</td>\n      <td>3.628836</td>\n      <td>0.218351</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>sqrt</td>\n      <td>442</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.946530</td>\n      <td>0.943016</td>\n      <td>0.944166</td>\n      <td>0.945457</td>\n      <td>0.944193</td>\n      <td>0.944673</td>\n      <td>0.001208</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>709.582681</td>\n      <td>1.743284</td>\n      <td>7.169362</td>\n      <td>0.387766</td>\n      <td>balanced_subsample</td>\n      <td>log_loss</td>\n      <td>sqrt</td>\n      <td>766</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.945691</td>\n      <td>0.942955</td>\n      <td>0.944767</td>\n      <td>0.945650</td>\n      <td>0.943750</td>\n      <td>0.944563</td>\n      <td>0.001072</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>402.694624</td>\n      <td>1.220985</td>\n      <td>4.029641</td>\n      <td>0.371186</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>460</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.946498</td>\n      <td>0.942907</td>\n      <td>0.943986</td>\n      <td>0.945386</td>\n      <td>0.943953</td>\n      <td>0.944546</td>\n      <td>0.001255</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>796.965170</td>\n      <td>1.816679</td>\n      <td>6.889778</td>\n      <td>0.200154</td>\n      <td>None</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>753</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.946558</td>\n      <td>0.943269</td>\n      <td>0.944305</td>\n      <td>0.945160</td>\n      <td>0.943353</td>\n      <td>0.944529</td>\n      <td>0.001228</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>614.072000</td>\n      <td>0.484783</td>\n      <td>6.173640</td>\n      <td>0.024593</td>\n      <td>balanced_subsample</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>662</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.945621</td>\n      <td>0.942968</td>\n      <td>0.944528</td>\n      <td>0.945520</td>\n      <td>0.943553</td>\n      <td>0.944438</td>\n      <td>0.001051</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>718.325676</td>\n      <td>5.286180</td>\n      <td>6.807955</td>\n      <td>0.961451</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>800</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.945762</td>\n      <td>0.942684</td>\n      <td>0.944257</td>\n      <td>0.945175</td>\n      <td>0.943850</td>\n      <td>0.944346</td>\n      <td>0.001068</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>561.586023</td>\n      <td>2.118599</td>\n      <td>6.337098</td>\n      <td>0.660861</td>\n      <td>balanced_subsample</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>601</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.945959</td>\n      <td>0.942356</td>\n      <td>0.944320</td>\n      <td>0.945217</td>\n      <td>0.943496</td>\n      <td>0.944270</td>\n      <td>0.001266</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>93.416879</td>\n      <td>0.269706</td>\n      <td>0.913513</td>\n      <td>0.035017</td>\n      <td>balanced_subsample</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>101</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.944743</td>\n      <td>0.943386</td>\n      <td>0.944053</td>\n      <td>0.944909</td>\n      <td>0.943308</td>\n      <td>0.944080</td>\n      <td>0.000664</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>88.450746</td>\n      <td>0.346537</td>\n      <td>0.828431</td>\n      <td>0.065010</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>101</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.945498</td>\n      <td>0.942691</td>\n      <td>0.943915</td>\n      <td>0.945180</td>\n      <td>0.943083</td>\n      <td>0.944074</td>\n      <td>0.001111</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>132.709218</td>\n      <td>0.691395</td>\n      <td>1.323703</td>\n      <td>0.147575</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>153</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.945493</td>\n      <td>0.942512</td>\n      <td>0.944365</td>\n      <td>0.944576</td>\n      <td>0.943104</td>\n      <td>0.944010</td>\n      <td>0.001069</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>323.662767</td>\n      <td>0.964103</td>\n      <td>7.703709</td>\n      <td>0.409996</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>log2</td>\n      <td>799</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.944019</td>\n      <td>0.941471</td>\n      <td>0.943716</td>\n      <td>0.944670</td>\n      <td>0.943363</td>\n      <td>0.943448</td>\n      <td>0.001078</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>347.579725</td>\n      <td>0.705520</td>\n      <td>8.431970</td>\n      <td>0.101914</td>\n      <td>None</td>\n      <td>entropy</td>\n      <td>log2</td>\n      <td>800</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.944114</td>\n      <td>0.941396</td>\n      <td>0.943744</td>\n      <td>0.944698</td>\n      <td>0.943257</td>\n      <td>0.943442</td>\n      <td>0.001126</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>136.200675</td>\n      <td>0.549271</td>\n      <td>3.504577</td>\n      <td>0.185863</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>321</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.944597</td>\n      <td>0.941679</td>\n      <td>0.943693</td>\n      <td>0.944245</td>\n      <td>0.942168</td>\n      <td>0.943276</td>\n      <td>0.001152</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>126.770246</td>\n      <td>0.532006</td>\n      <td>3.177777</td>\n      <td>0.079588</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>271</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.944463</td>\n      <td>0.941757</td>\n      <td>0.943425</td>\n      <td>0.944277</td>\n      <td>0.942412</td>\n      <td>0.943267</td>\n      <td>0.001047</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>206.629923</td>\n      <td>0.568967</td>\n      <td>5.097892</td>\n      <td>0.108359</td>\n      <td>None</td>\n      <td>log_loss</td>\n      <td>log2</td>\n      <td>504</td>\n      <td>{'model__class_weight': None, 'model__criterio...</td>\n      <td>0.944143</td>\n      <td>0.941510</td>\n      <td>0.943680</td>\n      <td>0.943972</td>\n      <td>0.942883</td>\n      <td>0.943238</td>\n      <td>0.000966</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>52.680727</td>\n      <td>0.421691</td>\n      <td>1.027410</td>\n      <td>0.062114</td>\n      <td>balanced_subsample</td>\n      <td>log_loss</td>\n      <td>log2</td>\n      <td>101</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.944920</td>\n      <td>0.940855</td>\n      <td>0.942360</td>\n      <td>0.944201</td>\n      <td>0.942810</td>\n      <td>0.943029</td>\n      <td>0.001426</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>55.131252</td>\n      <td>0.278878</td>\n      <td>1.538894</td>\n      <td>0.106783</td>\n      <td>balanced</td>\n      <td>entropy</td>\n      <td>log2</td>\n      <td>106</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.943942</td>\n      <td>0.941483</td>\n      <td>0.943218</td>\n      <td>0.943796</td>\n      <td>0.942655</td>\n      <td>0.943019</td>\n      <td>0.000893</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>170.014446</td>\n      <td>0.209937</td>\n      <td>4.381587</td>\n      <td>0.018258</td>\n      <td>balanced_subsample</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>391</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.944175</td>\n      <td>0.941416</td>\n      <td>0.942808</td>\n      <td>0.944091</td>\n      <td>0.942452</td>\n      <td>0.942988</td>\n      <td>0.001041</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>44.626302</td>\n      <td>0.567197</td>\n      <td>0.961206</td>\n      <td>0.131189</td>\n      <td>balanced_subsample</td>\n      <td>entropy</td>\n      <td>log2</td>\n      <td>103</td>\n      <td>{'model__class_weight': 'balanced_subsample', ...</td>\n      <td>0.945090</td>\n      <td>0.940788</td>\n      <td>0.942065</td>\n      <td>0.944003</td>\n      <td>0.942976</td>\n      <td>0.942984</td>\n      <td>0.001492</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>49.180252</td>\n      <td>0.490156</td>\n      <td>1.249152</td>\n      <td>0.156566</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>124</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.944249</td>\n      <td>0.940917</td>\n      <td>0.942503</td>\n      <td>0.944055</td>\n      <td>0.942838</td>\n      <td>0.942912</td>\n      <td>0.001204</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>42.894490</td>\n      <td>0.280651</td>\n      <td>1.069137</td>\n      <td>0.032160</td>\n      <td>balanced</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>109</td>\n      <td>{'model__class_weight': 'balanced', 'model__cr...</td>\n      <td>0.944234</td>\n      <td>0.940419</td>\n      <td>0.942486</td>\n      <td>0.944033</td>\n      <td>0.942755</td>\n      <td>0.942786</td>\n      <td>0.001367</td>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_grid_search_dataframe = pd.DataFrame(\n",
    "    np.load(\"Dataset_Files/Baseline_Models/Classification/optimised_rfc_cv_results.npy\", allow_pickle=True).tolist())\n",
    "rfc_grid_search_dataframe.sort_values(by=[\"rank_test_score\"], inplace=True)\n",
    "rfc_grid_search_dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 500\n",
      "--------------------------------------------------------\n",
      "Median Recall: 0.93 with a 95% confidence interval of [0.90,0.96]\n",
      "Median Precision: 0.76 with a 95% confidence interval of [0.72,0.80]\n",
      "Median F1: 0.84 with a 95% confidence interval of [0.81,0.86]\n",
      "Median Accuracy: 0.75 with a 95% confidence interval of [0.71,0.79]\n",
      "Median MCC: 0.35 with a 95% confidence interval of [0.26,0.44]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_rfc, X_test, y_test, 500, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stochastic Gradient Descent Classifier (SGDC)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model', SGDClassifier(random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': SGDClassifier(random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__alpha': 0.0001,\n 'model__average': False,\n 'model__class_weight': None,\n 'model__early_stopping': False,\n 'model__epsilon': 0.1,\n 'model__eta0': 0.0,\n 'model__fit_intercept': True,\n 'model__l1_ratio': 0.15,\n 'model__learning_rate': 'optimal',\n 'model__loss': 'hinge',\n 'model__max_iter': 1000,\n 'model__n_iter_no_change': 5,\n 'model__n_jobs': None,\n 'model__penalty': 'l2',\n 'model__power_t': 0.5,\n 'model__random_state': 42,\n 'model__shuffle': True,\n 'model__tol': 0.001,\n 'model__validation_fraction': 0.1,\n 'model__verbose': 0,\n 'model__warm_start': False}"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scale', StandardScaler()),\n",
    "        ('model', SGDClassifier(random_state=42))\n",
    "    ]\n",
    ")\n",
    "pipe.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "model = BayesSearchCV(estimator=pipe,\n",
    "                      search_spaces=\n",
    "                      {'model__loss': Categorical(\n",
    "                          ['hinge', 'log_loss', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error',\n",
    "                           'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']),\n",
    "                          'model__penalty': Categorical(['l2', 'l1', 'elasticnet']),\n",
    "                          'model__alpha': Real(1e-6, 1e-1, prior='log-uniform'),\n",
    "                          'model__learning_rate': Categorical(['constant', 'optimal', 'invscaling', 'adaptive']),\n",
    "                          'model__eta0': Real(1e-6, 1e-1, prior='log-uniform'),\n",
    "                          'model__class_weight': Categorical([None, 'balanced'])\n",
    "                      },\n",
    "                      scoring='f1',\n",
    "                      cv=5,\n",
    "                      error_score=np.nan,\n",
    "                      n_jobs=-1,\n",
    "                      pre_dispatch='2*n_jobs',\n",
    "                      random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# index = 1\n",
    "# model.fit(X_train, y_train, callback=on_step)\n",
    "#\n",
    "# optimised_sgdc = model.best_estimator_\n",
    "#\n",
    "# y_train_pred = optimised_sgdc.predict(X_train)\n",
    "# calculate_metrics_classification(y_train, y_train_pred)\n",
    "#\n",
    "# # Save Model\n",
    "# dump(optimised_sgdc, 'Dataset_Files/Baseline_Models/Classification/optimised_sgdc.joblib')\n",
    "# np.save(\"Dataset_Files/Baseline_Models/Classification/optimised_sgdc_cv_results.npy\", model.cv_results_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Load Model\n",
    "optimised_sgdc = load('Dataset_Files/Baseline_Models/Classification/optimised_sgdc.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 1000\n",
      "--------------------------------------------------------\n",
      "Median Recall: 0.93 with a 95% confidence interval of [0.91,0.95]\n",
      "Median Precision: 0.84 with a 95% confidence interval of [0.81,0.86]\n",
      "Median F1: 0.88 with a 95% confidence interval of [0.87,0.90]\n",
      "Median Accuracy: 0.82 with a 95% confidence interval of [0.79,0.84]\n",
      "Median MCC: 0.49 with a 95% confidence interval of [0.43,0.55]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_sgdc, X_train, y_train, 1000, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scale', StandardScaler()),\n  ('model',\n   SGDClassifier(alpha=1e-06, eta0=0.0009866506104658564, learning_rate='adaptive',\n                 loss='log_loss', penalty='elasticnet', random_state=42))],\n 'verbose': False,\n 'scale': StandardScaler(),\n 'model': SGDClassifier(alpha=1e-06, eta0=0.0009866506104658564, learning_rate='adaptive',\n               loss='log_loss', penalty='elasticnet', random_state=42),\n 'scale__copy': True,\n 'scale__with_mean': True,\n 'scale__with_std': True,\n 'model__alpha': 1e-06,\n 'model__average': False,\n 'model__class_weight': None,\n 'model__early_stopping': False,\n 'model__epsilon': 0.1,\n 'model__eta0': 0.0009866506104658564,\n 'model__fit_intercept': True,\n 'model__l1_ratio': 0.15,\n 'model__learning_rate': 'adaptive',\n 'model__loss': 'log_loss',\n 'model__max_iter': 1000,\n 'model__n_iter_no_change': 5,\n 'model__n_jobs': None,\n 'model__penalty': 'elasticnet',\n 'model__power_t': 0.5,\n 'model__random_state': 42,\n 'model__shuffle': True,\n 'model__tol': 0.001,\n 'model__validation_fraction': 0.1,\n 'model__verbose': 0,\n 'model__warm_start': False}"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimised_sgdc.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n42      11.371536      0.187080         0.120313        0.014446   \n43       9.930557      0.116561         0.122369        0.014750   \n11      12.323203      0.777626         0.090290        0.014649   \n21      11.653906      0.736498         0.090107        0.008717   \n14      21.720275      1.683850         0.086799        0.011324   \n29      22.164678      1.160952         0.098143        0.010870   \n22       9.552707      0.206343         0.110204        0.004911   \n35       7.110788      0.163579         0.105801        0.019669   \n47      17.977861      1.378186         0.097952        0.012883   \n38       7.497112      0.159908         0.116463        0.017065   \n37       7.909078      0.126910         0.109267        0.011407   \n40       7.657834      0.150864         0.113433        0.019624   \n24       4.839957      0.114795         0.128224        0.012579   \n12       7.242284      0.111126         0.101608        0.004747   \n46       2.425479      0.077998         0.112124        0.008104   \n27       6.538819      0.130196         0.128093        0.020720   \n20       6.037118      0.045193         0.132393        0.006356   \n45      10.437507      0.122368         0.122785        0.010291   \n16       4.022880      0.149623         0.123667        0.023020   \n26       7.741155      0.067561         0.141987        0.009746   \n3        5.830240      0.065382         0.147048        0.020574   \n17       8.864925      0.064287         0.140712        0.010894   \n41      13.568489      0.090104         0.122306        0.015145   \n4       11.223827      0.089680         0.113787        0.018354   \n39      20.832234      0.146697         0.110316        0.016931   \n19      11.404459      3.238001         0.094079        0.018358   \n32      18.146801      0.093816         0.125298        0.013075   \n31       2.629266      0.026307         0.142817        0.004114   \n5        7.381705      0.804128         0.088235        0.010347   \n7       12.694608      1.057290         0.086356        0.011195   \n25       2.977266      0.030641         0.144281        0.008797   \n30       9.335611      1.287870         0.096757        0.010922   \n28     149.340198     20.403291         0.091835        0.011297   \n49      64.104003     14.902746         0.094789        0.007688   \n10       2.712226      0.029628         0.174585        0.007204   \n9        7.448480      3.359447         0.090268        0.008094   \n48      99.811618      0.218830         0.098581        0.003739   \n8        4.997506      0.469523         0.112601        0.017231   \n6        8.458101      0.405895         0.102146        0.014705   \n23       7.438843      0.087571         0.105269        0.005452   \n0        7.482481      0.964029         0.125164        0.008567   \n36       2.904844      0.180061         0.123379        0.012841   \n2        4.077259      0.067143         0.138032        0.011970   \n34     122.044271     25.866073         0.091235        0.014066   \n18       3.479757      0.492655         0.118384        0.024489   \n13      48.038978      3.973946         0.095965        0.014400   \n1      293.638226      1.132964         0.102040        0.016493   \n33     286.435329      1.139006         0.097890        0.012976   \n15     267.347266      0.725299         0.096939        0.008555   \n44       3.781331      0.795908         0.115281        0.022847   \n\n   param_model__alpha param_model__class_weight param_model__eta0  \\\n42           0.000001                      None          0.000987   \n43           0.000001                      None          0.000494   \n11           0.000001                      None          0.000727   \n21           0.000001                      None          0.000657   \n14           0.000001                      None          0.034326   \n29           0.000001                      None          0.076401   \n22           0.000001                      None          0.000197   \n35           0.000156                      None          0.000019   \n47           0.000261                      None          0.001169   \n38           0.000023                      None          0.000014   \n37           0.000006                      None          0.000011   \n40           0.010342                      None          0.000014   \n24           0.000015                      None          0.000007   \n12            0.00039                      None          0.000004   \n46                0.1                      None          0.010704   \n27           0.000009                      None          0.000003   \n20           0.000001                      None          0.000023   \n45           0.000001                      None          0.000011   \n16           0.002118                      None          0.001112   \n26           0.000008                      None          0.000001   \n3            0.011534                      None          0.000978   \n17           0.005855                      None          0.000328   \n41           0.053992                      None           0.00008   \n4            0.009949                      None           0.00043   \n39           0.071471                      None          0.085677   \n19           0.000009                      None          0.011026   \n32           0.000833                      None          0.000045   \n31           0.000001                      None          0.000001   \n5            0.004679                  balanced          0.000007   \n7            0.000521                  balanced          0.000304   \n25           0.000007                      None          0.000014   \n30           0.000125                      None          0.004578   \n28           0.000005                      None          0.000005   \n49            0.00002                      None          0.000001   \n10           0.075042                      None          0.000759   \n9            0.000001                  balanced          0.005086   \n48            0.08768                  balanced          0.002819   \n8            0.059895                  balanced          0.022817   \n6            0.001217                  balanced          0.000062   \n23           0.009889                      None          0.000002   \n0            0.000112                  balanced          0.046168   \n36           0.000006                      None          0.000001   \n2            0.000168                  balanced          0.000003   \n34           0.000002                      None          0.049354   \n18           0.001494                      None          0.019815   \n13           0.000001                      None          0.054998   \n1            0.015379                  balanced          0.000033   \n33           0.000069                      None          0.038085   \n15                0.1                      None          0.000051   \n44            0.00001                      None               0.1   \n\n   param_model__learning_rate            param_model__loss  \\\n42                   adaptive                     log_loss   \n43                   adaptive                     log_loss   \n11                   adaptive               modified_huber   \n21                   adaptive               modified_huber   \n14                   adaptive               modified_huber   \n29                   adaptive               modified_huber   \n22                   adaptive                     log_loss   \n35                   adaptive               modified_huber   \n47                   adaptive                squared_hinge   \n38                   adaptive               modified_huber   \n37                   adaptive               modified_huber   \n40                   adaptive               modified_huber   \n24                   constant  squared_epsilon_insensitive   \n12                   adaptive               modified_huber   \n46                 invscaling                squared_hinge   \n27                   adaptive  squared_epsilon_insensitive   \n20                   constant                     log_loss   \n45                   adaptive                     log_loss   \n16                   constant                     log_loss   \n26                   adaptive  squared_epsilon_insensitive   \n3                  invscaling               modified_huber   \n17                 invscaling               modified_huber   \n41                   adaptive                     log_loss   \n4                  invscaling                squared_error   \n39                   adaptive                     log_loss   \n19                   constant                     log_loss   \n32                 invscaling               modified_huber   \n31                   constant                   perceptron   \n5                    constant  squared_epsilon_insensitive   \n7                     optimal                     log_loss   \n25                   constant                   perceptron   \n30                   constant                   perceptron   \n28                    optimal                squared_hinge   \n49                    optimal          epsilon_insensitive   \n10                 invscaling                   perceptron   \n9                    constant                   perceptron   \n48                    optimal                squared_hinge   \n8                    constant                     log_loss   \n6                     optimal                   perceptron   \n23                   adaptive                        huber   \n0                    constant                   perceptron   \n36                 invscaling                squared_error   \n2                    constant                        huber   \n34                   constant          epsilon_insensitive   \n18                   constant                squared_error   \n13                   adaptive                squared_error   \n1                     optimal                squared_error   \n33                   adaptive  squared_epsilon_insensitive   \n15                    optimal                squared_error   \n44                   constant  squared_epsilon_insensitive   \n\n   param_model__penalty                                             params  \\\n42           elasticnet  {'model__alpha': 1e-06, 'model__class_weight':...   \n43           elasticnet  {'model__alpha': 1e-06, 'model__class_weight':...   \n11           elasticnet  {'model__alpha': 1e-06, 'model__class_weight':...   \n21           elasticnet  {'model__alpha': 1e-06, 'model__class_weight':...   \n14           elasticnet  {'model__alpha': 1.208433613059891e-06, 'model...   \n29           elasticnet  {'model__alpha': 1e-06, 'model__class_weight':...   \n22           elasticnet  {'model__alpha': 1e-06, 'model__class_weight':...   \n35           elasticnet  {'model__alpha': 0.0001558896341561995, 'model...   \n47                   l1  {'model__alpha': 0.00026050658160080433, 'mode...   \n38           elasticnet  {'model__alpha': 2.3185490575738482e-05, 'mode...   \n37           elasticnet  {'model__alpha': 5.542025661946043e-06, 'model...   \n40           elasticnet  {'model__alpha': 0.010341539918142708, 'model_...   \n24           elasticnet  {'model__alpha': 1.5102696652058713e-05, 'mode...   \n12           elasticnet  {'model__alpha': 0.0003900951285443547, 'model...   \n46                   l2  {'model__alpha': 0.1, 'model__class_weight': N...   \n27           elasticnet  {'model__alpha': 9.482542507347432e-06, 'model...   \n20           elasticnet  {'model__alpha': 1.1052532881525498e-06, 'mode...   \n45           elasticnet  {'model__alpha': 1e-06, 'model__class_weight':...   \n16           elasticnet  {'model__alpha': 0.0021178262313998253, 'model...   \n26           elasticnet  {'model__alpha': 8.292082179554043e-06, 'model...   \n3            elasticnet  {'model__alpha': 0.011533999859559564, 'model_...   \n17           elasticnet  {'model__alpha': 0.005854632104963596, 'model_...   \n41           elasticnet  {'model__alpha': 0.053991933494224216, 'model_...   \n4                    l1  {'model__alpha': 0.009948719998234101, 'model_...   \n39                   l1  {'model__alpha': 0.07147057173391871, 'model__...   \n19           elasticnet  {'model__alpha': 9.053436778046378e-06, 'model...   \n32           elasticnet  {'model__alpha': 0.000832614559844781, 'model_...   \n31           elasticnet  {'model__alpha': 1e-06, 'model__class_weight':...   \n5                    l1  {'model__alpha': 0.0046788604247112444, 'model...   \n7            elasticnet  {'model__alpha': 0.0005212131190318165, 'model...   \n25           elasticnet  {'model__alpha': 6.590713623713951e-06, 'model...   \n30           elasticnet  {'model__alpha': 0.0001246610255516929, 'model...   \n28           elasticnet  {'model__alpha': 5.3678104049400005e-06, 'mode...   \n49                   l1  {'model__alpha': 2.042094287865455e-05, 'model...   \n10           elasticnet  {'model__alpha': 0.07504203081370357, 'model__...   \n9                    l1  {'model__alpha': 1.0426811836320545e-06, 'mode...   \n48                   l2  {'model__alpha': 0.08768010922961404, 'model__...   \n8            elasticnet  {'model__alpha': 0.05989491205267932, 'model__...   \n6                    l1  {'model__alpha': 0.0012172976749510152, 'model...   \n23           elasticnet  {'model__alpha': 0.009889417540774548, 'model_...   \n0                    l1  {'model__alpha': 0.00011233621690895234, 'mode...   \n36           elasticnet  {'model__alpha': 5.823893699289275e-06, 'model...   \n2                    l1  {'model__alpha': 0.00016755699440936588, 'mode...   \n34           elasticnet  {'model__alpha': 1.907041988802392e-06, 'model...   \n18                   l1  {'model__alpha': 0.0014937568205662616, 'model...   \n13                   l1  {'model__alpha': 1.0613730087581182e-06, 'mode...   \n1            elasticnet  {'model__alpha': 0.01537948446580078, 'model__...   \n33           elasticnet  {'model__alpha': 6.937084058445544e-05, 'model...   \n15                   l1  {'model__alpha': 0.1, 'model__class_weight': N...   \n44           elasticnet  {'model__alpha': 9.560509917296386e-06, 'model...   \n\n    split0_test_score  split1_test_score  split2_test_score  \\\n42           0.881067           0.879696           0.882391   \n43           0.881225           0.879568           0.882046   \n11           0.879445           0.880200           0.882000   \n21           0.879345           0.880241           0.881935   \n14           0.879728           0.879959           0.882158   \n29           0.879402           0.880403           0.882088   \n22           0.880972           0.879777           0.881438   \n35           0.880213           0.879695           0.881146   \n47           0.879344           0.880223           0.881504   \n38           0.880143           0.879849           0.880830   \n37           0.879706           0.879470           0.880589   \n40           0.878602           0.879309           0.880296   \n24           0.878005           0.878128           0.879540   \n12           0.877724           0.878218           0.879487   \n46           0.876894           0.876623           0.880410   \n27           0.877010           0.876669           0.878913   \n20           0.877355           0.877030           0.879074   \n45           0.875654           0.874753           0.878214   \n16           0.875093           0.876707           0.878307   \n26           0.874561           0.874462           0.877267   \n3            0.874558           0.873954           0.877467   \n17           0.869510           0.870075           0.874288   \n41           0.864656           0.862577           0.864093   \n4            0.861706           0.861486           0.864858   \n39           0.848705           0.848705           0.848705   \n19           0.849436           0.829524           0.847808   \n32           0.833769           0.834161           0.840318   \n31           0.810883           0.832623           0.822124   \n5            0.820764           0.823778           0.821549   \n7            0.815203           0.821658           0.821956   \n25           0.803554           0.815368           0.819242   \n30           0.794003           0.820598           0.838286   \n28           0.794833           0.795862           0.807527   \n49           0.795141           0.787408           0.825270   \n10           0.772447           0.651155           0.755722   \n9            0.724418           0.775093           0.755478   \n48           0.738224           0.746623           0.744615   \n8            0.735046           0.735476           0.729748   \n6            0.753267           0.746865           0.711102   \n23           0.729440           0.728789           0.738857   \n0            0.751342           0.707263           0.743205   \n36           0.716819           0.713706           0.724965   \n2            0.691503           0.694829           0.697351   \n34           0.582830           0.620532           0.635457   \n18           0.558026           0.629260           0.618340   \n13           0.571582           0.608444           0.625949   \n1            0.602855           0.603559           0.586773   \n33           0.602704           0.613147           0.577065   \n15           0.597503           0.595771           0.586406   \n44           0.599617           0.584659           0.589793   \n\n    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n42           0.880865           0.880873         0.880978        0.000857   \n43           0.880833           0.880974         0.880929        0.000800   \n11           0.880759           0.881322         0.880745        0.000882   \n21           0.880702           0.881422         0.880729        0.000904   \n14           0.880658           0.880842         0.880669        0.000853   \n29           0.880064           0.880907         0.880573        0.000902   \n22           0.880232           0.880146         0.880513        0.000603   \n35           0.880475           0.880904         0.880487        0.000512   \n47           0.880303           0.880417         0.880358        0.000688   \n38           0.879818           0.880419         0.880212        0.000379   \n37           0.879743           0.880184         0.879938        0.000399   \n40           0.878776           0.879221         0.879241        0.000590   \n24           0.877573           0.878697         0.878389        0.000678   \n12           0.877498           0.878997         0.878385        0.000754   \n46           0.877984           0.878793         0.878141        0.001375   \n27           0.876956           0.878041         0.877518        0.000838   \n20           0.876582           0.877332         0.877475        0.000847   \n45           0.875544           0.876788         0.876191        0.001202   \n16           0.874782           0.874400         0.875858        0.001455   \n26           0.874952           0.875745         0.875397        0.001038   \n3            0.874660           0.875502         0.875228        0.001223   \n17           0.871516           0.871708         0.871420        0.001660   \n41           0.864025           0.863719         0.863814        0.000689   \n4            0.862569           0.862826         0.862689        0.001196   \n39           0.848672           0.848672         0.848692        0.000016   \n19           0.835244           0.826797         0.837762        0.009291   \n32           0.833241           0.835487         0.835395        0.002571   \n31           0.832820           0.828595         0.825409        0.008233   \n5            0.816801           0.818738         0.820326        0.002390   \n7            0.816152           0.823749         0.819744        0.003409   \n25           0.836698           0.809443         0.816861        0.011256   \n30           0.791180           0.812198         0.811253        0.017433   \n28           0.793580           0.808601         0.800081        0.006567   \n49           0.794449           0.785762         0.797606        0.014322   \n10           0.789346           0.848672         0.763469        0.064318   \n9            0.707496           0.757212         0.743940        0.024450   \n48           0.739278           0.746236         0.742995        0.003546   \n8            0.748294           0.742245         0.738162        0.006435   \n6            0.761169           0.700737         0.734628        0.024098   \n23           0.733757           0.728350         0.731839        0.004004   \n0            0.722060           0.729883         0.730751        0.015537   \n36           0.720019           0.716570         0.718416        0.003837   \n2            0.693888           0.687074         0.692929        0.003475   \n34           0.597138           0.637601         0.614712        0.021510   \n18           0.631818           0.605645         0.608618        0.026934   \n13           0.595397           0.629338         0.606142        0.021192   \n1            0.593342           0.601164         0.597539        0.006499   \n33           0.603865           0.589174         0.597191        0.012640   \n15           0.581483           0.601205         0.592474        0.007349   \n44           0.556685           0.575613         0.581274        0.014541   \n\n    rank_test_score  \n42                1  \n43                2  \n11                3  \n21                4  \n14                5  \n29                6  \n22                7  \n35                8  \n47                9  \n38               10  \n37               11  \n40               12  \n24               13  \n12               14  \n46               15  \n27               16  \n20               17  \n45               18  \n16               19  \n26               20  \n3                21  \n17               22  \n41               23  \n4                24  \n39               25  \n19               26  \n32               27  \n31               28  \n5                29  \n7                30  \n25               31  \n30               32  \n28               33  \n49               34  \n10               35  \n9                36  \n48               37  \n8                38  \n6                39  \n23               40  \n0                41  \n36               42  \n2                43  \n34               44  \n18               45  \n13               46  \n1                47  \n33               48  \n15               49  \n44               50  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_model__alpha</th>\n      <th>param_model__class_weight</th>\n      <th>param_model__eta0</th>\n      <th>param_model__learning_rate</th>\n      <th>param_model__loss</th>\n      <th>param_model__penalty</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>42</th>\n      <td>11.371536</td>\n      <td>0.187080</td>\n      <td>0.120313</td>\n      <td>0.014446</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.000987</td>\n      <td>adaptive</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1e-06, 'model__class_weight':...</td>\n      <td>0.881067</td>\n      <td>0.879696</td>\n      <td>0.882391</td>\n      <td>0.880865</td>\n      <td>0.880873</td>\n      <td>0.880978</td>\n      <td>0.000857</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>9.930557</td>\n      <td>0.116561</td>\n      <td>0.122369</td>\n      <td>0.014750</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.000494</td>\n      <td>adaptive</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1e-06, 'model__class_weight':...</td>\n      <td>0.881225</td>\n      <td>0.879568</td>\n      <td>0.882046</td>\n      <td>0.880833</td>\n      <td>0.880974</td>\n      <td>0.880929</td>\n      <td>0.000800</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12.323203</td>\n      <td>0.777626</td>\n      <td>0.090290</td>\n      <td>0.014649</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.000727</td>\n      <td>adaptive</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1e-06, 'model__class_weight':...</td>\n      <td>0.879445</td>\n      <td>0.880200</td>\n      <td>0.882000</td>\n      <td>0.880759</td>\n      <td>0.881322</td>\n      <td>0.880745</td>\n      <td>0.000882</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>11.653906</td>\n      <td>0.736498</td>\n      <td>0.090107</td>\n      <td>0.008717</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.000657</td>\n      <td>adaptive</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1e-06, 'model__class_weight':...</td>\n      <td>0.879345</td>\n      <td>0.880241</td>\n      <td>0.881935</td>\n      <td>0.880702</td>\n      <td>0.881422</td>\n      <td>0.880729</td>\n      <td>0.000904</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>21.720275</td>\n      <td>1.683850</td>\n      <td>0.086799</td>\n      <td>0.011324</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.034326</td>\n      <td>adaptive</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1.208433613059891e-06, 'model...</td>\n      <td>0.879728</td>\n      <td>0.879959</td>\n      <td>0.882158</td>\n      <td>0.880658</td>\n      <td>0.880842</td>\n      <td>0.880669</td>\n      <td>0.000853</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>22.164678</td>\n      <td>1.160952</td>\n      <td>0.098143</td>\n      <td>0.010870</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.076401</td>\n      <td>adaptive</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1e-06, 'model__class_weight':...</td>\n      <td>0.879402</td>\n      <td>0.880403</td>\n      <td>0.882088</td>\n      <td>0.880064</td>\n      <td>0.880907</td>\n      <td>0.880573</td>\n      <td>0.000902</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>9.552707</td>\n      <td>0.206343</td>\n      <td>0.110204</td>\n      <td>0.004911</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.000197</td>\n      <td>adaptive</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1e-06, 'model__class_weight':...</td>\n      <td>0.880972</td>\n      <td>0.879777</td>\n      <td>0.881438</td>\n      <td>0.880232</td>\n      <td>0.880146</td>\n      <td>0.880513</td>\n      <td>0.000603</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>7.110788</td>\n      <td>0.163579</td>\n      <td>0.105801</td>\n      <td>0.019669</td>\n      <td>0.000156</td>\n      <td>None</td>\n      <td>0.000019</td>\n      <td>adaptive</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.0001558896341561995, 'model...</td>\n      <td>0.880213</td>\n      <td>0.879695</td>\n      <td>0.881146</td>\n      <td>0.880475</td>\n      <td>0.880904</td>\n      <td>0.880487</td>\n      <td>0.000512</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>17.977861</td>\n      <td>1.378186</td>\n      <td>0.097952</td>\n      <td>0.012883</td>\n      <td>0.000261</td>\n      <td>None</td>\n      <td>0.001169</td>\n      <td>adaptive</td>\n      <td>squared_hinge</td>\n      <td>l1</td>\n      <td>{'model__alpha': 0.00026050658160080433, 'mode...</td>\n      <td>0.879344</td>\n      <td>0.880223</td>\n      <td>0.881504</td>\n      <td>0.880303</td>\n      <td>0.880417</td>\n      <td>0.880358</td>\n      <td>0.000688</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>7.497112</td>\n      <td>0.159908</td>\n      <td>0.116463</td>\n      <td>0.017065</td>\n      <td>0.000023</td>\n      <td>None</td>\n      <td>0.000014</td>\n      <td>adaptive</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 2.3185490575738482e-05, 'mode...</td>\n      <td>0.880143</td>\n      <td>0.879849</td>\n      <td>0.880830</td>\n      <td>0.879818</td>\n      <td>0.880419</td>\n      <td>0.880212</td>\n      <td>0.000379</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>7.909078</td>\n      <td>0.126910</td>\n      <td>0.109267</td>\n      <td>0.011407</td>\n      <td>0.000006</td>\n      <td>None</td>\n      <td>0.000011</td>\n      <td>adaptive</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 5.542025661946043e-06, 'model...</td>\n      <td>0.879706</td>\n      <td>0.879470</td>\n      <td>0.880589</td>\n      <td>0.879743</td>\n      <td>0.880184</td>\n      <td>0.879938</td>\n      <td>0.000399</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>7.657834</td>\n      <td>0.150864</td>\n      <td>0.113433</td>\n      <td>0.019624</td>\n      <td>0.010342</td>\n      <td>None</td>\n      <td>0.000014</td>\n      <td>adaptive</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.010341539918142708, 'model_...</td>\n      <td>0.878602</td>\n      <td>0.879309</td>\n      <td>0.880296</td>\n      <td>0.878776</td>\n      <td>0.879221</td>\n      <td>0.879241</td>\n      <td>0.000590</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>4.839957</td>\n      <td>0.114795</td>\n      <td>0.128224</td>\n      <td>0.012579</td>\n      <td>0.000015</td>\n      <td>None</td>\n      <td>0.000007</td>\n      <td>constant</td>\n      <td>squared_epsilon_insensitive</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1.5102696652058713e-05, 'mode...</td>\n      <td>0.878005</td>\n      <td>0.878128</td>\n      <td>0.879540</td>\n      <td>0.877573</td>\n      <td>0.878697</td>\n      <td>0.878389</td>\n      <td>0.000678</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>7.242284</td>\n      <td>0.111126</td>\n      <td>0.101608</td>\n      <td>0.004747</td>\n      <td>0.00039</td>\n      <td>None</td>\n      <td>0.000004</td>\n      <td>adaptive</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.0003900951285443547, 'model...</td>\n      <td>0.877724</td>\n      <td>0.878218</td>\n      <td>0.879487</td>\n      <td>0.877498</td>\n      <td>0.878997</td>\n      <td>0.878385</td>\n      <td>0.000754</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>2.425479</td>\n      <td>0.077998</td>\n      <td>0.112124</td>\n      <td>0.008104</td>\n      <td>0.1</td>\n      <td>None</td>\n      <td>0.010704</td>\n      <td>invscaling</td>\n      <td>squared_hinge</td>\n      <td>l2</td>\n      <td>{'model__alpha': 0.1, 'model__class_weight': N...</td>\n      <td>0.876894</td>\n      <td>0.876623</td>\n      <td>0.880410</td>\n      <td>0.877984</td>\n      <td>0.878793</td>\n      <td>0.878141</td>\n      <td>0.001375</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>6.538819</td>\n      <td>0.130196</td>\n      <td>0.128093</td>\n      <td>0.020720</td>\n      <td>0.000009</td>\n      <td>None</td>\n      <td>0.000003</td>\n      <td>adaptive</td>\n      <td>squared_epsilon_insensitive</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 9.482542507347432e-06, 'model...</td>\n      <td>0.877010</td>\n      <td>0.876669</td>\n      <td>0.878913</td>\n      <td>0.876956</td>\n      <td>0.878041</td>\n      <td>0.877518</td>\n      <td>0.000838</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>6.037118</td>\n      <td>0.045193</td>\n      <td>0.132393</td>\n      <td>0.006356</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.000023</td>\n      <td>constant</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1.1052532881525498e-06, 'mode...</td>\n      <td>0.877355</td>\n      <td>0.877030</td>\n      <td>0.879074</td>\n      <td>0.876582</td>\n      <td>0.877332</td>\n      <td>0.877475</td>\n      <td>0.000847</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>10.437507</td>\n      <td>0.122368</td>\n      <td>0.122785</td>\n      <td>0.010291</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.000011</td>\n      <td>adaptive</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1e-06, 'model__class_weight':...</td>\n      <td>0.875654</td>\n      <td>0.874753</td>\n      <td>0.878214</td>\n      <td>0.875544</td>\n      <td>0.876788</td>\n      <td>0.876191</td>\n      <td>0.001202</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>4.022880</td>\n      <td>0.149623</td>\n      <td>0.123667</td>\n      <td>0.023020</td>\n      <td>0.002118</td>\n      <td>None</td>\n      <td>0.001112</td>\n      <td>constant</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.0021178262313998253, 'model...</td>\n      <td>0.875093</td>\n      <td>0.876707</td>\n      <td>0.878307</td>\n      <td>0.874782</td>\n      <td>0.874400</td>\n      <td>0.875858</td>\n      <td>0.001455</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>7.741155</td>\n      <td>0.067561</td>\n      <td>0.141987</td>\n      <td>0.009746</td>\n      <td>0.000008</td>\n      <td>None</td>\n      <td>0.000001</td>\n      <td>adaptive</td>\n      <td>squared_epsilon_insensitive</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 8.292082179554043e-06, 'model...</td>\n      <td>0.874561</td>\n      <td>0.874462</td>\n      <td>0.877267</td>\n      <td>0.874952</td>\n      <td>0.875745</td>\n      <td>0.875397</td>\n      <td>0.001038</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.830240</td>\n      <td>0.065382</td>\n      <td>0.147048</td>\n      <td>0.020574</td>\n      <td>0.011534</td>\n      <td>None</td>\n      <td>0.000978</td>\n      <td>invscaling</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.011533999859559564, 'model_...</td>\n      <td>0.874558</td>\n      <td>0.873954</td>\n      <td>0.877467</td>\n      <td>0.874660</td>\n      <td>0.875502</td>\n      <td>0.875228</td>\n      <td>0.001223</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>8.864925</td>\n      <td>0.064287</td>\n      <td>0.140712</td>\n      <td>0.010894</td>\n      <td>0.005855</td>\n      <td>None</td>\n      <td>0.000328</td>\n      <td>invscaling</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.005854632104963596, 'model_...</td>\n      <td>0.869510</td>\n      <td>0.870075</td>\n      <td>0.874288</td>\n      <td>0.871516</td>\n      <td>0.871708</td>\n      <td>0.871420</td>\n      <td>0.001660</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>13.568489</td>\n      <td>0.090104</td>\n      <td>0.122306</td>\n      <td>0.015145</td>\n      <td>0.053992</td>\n      <td>None</td>\n      <td>0.00008</td>\n      <td>adaptive</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.053991933494224216, 'model_...</td>\n      <td>0.864656</td>\n      <td>0.862577</td>\n      <td>0.864093</td>\n      <td>0.864025</td>\n      <td>0.863719</td>\n      <td>0.863814</td>\n      <td>0.000689</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11.223827</td>\n      <td>0.089680</td>\n      <td>0.113787</td>\n      <td>0.018354</td>\n      <td>0.009949</td>\n      <td>None</td>\n      <td>0.00043</td>\n      <td>invscaling</td>\n      <td>squared_error</td>\n      <td>l1</td>\n      <td>{'model__alpha': 0.009948719998234101, 'model_...</td>\n      <td>0.861706</td>\n      <td>0.861486</td>\n      <td>0.864858</td>\n      <td>0.862569</td>\n      <td>0.862826</td>\n      <td>0.862689</td>\n      <td>0.001196</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>20.832234</td>\n      <td>0.146697</td>\n      <td>0.110316</td>\n      <td>0.016931</td>\n      <td>0.071471</td>\n      <td>None</td>\n      <td>0.085677</td>\n      <td>adaptive</td>\n      <td>log_loss</td>\n      <td>l1</td>\n      <td>{'model__alpha': 0.07147057173391871, 'model__...</td>\n      <td>0.848705</td>\n      <td>0.848705</td>\n      <td>0.848705</td>\n      <td>0.848672</td>\n      <td>0.848672</td>\n      <td>0.848692</td>\n      <td>0.000016</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>11.404459</td>\n      <td>3.238001</td>\n      <td>0.094079</td>\n      <td>0.018358</td>\n      <td>0.000009</td>\n      <td>None</td>\n      <td>0.011026</td>\n      <td>constant</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 9.053436778046378e-06, 'model...</td>\n      <td>0.849436</td>\n      <td>0.829524</td>\n      <td>0.847808</td>\n      <td>0.835244</td>\n      <td>0.826797</td>\n      <td>0.837762</td>\n      <td>0.009291</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>18.146801</td>\n      <td>0.093816</td>\n      <td>0.125298</td>\n      <td>0.013075</td>\n      <td>0.000833</td>\n      <td>None</td>\n      <td>0.000045</td>\n      <td>invscaling</td>\n      <td>modified_huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.000832614559844781, 'model_...</td>\n      <td>0.833769</td>\n      <td>0.834161</td>\n      <td>0.840318</td>\n      <td>0.833241</td>\n      <td>0.835487</td>\n      <td>0.835395</td>\n      <td>0.002571</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>2.629266</td>\n      <td>0.026307</td>\n      <td>0.142817</td>\n      <td>0.004114</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.000001</td>\n      <td>constant</td>\n      <td>perceptron</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1e-06, 'model__class_weight':...</td>\n      <td>0.810883</td>\n      <td>0.832623</td>\n      <td>0.822124</td>\n      <td>0.832820</td>\n      <td>0.828595</td>\n      <td>0.825409</td>\n      <td>0.008233</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>7.381705</td>\n      <td>0.804128</td>\n      <td>0.088235</td>\n      <td>0.010347</td>\n      <td>0.004679</td>\n      <td>balanced</td>\n      <td>0.000007</td>\n      <td>constant</td>\n      <td>squared_epsilon_insensitive</td>\n      <td>l1</td>\n      <td>{'model__alpha': 0.0046788604247112444, 'model...</td>\n      <td>0.820764</td>\n      <td>0.823778</td>\n      <td>0.821549</td>\n      <td>0.816801</td>\n      <td>0.818738</td>\n      <td>0.820326</td>\n      <td>0.002390</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>12.694608</td>\n      <td>1.057290</td>\n      <td>0.086356</td>\n      <td>0.011195</td>\n      <td>0.000521</td>\n      <td>balanced</td>\n      <td>0.000304</td>\n      <td>optimal</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.0005212131190318165, 'model...</td>\n      <td>0.815203</td>\n      <td>0.821658</td>\n      <td>0.821956</td>\n      <td>0.816152</td>\n      <td>0.823749</td>\n      <td>0.819744</td>\n      <td>0.003409</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2.977266</td>\n      <td>0.030641</td>\n      <td>0.144281</td>\n      <td>0.008797</td>\n      <td>0.000007</td>\n      <td>None</td>\n      <td>0.000014</td>\n      <td>constant</td>\n      <td>perceptron</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 6.590713623713951e-06, 'model...</td>\n      <td>0.803554</td>\n      <td>0.815368</td>\n      <td>0.819242</td>\n      <td>0.836698</td>\n      <td>0.809443</td>\n      <td>0.816861</td>\n      <td>0.011256</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>9.335611</td>\n      <td>1.287870</td>\n      <td>0.096757</td>\n      <td>0.010922</td>\n      <td>0.000125</td>\n      <td>None</td>\n      <td>0.004578</td>\n      <td>constant</td>\n      <td>perceptron</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.0001246610255516929, 'model...</td>\n      <td>0.794003</td>\n      <td>0.820598</td>\n      <td>0.838286</td>\n      <td>0.791180</td>\n      <td>0.812198</td>\n      <td>0.811253</td>\n      <td>0.017433</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>149.340198</td>\n      <td>20.403291</td>\n      <td>0.091835</td>\n      <td>0.011297</td>\n      <td>0.000005</td>\n      <td>None</td>\n      <td>0.000005</td>\n      <td>optimal</td>\n      <td>squared_hinge</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 5.3678104049400005e-06, 'mode...</td>\n      <td>0.794833</td>\n      <td>0.795862</td>\n      <td>0.807527</td>\n      <td>0.793580</td>\n      <td>0.808601</td>\n      <td>0.800081</td>\n      <td>0.006567</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>64.104003</td>\n      <td>14.902746</td>\n      <td>0.094789</td>\n      <td>0.007688</td>\n      <td>0.00002</td>\n      <td>None</td>\n      <td>0.000001</td>\n      <td>optimal</td>\n      <td>epsilon_insensitive</td>\n      <td>l1</td>\n      <td>{'model__alpha': 2.042094287865455e-05, 'model...</td>\n      <td>0.795141</td>\n      <td>0.787408</td>\n      <td>0.825270</td>\n      <td>0.794449</td>\n      <td>0.785762</td>\n      <td>0.797606</td>\n      <td>0.014322</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2.712226</td>\n      <td>0.029628</td>\n      <td>0.174585</td>\n      <td>0.007204</td>\n      <td>0.075042</td>\n      <td>None</td>\n      <td>0.000759</td>\n      <td>invscaling</td>\n      <td>perceptron</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.07504203081370357, 'model__...</td>\n      <td>0.772447</td>\n      <td>0.651155</td>\n      <td>0.755722</td>\n      <td>0.789346</td>\n      <td>0.848672</td>\n      <td>0.763469</td>\n      <td>0.064318</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>7.448480</td>\n      <td>3.359447</td>\n      <td>0.090268</td>\n      <td>0.008094</td>\n      <td>0.000001</td>\n      <td>balanced</td>\n      <td>0.005086</td>\n      <td>constant</td>\n      <td>perceptron</td>\n      <td>l1</td>\n      <td>{'model__alpha': 1.0426811836320545e-06, 'mode...</td>\n      <td>0.724418</td>\n      <td>0.775093</td>\n      <td>0.755478</td>\n      <td>0.707496</td>\n      <td>0.757212</td>\n      <td>0.743940</td>\n      <td>0.024450</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>99.811618</td>\n      <td>0.218830</td>\n      <td>0.098581</td>\n      <td>0.003739</td>\n      <td>0.08768</td>\n      <td>balanced</td>\n      <td>0.002819</td>\n      <td>optimal</td>\n      <td>squared_hinge</td>\n      <td>l2</td>\n      <td>{'model__alpha': 0.08768010922961404, 'model__...</td>\n      <td>0.738224</td>\n      <td>0.746623</td>\n      <td>0.744615</td>\n      <td>0.739278</td>\n      <td>0.746236</td>\n      <td>0.742995</td>\n      <td>0.003546</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4.997506</td>\n      <td>0.469523</td>\n      <td>0.112601</td>\n      <td>0.017231</td>\n      <td>0.059895</td>\n      <td>balanced</td>\n      <td>0.022817</td>\n      <td>constant</td>\n      <td>log_loss</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.05989491205267932, 'model__...</td>\n      <td>0.735046</td>\n      <td>0.735476</td>\n      <td>0.729748</td>\n      <td>0.748294</td>\n      <td>0.742245</td>\n      <td>0.738162</td>\n      <td>0.006435</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>8.458101</td>\n      <td>0.405895</td>\n      <td>0.102146</td>\n      <td>0.014705</td>\n      <td>0.001217</td>\n      <td>balanced</td>\n      <td>0.000062</td>\n      <td>optimal</td>\n      <td>perceptron</td>\n      <td>l1</td>\n      <td>{'model__alpha': 0.0012172976749510152, 'model...</td>\n      <td>0.753267</td>\n      <td>0.746865</td>\n      <td>0.711102</td>\n      <td>0.761169</td>\n      <td>0.700737</td>\n      <td>0.734628</td>\n      <td>0.024098</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>7.438843</td>\n      <td>0.087571</td>\n      <td>0.105269</td>\n      <td>0.005452</td>\n      <td>0.009889</td>\n      <td>None</td>\n      <td>0.000002</td>\n      <td>adaptive</td>\n      <td>huber</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.009889417540774548, 'model_...</td>\n      <td>0.729440</td>\n      <td>0.728789</td>\n      <td>0.738857</td>\n      <td>0.733757</td>\n      <td>0.728350</td>\n      <td>0.731839</td>\n      <td>0.004004</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>7.482481</td>\n      <td>0.964029</td>\n      <td>0.125164</td>\n      <td>0.008567</td>\n      <td>0.000112</td>\n      <td>balanced</td>\n      <td>0.046168</td>\n      <td>constant</td>\n      <td>perceptron</td>\n      <td>l1</td>\n      <td>{'model__alpha': 0.00011233621690895234, 'mode...</td>\n      <td>0.751342</td>\n      <td>0.707263</td>\n      <td>0.743205</td>\n      <td>0.722060</td>\n      <td>0.729883</td>\n      <td>0.730751</td>\n      <td>0.015537</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>2.904844</td>\n      <td>0.180061</td>\n      <td>0.123379</td>\n      <td>0.012841</td>\n      <td>0.000006</td>\n      <td>None</td>\n      <td>0.000001</td>\n      <td>invscaling</td>\n      <td>squared_error</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 5.823893699289275e-06, 'model...</td>\n      <td>0.716819</td>\n      <td>0.713706</td>\n      <td>0.724965</td>\n      <td>0.720019</td>\n      <td>0.716570</td>\n      <td>0.718416</td>\n      <td>0.003837</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.077259</td>\n      <td>0.067143</td>\n      <td>0.138032</td>\n      <td>0.011970</td>\n      <td>0.000168</td>\n      <td>balanced</td>\n      <td>0.000003</td>\n      <td>constant</td>\n      <td>huber</td>\n      <td>l1</td>\n      <td>{'model__alpha': 0.00016755699440936588, 'mode...</td>\n      <td>0.691503</td>\n      <td>0.694829</td>\n      <td>0.697351</td>\n      <td>0.693888</td>\n      <td>0.687074</td>\n      <td>0.692929</td>\n      <td>0.003475</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>122.044271</td>\n      <td>25.866073</td>\n      <td>0.091235</td>\n      <td>0.014066</td>\n      <td>0.000002</td>\n      <td>None</td>\n      <td>0.049354</td>\n      <td>constant</td>\n      <td>epsilon_insensitive</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 1.907041988802392e-06, 'model...</td>\n      <td>0.582830</td>\n      <td>0.620532</td>\n      <td>0.635457</td>\n      <td>0.597138</td>\n      <td>0.637601</td>\n      <td>0.614712</td>\n      <td>0.021510</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>3.479757</td>\n      <td>0.492655</td>\n      <td>0.118384</td>\n      <td>0.024489</td>\n      <td>0.001494</td>\n      <td>None</td>\n      <td>0.019815</td>\n      <td>constant</td>\n      <td>squared_error</td>\n      <td>l1</td>\n      <td>{'model__alpha': 0.0014937568205662616, 'model...</td>\n      <td>0.558026</td>\n      <td>0.629260</td>\n      <td>0.618340</td>\n      <td>0.631818</td>\n      <td>0.605645</td>\n      <td>0.608618</td>\n      <td>0.026934</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>48.038978</td>\n      <td>3.973946</td>\n      <td>0.095965</td>\n      <td>0.014400</td>\n      <td>0.000001</td>\n      <td>None</td>\n      <td>0.054998</td>\n      <td>adaptive</td>\n      <td>squared_error</td>\n      <td>l1</td>\n      <td>{'model__alpha': 1.0613730087581182e-06, 'mode...</td>\n      <td>0.571582</td>\n      <td>0.608444</td>\n      <td>0.625949</td>\n      <td>0.595397</td>\n      <td>0.629338</td>\n      <td>0.606142</td>\n      <td>0.021192</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>293.638226</td>\n      <td>1.132964</td>\n      <td>0.102040</td>\n      <td>0.016493</td>\n      <td>0.015379</td>\n      <td>balanced</td>\n      <td>0.000033</td>\n      <td>optimal</td>\n      <td>squared_error</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 0.01537948446580078, 'model__...</td>\n      <td>0.602855</td>\n      <td>0.603559</td>\n      <td>0.586773</td>\n      <td>0.593342</td>\n      <td>0.601164</td>\n      <td>0.597539</td>\n      <td>0.006499</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>286.435329</td>\n      <td>1.139006</td>\n      <td>0.097890</td>\n      <td>0.012976</td>\n      <td>0.000069</td>\n      <td>None</td>\n      <td>0.038085</td>\n      <td>adaptive</td>\n      <td>squared_epsilon_insensitive</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 6.937084058445544e-05, 'model...</td>\n      <td>0.602704</td>\n      <td>0.613147</td>\n      <td>0.577065</td>\n      <td>0.603865</td>\n      <td>0.589174</td>\n      <td>0.597191</td>\n      <td>0.012640</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>267.347266</td>\n      <td>0.725299</td>\n      <td>0.096939</td>\n      <td>0.008555</td>\n      <td>0.1</td>\n      <td>None</td>\n      <td>0.000051</td>\n      <td>optimal</td>\n      <td>squared_error</td>\n      <td>l1</td>\n      <td>{'model__alpha': 0.1, 'model__class_weight': N...</td>\n      <td>0.597503</td>\n      <td>0.595771</td>\n      <td>0.586406</td>\n      <td>0.581483</td>\n      <td>0.601205</td>\n      <td>0.592474</td>\n      <td>0.007349</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>3.781331</td>\n      <td>0.795908</td>\n      <td>0.115281</td>\n      <td>0.022847</td>\n      <td>0.00001</td>\n      <td>None</td>\n      <td>0.1</td>\n      <td>constant</td>\n      <td>squared_epsilon_insensitive</td>\n      <td>elasticnet</td>\n      <td>{'model__alpha': 9.560509917296386e-06, 'model...</td>\n      <td>0.599617</td>\n      <td>0.584659</td>\n      <td>0.589793</td>\n      <td>0.556685</td>\n      <td>0.575613</td>\n      <td>0.581274</td>\n      <td>0.014541</td>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgdc_grid_search_dataframe = pd.DataFrame(\n",
    "    np.load(\"Dataset_Files/Baseline_Models/Classification/optimised_sgdc_cv_results.npy\", allow_pickle=True).tolist())\n",
    "sgdc_grid_search_dataframe.sort_values(by=[\"rank_test_score\"], inplace=True)\n",
    "sgdc_grid_search_dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after 1000 bootstrapped samples of size 500\n",
      "--------------------------------------------------------\n",
      "Median Recall: 0.86 with a 95% confidence interval of [0.83,0.90]\n",
      "Median Precision: 0.77 with a 95% confidence interval of [0.73,0.81]\n",
      "Median F1: 0.81 with a 95% confidence interval of [0.78,0.84]\n",
      "Median Accuracy: 0.73 with a 95% confidence interval of [0.69,0.77]\n",
      "Median MCC: 0.33 with a 95% confidence interval of [0.24,0.41]\n"
     ]
    }
   ],
   "source": [
    "get_confidence_intervals(optimised_sgdc, X_test, y_test, 500, \"Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AlphaFold Project Environment",
   "language": "python",
   "name": "alphafold_dataset_drug_binding_prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}